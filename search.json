[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Odin and Monty",
    "section": "",
    "text": "Preface\nThis is a book about writing models in the odin “domain specific language” (DSL) and fitting these models to data using monty. These tools can be used entirely separately; you can create a dynamical model (or “system”) in odin and never fit it to data, or you can use monty to fit models that are written in plain R code. We’ll structure the book to cover the tools fairly separately at first, then describe their intersection. Along the way, you’ll also use dust, which powers odin, so we’ll spend some time describing how to use that, and also how to write models directly in dust if you need more control than odin provides.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#history",
    "href": "index.html#history",
    "title": "Odin and Monty",
    "section": "History",
    "text": "History\nOriginally, we designed odin around describing and solving systems of differential equations, with a small amount of support for working with discrete-time stochastic systems. Over time, and particularly during the COVID-19 response, we expanded the stochastic support and introduced the ability to fit these models using particle filters and other sequential Monte Carlo algorithms. You may have used odin.dust and mcstate through this period. As of 2024 we have rationalised our tools into a new set of packages which are currently called odin2, dust2 and monty",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#slide-decks",
    "href": "index.html#slide-decks",
    "title": "Odin and Monty",
    "section": "Slide decks",
    "text": "Slide decks\n\nFitting odin models with monty",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Odin and Monty",
    "section": "Installation",
    "text": "Installation\nYou can install these packages in one go from our R-universe:\ninstall.packages(\n  c(\"monty\", \"dust2\", \"odin2\"),\n  repos = c(\"https://mrc-ide.r-universe.dev\", \"https://cloud.r-project.org\"))\nYou will also need a functioning C++ toolchain; you can test this by running\n\npkgbuild::has_build_tools(debug = TRUE)\n#&gt; Trying to compile a simple C file\n#&gt; Running /opt/R/4.5.1/lib/R/bin/R CMD SHLIB foo.c\n#&gt; using C compiler: ‘gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0’\n#&gt; gcc -std=gnu2x -I\"/opt/R/4.5.1/lib/R/include\" -DNDEBUG   -I/usr/local/include    -fpic  -g -O2  -c foo.c -o foo.o\n#&gt; gcc -std=gnu2x -shared -L/opt/R/4.5.1/lib/R/lib -L/usr/local/lib -o foo.so foo.o -L/opt/R/4.5.1/lib/R/lib -lR\n#&gt; \n#&gt; [1] TRUE",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "Odin and Monty",
    "section": "About this book",
    "text": "About this book\nThis book exists to supplement the package documentation, and we will try to link extensively to it. It is designed as a fairly friendly walk-through of the tools, and to mirror courses that we run.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "odin.html",
    "href": "odin.html",
    "title": "1  Getting started with odin",
    "section": "",
    "text": "1.1 A simple example\nodin is a “Domain Specific Language” (DSL), that is a mini-language that is specifically tailored to a domain. By targeting a narrow domain we can have a language that expressively captures a problem and gives an efficient solution, as opposed to a general purpose language where you can write code that expresses anything, but your solution might either be quite verbose or have poor performance. You might be familiar with other DSLs such as the dplyr or ggplot2 syntax, or SQL if you have used databases.\nHere is a small system of differential equations for an “SIR” (Susceptible-Infected-Recovered) model:\n\\[\\begin{gather*}\n\\frac{dS}{dt} = -\\beta S \\frac{I}{N}\\\\\n\\frac{dI}{dt} = \\beta S \\frac{I}{N} - \\gamma I\\\\\n\\frac{dR}{dt} = \\gamma I\n\\end{gather*}\\]\nAnd here is an implementation of these equations in odin:\nsir &lt;- odin({\n  deriv(S) &lt;- -beta * S * I / N\n  deriv(I) &lt;- beta * S * I / N - gamma * I\n  deriv(R) &lt;- gamma * I\n\n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  initial(R) &lt;- 0\n\n  N &lt;- parameter(1000)\n  I0 &lt;- parameter(10)\n  beta &lt;- parameter(0.2)\n  gamma &lt;- parameter(0.1)\n})\nThere are a few things to note here:\nThe odin() function will compile (more strictly, transpile) the odin code to C++ and then compile this into machine code and load it into your session. The resulting object is a dust_sytem_generator object:\nsir\n#&gt; \n#&gt; ── &lt;dust_system_generator: odin_system&gt; ────────────────────────────────────────\n#&gt; ℹ This system runs in continuous time\n#&gt; ℹ This system has 4 parameters\n#&gt; → 'N', 'I0', 'beta', and 'gamma'\n#&gt; ℹ Use dust2::dust_system_create() (`?dust2::dust_system_create()`) to create a system with this generator\n#&gt; ℹ Use coef() (`?stats::coef()`) to get more information on parameters\nAs its name suggests, we can use this object to generate different versions of our system with different configurations. We pass this object to other functions from dust2 to create, run and examine our simulations.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with odin</span>"
    ]
  },
  {
    "objectID": "odin.html#sec-odin-sir",
    "href": "odin.html#sec-odin-sir",
    "title": "1  Getting started with odin",
    "section": "",
    "text": "equations are defined out of order; we just will things into existence and trust odin to put them in the right order for us (much more on this later)\nour system has “parameters”; these are things we’ll be able to change easily in it after creation\nevery variable (as in, model variable — those that make up the state) has a pair of equations; an initial condition via initial() and an equation for the derivative with respect to time via deriv()\n\n\n\n\n\n\n\nNote\n\n\n\nAbove you will see us struggle a bit with terminology, particularly between “system” and “model”. There are going to be two places where “model” can be usefully used - a model could be the generative model (here an SIR model) or it could be the statistical model, more the focus on the second half of the book. In order to make things slightly less ambiguous we will often refer to the generative model as a “system”, and this is reflected in the calls to functions in dust.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with odin</span>"
    ]
  },
  {
    "objectID": "odin.html#running-systems-using-dust2",
    "href": "odin.html#running-systems-using-dust2",
    "title": "1  Getting started with odin",
    "section": "1.2 Running systems using dust2",
    "text": "1.2 Running systems using dust2\n\nlibrary(dust2)\n\nWe create a system by using dust_system_create and passing in a list of parameters:\n\npars &lt;- list()\nsys &lt;- dust_system_create(sir, pars)\nsys\n#&gt; \n#&gt; ── &lt;dust_system: odin_system&gt; ──────────────────────────────────────────────────\n#&gt; ℹ single particle with 3 states\n#&gt; ℹ This system runs in continuous time\n#&gt; ℹ This system has 4 parameters that can be updated via `dust_system_update_pars`\n#&gt; → 'N', 'I0', 'beta', and 'gamma'\n#&gt; ℹ Use coef() (`?stats::coef()`) to get more information on parameters\n\nTo interact with a system, you will use functions from dust2, which we’ll show below.\nAll systems start off with a state of all zeros:\n\ndust_system_state(sys)\n#&gt; [1] 0 0 0\n\nThere are two ways of setting state:\n\nProvide a new state vector and set it with dust_system_set_state\nUse the initial condition from the model itself (the expressions with initial() on the left hand side)\n\nHere, we’ll use the latter, and use the initial condition defined in the odin code:\n\ndust_system_set_state_initial(sys)\ndust_system_state(sys)\n#&gt; [1] 990  10   0\n\nIn general, the order of the state is arbitrary (though in practice it is fairly stable). To turn this state vector into something more interpretable you can use dust_unpack_state:\n\ns &lt;- dust_system_state(sys)\ndust_unpack_state(sys, s)\n#&gt; $S\n#&gt; [1] 990\n#&gt; \n#&gt; $I\n#&gt; [1] 10\n#&gt; \n#&gt; $R\n#&gt; [1] 0\n\nThis gives a named list of numbers, which means we can work with the output of the model in a more reasonable way.\nNext, we want to run the system. There are two main functions for doing this:\n\ndust_system_run_to_time which runs the system up to some point in time, but returns nothing\ndust_system_simulate which runs the system over a series of points in time and returns the state at these points in time\n\nHere we’ll do the latter as it will produce something we can look at!\n\nt &lt;- seq(0, 150, by = 0.25)\ny &lt;- dust_system_simulate(sys, t)\ndim(y)\n#&gt; [1]   3 601\n\nThis produces a 3 x 601 matrix. This is typical of how time-series data are produced from odin2/dust2 and may be a surprise:\n\nstate will always be on the first dimension\ntime will always be on the last dimension\n\nThis may take some getting used to at first, but practically some degree of manipulation will be required in any case if you want to plot things.\nWe’ll explore some other ways of plotting later, but here’s the number of individuals in the infectious class over time, as the epidemic proceeds.\n\nplot(t, dust_unpack_state(sys, y)$I, type = \"l\",\n     xlab = \"Time\", ylab = \"Infected population\")\n\n\n\n\n\n\n\n\nOnce a system has been run to a time, you’ll need to reset it to run it again. For example, this won’t work\n\ndust_system_simulate(sys, t)\n#&gt; Error: Expected 'time[1]' (0) to be larger than the previous value (150)\n\nThe error here is trying to tell us that the first time in our vector t, which is 0, is smaller than the current time in the system, which is 150. We can query the system to get its current time, too:\n\ndust_system_time(sys)\n#&gt; [1] 150\n\nYou can reset the time back to zero (or any other time) using dust_system_set_time:\n\ndust_system_set_time(sys, 0)\n\nthis does not reset the state, however:\n\ndust_system_state(sys)\n#&gt; [1] 200.2910254   0.7422209 798.9667537\n\nWe can set new parameters, perhaps, and then update the state:\n\ndust_system_update_pars(sys, list(I0 = 5))\ndust_system_set_state_initial(sys)\ndust_system_state(sys)\n#&gt; [1] 995   5   0",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with odin</span>"
    ]
  },
  {
    "objectID": "odin.html#going-further",
    "href": "odin.html#going-further",
    "title": "1  Getting started with odin",
    "section": "1.3 Going further",
    "text": "1.3 Going further\nThese are the lowest-level functions you would typically use, and we expect that you would combine these together yourself to perform specific tasks. For example suppose you wanted to explore how beta affected the epidemic trajectory over this set of times, we might write:\n\nrun_with_beta &lt;- function(beta, t) {\n  sys &lt;- dust_system_create(sir, list(beta = beta))\n  dust_system_set_state_initial(sys)\n  idx &lt;- dust_unpack_index(sys)$I\n  drop(dust_system_simulate(sys, t, index_state = idx))\n}\n\nHere, we’ve used dust_unpack_index to get the index of the I compartment and passed that in as the index to dust_system_simulate.\nWe could then run this over a series of beta values:\n\nbeta &lt;- seq(0.1, 0.3, by = 0.02)\ny &lt;- vapply(beta, run_with_beta, t, FUN.VALUE = numeric(length(t)))\nmatplot(t, y, type = \"l\", lty = 1, col = \"steelblue4\",\n        xlab = \"Time\", ylab = \"Infected population\")\n\n\n\n\n\n\n\n\nWe could modify this to take a single system object and reset it each time (which might be useful if our model was slow to initialise). Alternatively we could simulate the whole grid of beta values at once:\n\npars &lt;- lapply(beta, function(b) list(beta = b))\nsys &lt;- dust_system_create(sir, pars, n_groups = length(pars))\ndust_system_set_state_initial(sys)\nidx &lt;- dust_unpack_index(sys)$I\ny &lt;- dust_system_simulate(sys, t, index_state = idx)\nmatplot(t, t(y[1, , ]), type = \"l\", lty = 1, col = \"steelblue4\",\n        xlab = \"Time\", ylab = \"Infected population\")\n\n\n\n\n\n\n\n\nOr perhaps you would want to combine these approaches and start the simulation from a range of stochastic starting points. Given the unbounded range of things people want to do with dynamical models, the hope is that you can use the functions in dust2 in order to build workflows that match your needs, and that these functions should be well documented and efficient.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with odin</span>"
    ]
  },
  {
    "objectID": "time.html",
    "href": "time.html",
    "title": "2  On the nature of time",
    "section": "",
    "text": "2.1 A simple example where time matters\nThere are two main sorts of treatment of time within odin models:\nContinuous time models, as seen in the previous chapter, are described in terms of a set of ordinary differential equations (ODEs). At any point in time we can compute the rates of change of our quantity of interest, and using that and some initial condition, we can generate a time-series of the quantity or quantities involved.\nDiscrete time models, which will be the focus of the next section, are both more basic and more complicated depending on how you approach them. We assume that the system takes steps of some size dt and our equations will describe how each variable is updated – how it changes from a value at time t to time t + dt. Sometimes this formulation is called a set of “recurrence equations”.\nThis seems like a small difference but it is quite profound.\nlibrary(odin2)\nlibrary(dust2)\nConsider just about the simplest interesting “system” of ODEs, the logistic equation:\nlogistic_ode &lt;- odin({\n  deriv(x) &lt;- r * x * (1 - x)\n  initial(x) &lt;- x0\n  x0 &lt;- parameter(0.01)\n  r &lt;- parameter(0.1)\n}, debug = TRUE)\nlogistic_ode\n#&gt; \n#&gt; ── &lt;dust_system_generator: odin_system&gt; ────────────────────────────────────────\n#&gt; ℹ This system runs in continuous time\n#&gt; ℹ This system has 2 parameters\n#&gt; → 'x0' and 'r'\n#&gt; ℹ Use dust2::dust_system_create() (`?dust2::dust_system_create()`) to create a system with this generator\n#&gt; ℹ Use coef() (`?stats::coef()`) to get more information on parameters\nAs in Section 1.1, we can run this through time from its initial conditions:\nsys &lt;- dust_system_create(logistic_ode, list())\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 100, by = 1)\ny &lt;- dust_system_simulate(sys, t)\nplot(t, y[1, ], type = \"l\", xlab = \"Time\", ylab = \"Population\")\nNow, we write out a closely related system which uses discrete time; the “logistic map”\nlogistic_map &lt;- odin({\n  update(x) &lt;- r * x * (1 - x)\n  initial(x) &lt;- x0\n  x0 &lt;- parameter(0.01)\n  r &lt;- parameter(1.1)\n}, debug = TRUE)\nand run it:\nsys2 &lt;- dust_system_create(logistic_map, list())\ndust_system_set_state_initial(sys2)\ny2 &lt;- dust_system_simulate(sys2, t)\nplot(t, y[1, ], type = \"l\", xlab = \"Time\", ylab = \"Population\")\nlines(t, y2[1, ], col = \"red\")\nLet’s write a function for this:\nrun &lt;- function(r, sys, t) {\n  dust_system_update_pars(sys, list(r = r))\n  dust_system_set_time(sys, 0)\n  dust_system_set_state_initial(sys)\n  dust_system_simulate(sys, t)[1, ]\n}\nWe can run this function for some small values of r and see the population go extinct (black line) or grow to some stable value (red lines)\nplot(t, run(0.5, sys2, t), col = \"black\", ylim = 0:1, type = \"l\",\n     xlab = \"Time\", ylab = \"Population\")\nlines(t, run(1.5, sys2, t), col = \"red\")\nlines(t, run(1.8, sys2, t), col = \"red\")\nlines(t, run(2, sys2, t), col = \"red\")\nThe equilibrium level of the discrete time system is not 0 or 1 (as in the continuous time version) but (r - 1) / r.\nFor larger values of r we start getting oscillations around the maximum, either decaying (blue lines) or stable (green line):\nplot(t, run(2.1, sys2, t), col = \"blue\", ylim = 0:1, type = \"l\",\n     xlab = \"Time\", ylab = \"Population\")\nlines(t, run(2.5, sys2, t), col = \"blue\")\nlines(t, run(2.9, sys2, t), col = \"blue\")\nlines(t, run(3.3, sys2, t), col = \"green\")\nHigher values bounce around chaotically:\nplot(t, run(3.8, sys2, t), ylim = 0:1, type = \"l\",\n     xlab = \"Time\", ylab = \"Population\")\nNone of these dynamics appeared in the continuous time version!",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>On the nature of time</span>"
    ]
  },
  {
    "objectID": "time.html#sec-reset-variables",
    "href": "time.html#sec-reset-variables",
    "title": "2  On the nature of time",
    "section": "2.2 Variables that reset",
    "text": "2.2 Variables that reset\nLet’s revisit our simple SIR example from Section 1.1. Our model had just three compartments; S, I and R. These all represent prevalences, but frequently we are interested in incidences, for example the incidence of new infections or cases. This might be because we want to fit to data that are incidences, or it might just be that we want to run projections of a model and output incidences over time.\nIn some simple models it might be easy enough to extract incidences given outputs on all states of the model, but with increasingly complexity this calculation quickly becomes overly complicated or even impossible. Thus we support calculating incidences within your odin code.\nSuppose that each time unit represents one day. We can declare incidence as a variable that resets every day by using the zero_every argument.\n\nsir &lt;- odin({\n  deriv(S) &lt;- -beta * S * I / N\n  deriv(I) &lt;- beta * S * I / N - gamma * I\n  deriv(R) &lt;- gamma * I\n  deriv(incidence) &lt;- beta * S * I / N\n\n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  initial(R) &lt;- 0\n  initial(incidence, zero_every = 1) &lt;- 0\n\n  N &lt;- parameter(1000)\n  I0 &lt;- parameter(10)\n  beta &lt;- parameter(0.2)\n  gamma &lt;- parameter(0.1)\n})\n\nIf we were interested in weekly incidence we might choose to write\ninitial(incidence, zero_every = 7) &lt;- 0\nor to work with time so that one unit represents a week rather than a day and scaling our rates accordingly.\n\n\n\n\n\n\nNote\n\n\n\nVariables reset on multiples of the value of zero_every, and it is not currently possible to have this offset. If zero_every = 7 the variable would reset only on multiples of 7 - so if you were dealing with weekly data, you would have to be careful to set time-zero in such a way that your weekly data aligns on multiples of 7!\n\n\nWhen running this model we’ll see incidence produced:\n\npars &lt;- list(beta = 1, gamma = 0.6)\nsys &lt;- dust_system_create(sir, pars)\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 20, by = 0.05)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\nplot(t, y$incidence, type = \"s\", xlab = \"Time\", ylab = \"Incidence\")\n\n\n\n\n\n\n\n\nWe have output at intervals of one 20th of a day, so we see 20 levels of incidence per day, with the last being the daily peak. If we output instead at intervals of one day, we only get those peaks corresponding to the daily incidence\n\nsys &lt;- dust_system_create(sir, pars)\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 20)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\nplot(t, y$incidence, type = \"p\", xlab = \"Time\", ylab = \"Incidence\")\n\n\n\n\n\n\n\n\nWe will see that resetting variables works in a similar fashion for discrete-time models in Chapter 3.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>On the nature of time</span>"
    ]
  },
  {
    "objectID": "stochasticity.html",
    "href": "stochasticity.html",
    "title": "3  Stochasticity",
    "section": "",
    "text": "3.1 Discrete-time\nEverybody get random\nOne of the key motivations for discrete time models is that they allow a natural mechanism for using stochasticity. By including stochasticity in our models we can better capture things like demographic effects where random fluctuations when population sizes are small have profound consequences for the longer term dynamics. In a deterministic system, things always happen the same way when you run them multiple times, but in a stochastic system – especially nonlinear ones – small changes in how the system arranges itself in its early steps can result in large changes in the dynamics later on, and this can help describe observed dynamics better.\nStochastic models can be constructed in continuous-time. However, running realisations of such models is computationally expensive and becomes prohibitively so with increasing model complexity. Typically every time an event changes the state of the model (e.g. an infection or a recovery), the distribution of the time to the next event changes along with the probabilities governing the next event.\nIn odin we support discrete-time stochastic models as they are less expensive than continuous-time models as we just have to update the state of the model at a finite number of fixed time points. Models are updated at increments of dt, which currently must be the inverse of an integer (we recommend it be a non-recurring decimal, e.g. 1, 0.5, 0.25, 0.2, 0.125, 0.1 etc).\nFor the discrete-time stochastic models to be implemented in odin, they must follow the Markov property - given the entire history of the model up until time t, the distribution of the state at time t + dt must only depend upon the state of the model at time t.\nlibrary(odin2)\nlibrary(dust2)",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Stochasticity</span>"
    ]
  },
  {
    "objectID": "stochasticity.html#discrete-time",
    "href": "stochasticity.html#discrete-time",
    "title": "3  Stochasticity",
    "section": "",
    "text": "Note\n\n\n\nIf you have used odin version 1, you will see that the interface for stochastic models has changed, and we no longer use functions named after R’s random functions. For example we now use Normal() rather than rnorm to refer to the normal distribution. See the odin2 migration vignette for more details.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Stochasticity</span>"
    ]
  },
  {
    "objectID": "stochasticity.html#sec-stochastic-sir",
    "href": "stochasticity.html#sec-stochastic-sir",
    "title": "3  Stochasticity",
    "section": "3.2 A simple stochastic model",
    "text": "3.2 A simple stochastic model\nHere’s a simple SIR model, based on the one in Section 1.1, but which is stochastic:\n\nsir &lt;- odin({\n  update(S) &lt;- S - n_SI\n  update(I) &lt;- I + n_SI - n_IR\n  update(R) &lt;- R + n_IR\n  update(incidence) &lt;- incidence + n_SI\n\n  p_SI &lt;- 1 - exp(-beta * I / N * dt)\n  p_IR &lt;- 1 - exp(-gamma * dt)\n  n_SI &lt;- Binomial(S, p_SI)\n  n_IR &lt;- Binomial(I, p_IR)\n\n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  initial(R) &lt;- 0\n  initial(incidence, zero_every = 1) &lt;- 0\n\n  N &lt;- parameter(1000)\n  I0 &lt;- parameter(10)\n  beta &lt;- parameter(0.2)\n  gamma &lt;- parameter(0.1)\n})\n\nThis is a discrete-time model (using update() and not deriv()) as stochastic models must run in discrete time. We use dt to scale the rates, and adjusting dt will change the way that stochasticity affects the dynamics of the system.\nThe call to Binomial() samples from a binomial distribution, returning the number of successes from S (or I) draws, each with probability p_SI (or p_IR).\n\nsir\n#&gt; \n#&gt; ── &lt;dust_system_generator: odin_system&gt; ────────────────────────────────────────\n#&gt; ℹ This system runs in discrete time with a default dt of 1\n#&gt; ℹ This system has 4 parameters\n#&gt; → 'N', 'I0', 'beta', and 'gamma'\n#&gt; ℹ Use dust2::dust_system_create() (`?dust2::dust_system_create()`) to create a system with this generator\n#&gt; ℹ Use coef() (`?stats::coef()`) to get more information on parameters\n\nThe movement from S to I and from I to R are now drawn from a binomial distribution with probabilities that are computed from the rates (beta and gamma) multiplied by the change in time (dt). Some care is required to make sure that we subtract the same number of individuals from S as we add to I so we save this number as n_SI.\nWe can run this model just like before:\n\nsys &lt;- dust_system_create(sir, list())\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 100)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\n\nHere is the number of infected individuals over time:\n\nplot(t, y$I, type = \"l\", xlab = \"Time\", ylab = \"Infected population\")\n\n\n\n\n\n\n\n\nAs in Section 1.1, we see an epidemic start, increase and then decay. Unlike the deterministic version though, the trajectory is not smooth, and it will be different each time we run it.\nYou can pass an argument n_particles when creating a system (the default is 1) to simulate multiple independent realisations at once:\n\nsys &lt;- dust_system_create(sir, list(), n_particles = 50)\ndust_system_set_state_initial(sys)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\nmatplot(t, t(y$I), type = \"l\", lty = 1, col = \"#00000044\",\n        xlab = \"Time\", ylab = \"Infected population\")\n\n\n\n\n\n\n\n\nHere, we simulate 50 particles at once, all from the same point (10 individuals infected at time 0) and we see the similarities and differences in the trajectories: all follow approximately the same shape, and all rise and fall at approximately the same rate, but there is quite a bit of difference in the individual trajectories and the timings of when the epidemic peaks.\n\n\n\n\n\n\nNote\n\n\n\nThe t() in plotting here moves time from the last dimension to the first, as is expected by matplot. We may write functions to help prepare output for plotting.\n\n\nThe stochastic effects will be stronger around the critical parameter values where the behaviour of the model diverges, or with smaller initial population sizes:\n\nsys &lt;- dust_system_create(sir, list(I0 = 5, gamma = 0.15), n_particles = 50)\ndust_system_set_state_initial(sys)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\nmatplot(t, t(y$I), type = \"l\", lty = 1, col = \"#00000044\",\n        xlab = \"Time\", ylab = \"Infected population\")\n\n\n\n\n\n\n\n\nHere, we see some epidemics fail to take off, and a huge variation in where the peak is, with some trajectories only starting to take off at time 100 where in the previous example all were in decline.\nWe can see we have used zero_every to calculate the incidence of new infections in discrete-time in a similar way to how we did in the continuous-time deterministic model in Section 2.2.\nRunning the model we see the incidence produced:\n\npars &lt;- list(beta = 1, gamma = 0.6)\nsys &lt;- dust_system_create(sir, pars, dt = 0.25)\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 20, by = 0.25)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\nplot(t, y$incidence, type = \"s\", xlab = \"Time\", ylab = \"Incidence\")\n\n\n\n\n\n\n\n\nOur step is a quarter of a day, so we see four levels of incidence per day, with the last being the daily peak. Let’s run again, this time outputting only every day, we see:\n\nsys &lt;- dust_system_create(sir, pars, dt = 0.25)\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 20)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\nplot(t, y$incidence, type = \"p\", xlab = \"Time\", ylab = \"Incidence\")",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Stochasticity</span>"
    ]
  },
  {
    "objectID": "stochasticity.html#supported-random-number-functions",
    "href": "stochasticity.html#supported-random-number-functions",
    "title": "3  Stochasticity",
    "section": "3.3 Supported random number functions",
    "text": "3.3 Supported random number functions\nWe have already seen use of Binomial draws, and we support other distributions. Support for the distributions includes both random draws and density calculations (more on that later). The support for these functions comes from monty and all the distributions are available for use in the both the odin DSL and the monty DSL (more on that also later).\nSome distributions have several parametrisations; these are distinguished by the arguments to the functions. These distributions have a default parametrisation. For example, the Gamma distribution defaults to a shape and rate parametrisation so:\na &lt;- Gamma(2, 0.1)\na &lt;- Gamma(shape = 2, rate = 0.1)\ndraw from a Gamma distribution with a shape of 2 and a rate of 0.1, while\na &lt;- Gamma(2, scale = 10)\na &lt;- Gamma(shape = 2, scale = 10)\ndraw from a Gamma distribution with a shape of 2 and a scale of 10. You may find it is good practice to specify your arguments with such distributions whether using the default parameterisation or not.\nOther supported distributions include the Normal, Uniform, Exponential, Beta and Poisson distributions. A full list of supported distributions and their parametrisations can be found here.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Stochasticity</span>"
    ]
  },
  {
    "objectID": "stochasticity.html#more-sections-to-add",
    "href": "stochasticity.html#more-sections-to-add",
    "title": "3  Stochasticity",
    "section": "3.4 More sections to add:",
    "text": "3.4 More sections to add:\n\nSeeding\nSomething on threads and parallelism\nStochastic quantities vary over time",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Stochasticity</span>"
    ]
  },
  {
    "objectID": "arrays.html",
    "href": "arrays.html",
    "title": "4  Arrays",
    "section": "",
    "text": "4.1 When scalars are just not enough\nThe aim of this section is to show you how you use odin’s array syntax, via some motivating examples. The examples here are necessarily a bit longer than in the previous sections because we will generally need a few more moving parts.\nlibrary(odin2)\nlibrary(dust2)",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "arrays.html#example-a-two-group-age-structured-sir-model",
    "href": "arrays.html#example-a-two-group-age-structured-sir-model",
    "title": "4  Arrays",
    "section": "4.2 Example: a two-group age structured SIR model",
    "text": "4.2 Example: a two-group age structured SIR model\nLet’s take the simple stochastic SIR model from Section 3.2 and add age structure to it by having two groups (children and adults), with heterogeneous mixing between the groups.\n\nsir &lt;- odin({\n  \n  # Equations for transitions between compartments by age group\n  update(S[]) &lt;- S[i] - n_SI[i]\n  update(I[]) &lt;- I[i] + n_SI[i] - n_IR[i]\n  update(R[]) &lt;- R[i] + n_IR[i]\n  update(incidence) &lt;- incidence + n_SI[1] + n_SI[2]\n  \n  # Individual probabilities of transition:\n  \n  p_SI[] &lt;- 1 - exp(-lambda[i] * dt) # S to I\n  p_IR &lt;- 1 - exp(-gamma * dt) # I to R\n  \n  # Calculate force of infection\n  \n  # age-structured contact matrix: m[i, j] is mean number of contacts an\n  # individual in group i has with an individual in group j per time unit\n  \n  m &lt;- parameter()\n  \n  # here s_ij[i, j] gives the mean number of contacts and individual in group\n  # i will have with the currently infectious individuals of group j\n  s_ij[, ] &lt;- m[i, j] * I[j]\n  \n  # lambda[i] is the total force of infection on an individual in group i \n  lambda[] &lt;- beta * (s_ij[i, 1] + s_ij[i, 2])\n  \n  # Draws from binomial distributions for numbers changing between\n  # compartments:\n  \n  n_SI[] &lt;- Binomial(S[i], p_SI[i])\n  n_IR[] &lt;- Binomial(I[i], p_IR)\n  \n  initial(S[]) &lt;- S0[i]\n  initial(I[]) &lt;- I0[i]\n  initial(R[]) &lt;- 0\n  initial(incidence, zero_every = 1) &lt;- 0\n  \n  # User defined parameters - default in parentheses:\n  S0 &lt;- parameter()\n  I0 &lt;- parameter()\n  beta &lt;- parameter(0.0165)\n  gamma &lt;- parameter(0.1)\n  \n  # Dimensions of arrays\n  dim(S0) &lt;- 2\n  dim(I0) &lt;- 2\n  dim(S) &lt;- 2\n  dim(I) &lt;- 2\n  dim(R) &lt;- 2\n  dim(n_SI) &lt;- 2\n  dim(n_IR) &lt;- 2\n  dim(p_SI) &lt;- 2\n  dim(m) &lt;- c(2, 2)\n  dim(s_ij) &lt;- c(2, 2)\n  dim(lambda) &lt;- 2\n})\n\nIn the odin code above\nupdate(S[]) &lt;- S[i] - n_SI[i]\nbecomes (approximately)\nfor (int i = 0; i &lt; S_length; ++i) {\n  update_S[i] = S[i] + n_SI[i];\n}\nso there is an implicit indexing by i on the LHS in that equation of the odin code, and the generated code will then produce a for loop over all values of i.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "arrays.html#declaring-dimensions",
    "href": "arrays.html#declaring-dimensions",
    "title": "4  Arrays",
    "section": "4.3 Declaring dimensions",
    "text": "4.3 Declaring dimensions\nWe can see in our first example that it is necessary to declare the dimensions of all arrays within your odin code using a dim equation.\nDimensions can be hard-coded:\ndim(S) &lt;- 2\nor can be generalised so that the dimensions themselves become parameters:\ndim(S) &lt;- n_age\nn_age &lt;- parameter()\nYou may have array parameters, these can have dimensions explicitly declared\ndim(m) &lt;- c(n_age, n_age)\nor they can also have their dimensions detected when the parameters are passed into the system - this still needs a dim equation where you must explicitly state the rank:\ndim(m) &lt;- parameter(rank = 2)\nYou can also declare the dimensions of one array to be the same as the dimensions of another:\ndim(m) &lt;- c(n_age, n_age)\ndim(s_ij) &lt;- dim(m)\nor collectively declare dimensions of arrays that have the same dimensions:\ndim(m, s_ij) &lt;- c(n_age, n_age)",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "arrays.html#summing-over-arrays",
    "href": "arrays.html#summing-over-arrays",
    "title": "4  Arrays",
    "section": "4.4 Summing over arrays",
    "text": "4.4 Summing over arrays\nFrequently, you will want to take a sum over an array, or part of an array, using sum. To sum over all elements of an array, use sum() with the name of the array you would like to sum over:\ndim(x) &lt;- 10\nx_tot &lt;- sum(x)\nIf m is a matrix you can compute the sums over the second column by writing:\nm1_tot &lt;- sum(m[, 2])\nThis partial sum approach is frequently used within implicit loops:\nm_col_totals[] &lt;- sum(m[, i])\nIn our example we calculated the force of infection by summing over the two age groups\nlambda[] &lt;- beta * (s_ij[i, 1] + s_ij[i, 2])\nso we could have used sum to write this as\nlambda[] &lt;- beta * sum(s_ij[i, ])\nand this equation has been generalised to any number of age groups now!\n\n\n\n\n\n\nNote\n\n\n\nThe same syntax applies to other functions that reduce arrays: min, max and prod.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "arrays.html#sec-stochastic-age",
    "href": "arrays.html#sec-stochastic-age",
    "title": "4  Arrays",
    "section": "4.5 Example: a generalised age structured SIR model",
    "text": "4.5 Example: a generalised age structured SIR model\nLet’s now take the two group SIR model and generalise it to n_age age groups\n\nsir_age &lt;- odin({\n  # Equations for transitions between compartments by age group\n  update(S[]) &lt;- S[i] - n_SI[i]\n  update(I[]) &lt;- I[i] + n_SI[i] - n_IR[i]\n  update(R[]) &lt;- R[i] + n_IR[i]\n  update(incidence) &lt;- incidence + sum(n_SI)\n  \n  # Individual probabilities of transition:\n  p_SI[] &lt;- 1 - exp(-lambda[i] * dt) # S to I\n  p_IR &lt;- 1 - exp(-gamma * dt) # I to R\n  \n  # Calculate force of infection\n  \n  # age-structured contact matrix: m[i, j] is mean number of contacts an\n  # individual in group i has with an individual in group j per time unit\n  \n  m &lt;- parameter()\n  \n  # here s_ij[i, j] gives the mean number of contacts and individual in group\n  # i will have with the currently infectious individuals of group j\n  s_ij[, ] &lt;- m[i, j] * I[j]\n  \n  # lambda[i] is the total force of infection on an individual in group i \n  lambda[] &lt;- beta * sum(s_ij[i, ])\n  \n  # Draws from binomial distributions for numbers changing between\n  # compartments:\n  n_SI[] &lt;- Binomial(S[i], p_SI[i])\n  n_IR[] &lt;- Binomial(I[i], p_IR)\n  \n  initial(S[]) &lt;- S0[i]\n  initial(I[]) &lt;- I0[i]\n  initial(R[]) &lt;- 0\n  initial(incidence, zero_every = 1) &lt;- 0\n  \n  # User defined parameters - default in parentheses:\n  S0 &lt;- parameter()\n  I0 &lt;- parameter()\n  beta &lt;- parameter(0.0165)\n  gamma &lt;- parameter(0.1)\n  \n  # Dimensions of arrays\n  n_age &lt;- parameter()\n  dim(S, S0, n_SI, p_SI) &lt;- n_age\n  dim(I, I0, n_IR) &lt;- n_age\n  dim(R) &lt;- n_age\n  dim(m, s_ij) &lt;- c(n_age, n_age)\n  dim(lambda) &lt;- n_age\n})\n\n\n\n\n\n\n\nNote\n\n\n\nWith the equations\ns_ij[, ] &lt;- m[i, j] * I[j]\nlambda[] &lt;- beta * sum(s_ij[i, ])\nwhat we are really doing is matrix multiplication, and in R this would be\nlambda &lt;- beta * (m %*% I)\nWe are aiming to support matrix multiplication in future to help simplify this code.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "arrays.html#indexing",
    "href": "arrays.html#indexing",
    "title": "4  Arrays",
    "section": "4.6 Indexing",
    "text": "4.6 Indexing\nWe have seen in the above examples uses of 1-dimensions and 2-dimensional arrays, making use of index variables i and j. Note that while we never use these index variables on the LHS, it is implicit that on the LHS we are indexing by i for 1-dimensional arrays and i and j for 2-dimensional arrays! Use of these index variables on the RHS corresponds to the indexing on the LHS.\nOf course you may want to use higher-dimensional arrays! We currently supporting up to 8 dimensions, with index variables i, j, k, l, i5, i6, i7 and i8.\nBe careful with array equations! It’s possible that in an array equation you end up going out of bounds with an array used on the RHS. This can crash the program when running.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "arrays.html#sec-age-vax",
    "href": "arrays.html#sec-age-vax",
    "title": "4  Arrays",
    "section": "4.7 Example: an age-structured SIR model with vaccination",
    "text": "4.7 Example: an age-structured SIR model with vaccination\nLet’s take the above model and additionally add some vaccination to it.\n\n\n\n\n\n\nNote\n\n\n\nThis should not be considered a guide on how to model vaccination with odin, as it merely presents one model for the purposes of illustrating how arrays work in odin - there are many other ways one could model vaccination!\n\n\n\nsir_age_vax &lt;- odin({\n  # Equations for transitions between compartments by age group\n  update(S[, ]) &lt;- new_S[i, j]\n  update(I[, ]) &lt;- I[i, j] + n_SI[i, j] - n_IR[i, j]\n  update(R[, ]) &lt;- R[i, j] + n_IR[i, j]\n  update(incidence) &lt;- incidence + sum(n_SI)\n  \n  # Individual probabilities of transition:\n  p_SI[, ] &lt;- 1 - exp(-rel_susceptibility[j] * lambda[i] * dt) # S to I\n  p_IR &lt;- 1 - exp(-gamma * dt) # I to R\n  p_vax[, ] &lt;- 1 - exp(-eta[i, j] * dt)\n  \n  # Force of infection\n  m &lt;- parameter() # age-structured contact matrix\n  s_ij[, ] &lt;- m[i, j] * sum(I[j, ])\n  lambda[] &lt;- beta * sum(s_ij[i, ])\n  \n  # Draws from binomial distributions for numbers changing between\n  # compartments:\n  n_SI[, ] &lt;- Binomial(S[i, j], p_SI[i, j])\n  n_IR[, ] &lt;- Binomial(I[i, j], p_IR)\n  \n  # Nested binomial draw for vaccination in S\n  # Assume you cannot move vaccine class and get infected in same step\n  n_S_vax[, ] &lt;- Binomial(S[i, j] - n_SI[i, j], p_vax[i, j])\n  new_S[, 1] &lt;- S[i, j] - n_SI[i, j] - n_S_vax[i, j] + n_S_vax[i, n_vax]\n  new_S[, 2:n_vax] &lt;- S[i, j] - n_SI[i, j] - n_S_vax[i, j] + n_S_vax[i, j - 1]\n  \n  initial(S[, ]) &lt;- S0[i, j]\n  initial(I[, ]) &lt;- I0[i, j]\n  initial(R[, ]) &lt;- 0\n  initial(incidence, zero_every = 1) &lt;- 0\n  \n  # User defined parameters - default in parentheses:\n  S0 &lt;- parameter()\n  I0 &lt;- parameter()\n  beta &lt;- parameter(0.0165)\n  gamma &lt;- parameter(0.1)\n  eta &lt;- parameter()\n  rel_susceptibility &lt;- parameter()\n  \n  # Dimensions of arrays\n  n_age &lt;- parameter()\n  n_vax &lt;- parameter()\n  dim(S, S0, n_SI, p_SI) &lt;- c(n_age, n_vax)\n  dim(I, I0, n_IR) &lt;- c(n_age, n_vax)\n  dim(R) &lt;- c(n_age, n_vax)\n  dim(m, s_ij) &lt;- c(n_age, n_age)\n  dim(lambda) &lt;- n_age\n  dim(eta) &lt;- c(n_age, n_vax)\n  dim(rel_susceptibility) &lt;- c(n_vax)\n  dim(p_vax, n_S_vax, new_S) &lt;- c(n_age, n_vax)\n})\n\nWe see we can use multiple lines to deal with boundary conditions:\nnew_S[, 1] &lt;- S[i, j] - n_SI[i, j] - n_S_vax[i, j] + n_S_vax[i, n_vax]\nnew_S[, 2:n_vax] &lt;- S[i, j] - n_SI[i, j] - n_S_vax[i, j] + n_S_vax[i, j - 1]\nwhich we could also write as\nnew_S[, ] &lt;- S[i, j] - n_SI[i, j] - n_S_vax[i, j]\nnew_S[, 1] &lt;- new_S[i, j] + n_S_vax[i, n_vax]\nnew_S[, 2:n_vax] &lt;- new_S[i, j] + n_S_vax[i, j - 1]\nor another alternative way of writing this would be to use if else\nnew_S[, ] &lt;- S[i, j] - n_SI[i, j] - n_S_vax[i, j] +\n    (if (j == 1) n_S_vax[i, n_vax] else n_S_vax[i, j - 1])\nNote that in odin, an if always requires an else!",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "arrays.html#semantics-of-random-number-draws",
    "href": "arrays.html#semantics-of-random-number-draws",
    "title": "4  Arrays",
    "section": "4.8 Semantics of random number draws",
    "text": "4.8 Semantics of random number draws\nStochastic functions are called for each element in an array they are assigned to, at each time. So here:\nx[] &lt;- Normal(0, 1)\nx will be filled with each element having a different draw from a standard normal. In contrast, in:\na &lt;- Normal(0, 1)\nx[] &lt;- a\nx will be a vector where every element is the same, the result of a single draw from a standard normal.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "arrays.html#using-arrays-for-erlang-durations",
    "href": "arrays.html#using-arrays-for-erlang-durations",
    "title": "4  Arrays",
    "section": "4.9 Using arrays for Erlang durations",
    "text": "4.9 Using arrays for Erlang durations\nIn our examples we have assumed that infectious periods follow a discretised exponential distribution (rounded up to the nearest dt), for instance in Section 4.7 we see this in the equations governing movement from I to R:\np_IR &lt;- 1 - exp(-gamma * dt) # I to R\nn_IR[, ] &lt;- Binomial(I[i, j], p_IR)\n\nupdate(I[, ]) &lt;- I[i, j] + n_SI[i, j] - n_IR[i, j]\nupdate(R[, ]) &lt;- R[i, j] + n_IR[i, j]\n\ndim(I, I0, n_IR) &lt;- c(n_age, n_vax)\nHowever, exponential distributions often do not capture the true distribution of infectious periods or other such delays you may be interested in modelling. Arrays in odin can be used to implement (discretised) Erlang distributions by breaking them down into stages of iid exponential distributions by adding a dimension to an array corresponding to these stages. For instance we could generalise the above to an Erlang with shape parameter k_I (the number of stages) and rate gamma:\nk_I &lt;- parameter()\np_I_progress &lt;- 1 - exp(-gamma * dt)\nn_I_progress[, , ] &lt;- Binomial(I[i, j, k], p_I_progress)\n\nupdate(I[, , ]) &lt;- I[i, j, k] - n_I_progress[i, j, k] +\n  (if (k == 1) n_SI[i, j] else n_I_progress[i, j, k - 1])\nupdate(R[, ]) &lt;- R[i, j] + n_I_progress[i, j, k_I]\ndim(I, I0, n_I_progress) &lt;- c(n_age, n_vax, k_I)\nand there would be some other bits we’d need to change to deal with the increased dimensionality of I:\ns_ij[, ] &lt;- m[i, j] * sum(I[j, ,])\ninitial(I[, , ]) &lt;- I0[i, j, k]",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "interpolation.html",
    "href": "interpolation.html",
    "title": "5  Inputs that vary over time",
    "section": "",
    "text": "5.1 Using time within equations\nOdin models propagate variables over time, either in discrete time or continuous (see Chapter 2). However, sometimes it is useful to have these models respond to quantities that themselves vary over time. This chapter explores a few different options, and highlights issues to be aware of when using them.\nThe simplest way to make a model time-dependent is simply to refer to time as a variable. For example, suppose we have a continuous-time logistic growth model (see Section 2.1)\nlogistic &lt;- odin({\n  deriv(n) &lt;- r * n * (1 - n / K)\n  initial(n) &lt;- 1\n  K &lt;- parameter()\n  r &lt;- parameter()\n})\nHere we create the system with r of 2 and K of 100, then run it from 0 to 6 time units:\nsys &lt;- dust_system_create(logistic(), list(r = 2, K = 100))\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 6, length.out = 101)\ny &lt;- dust_system_simulate(sys, t)\nplot(t, y, type = \"l\", xlab = \"Time\", ylab = \"n\")\nWe might think that growth rate r is seasonal, e.g., it’s higher in the spring and summer than in autumn and winter. Time in this model is fairly arbitrary, so let’s assume that each year is 1 time unit long and let growth rate r be a function of t. Supposing a mean growth rate r0 of 0.1, and assuming a p fraction of the growth rate being seasonal (so that if p is 1 growth is entirely seasonal and if p is 0 we recover our aseasonal model) we might model this as:\nr0 &lt;- 2\np &lt;- 0.2\ncurve(r0 * (1 - p) + r0 * p * (1 + sin(time * 2 * pi)), 0, 6,\n      n = 1001, xname = \"time\", xlab = \"Time\", ylab = \"Growth rate\")\nabline(h = r0, lty = 3)\nWe can use this directly within an odin model with no further modification:\nlogistic_t &lt;- odin({\n  deriv(n) &lt;- r * n * (1 - n / K)\n  initial(n) &lt;- 1\n  K &lt;- parameter()\n  r0 &lt;- parameter()\n  p &lt;- parameter(0.2)\n  r &lt;- r0 * (1 - p) + r0 * p * (1 + sin(time * 2 * pi))\n})\nHere, we have written r as an expression involving time, which means that at each time step we calculate a new value. Our parameters are now r0 and p as described above.\nHere’s the solution plotted against our original one - not terribly different; you can just make out the departure between the blue and the grey lines:\nsys &lt;- dust_system_create(logistic_t(), list(r0 = 2, K = 100))\ndust_system_set_state_initial(sys)\nyt_1 &lt;- dust_system_simulate(sys, t)\nplot(t, yt_1, type = \"l\", xlab = \"Time\", ylab = \"n\", col = \"blue\")\nlines(t, y, col = \"grey\")\nHere’s a more extreme set of parameters, where the seasonal effect is 80%, plotted against both solutions where the effect is more obvious:\ndust_system_update_pars(sys, list(p = 0.8))\ndust_system_set_time(sys, 0)\ndust_system_set_state_initial(sys)\nyt_2 &lt;- dust_system_simulate(sys, t)\nplot(t, yt_1, type = \"l\", xlab = \"Time\", ylab = \"n\", col = \"blue\")\nlines(t, y, col = \"grey\")\nlines(t, yt_2, col = \"red\")",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Inputs that vary over time</span>"
    ]
  },
  {
    "objectID": "interpolation.html#nondifferentiable-functions",
    "href": "interpolation.html#nondifferentiable-functions",
    "title": "5  Inputs that vary over time",
    "section": "5.2 Nondifferentiable functions",
    "text": "5.2 Nondifferentiable functions\n\n\n\n\n\n\nNote\n\n\n\nThis section may not be very interesting on the first reading, however this is a situation that comes up fairly often and has some subtleties to consider in continuous time systems especially.\n\n\nSo far, so good. One trick to watch out for is where you want to use a non-differentiable function of time, or one with abrupt changes in magnitude. For example, suppose we have a model where there’s a period where some effect happens (e.g., a period where vaccination or infection is possible). We might model this as a square wave:\n\n\n\n\n\n\n\n\n\nWe might define this within odin code as something like:\nsignal &lt;- if (time &gt; 4 && time &lt; 5) 1 else 0\nor we could use a piecewise-constant interpolation function (see below). If we use this within a discrete time model this will behave fine. However, if we use this within a differential equation model then we need to consider how the ODE solver works.\nAn ode solver works by looking at the slope with respect to time and working out how big a step it can take based on how this slope itself changes as a function of time. Where functions are very smooth (often where they are very flat) an ODE solver can take quite large steps, and it is possible that they can jump right over a spike like this. So if this spike is doing something like introducing infections into your model it’s possible that no-one becomes infected because we never evaluate your right-hand-side function within this window.\nIf you do land in the window, then the solver will have a difficult job as it tries to work out where this discontinuity started from. Typically, it will reject steps until it “finds” the starting time (here, 4).\nWhat we need to do is pass in a vector of critical times representing times that the solver must stop at.\nTo make this more concrete, here’s an ODE model which implements a square wave in an input (r) which has 1 between r0 and r1 and affects a variable y. We scale this input so that y will increase by one total unit over time:\n\nwave &lt;- odin({\n  deriv(y) &lt;- r / (r1 - r0)\n  initial(y) &lt;- 0\n  r0 &lt;- parameter(10)\n  r1 &lt;- parameter(15)\n  r &lt;- if (time &gt; r0 && time &lt; r1) 1 else 0\n})\n\nWe can run this and plot the output:\n\nsys &lt;- dust_system_create(wave, list())\nt &lt;- seq(0, 25)\ny &lt;- drop(dust_system_simulate(sys, t))\nplot(y ~ t, type = \"l\", xlab = \"Time\", ylab = \"Variable\")\n\n\n\n\n\n\n\n\nHere, from time 10 the variable increases, reaching a value of 1 at time 15.\nWe can shrink the time that transition happens, and this will happen more quickly, but always approach 1:\n\npars &lt;- list(list(r1 = 11), list(r1 = 12), list(r1 = 13), list(r1 = 14))\nsys &lt;- dust_system_create(wave, pars, n_groups = 4)\nt &lt;- seq(0, 25)\ny &lt;- drop(dust_system_simulate(sys, t))\nmatplot(t, t(y), type = \"l\", lty = 1, col = \"black\",\n        xlab = \"Time\", ylab = \"Variable\")\n\n\n\n\n\n\n\n\nWith dust_system_simulate() the solver will stop at every time, so we’ll never jump over the solution. But if you were running this where you were just advancing the solution through time you might do so. We get our expected value of (approximately) 1 at time 25 whenever r1 is 15:\n\nsys &lt;- dust_system_create(wave, list(r1 = 15))\ndust_system_run_to_time(sys, 25)\ndust_system_state(sys)\n#&gt; [1] 0.9999531\n\nbut with an earlier r1, and therefore a shorter window, we jump over this region:\n\nsys &lt;- dust_system_create(wave, list(r1 = 11))\ndust_system_run_to_time(sys, 25)\ndust_system_state(sys)\n#&gt; [1] 0\n\nWe can see what is going on here by saving out the steps that the solution takes:\n\ncontrol &lt;- dust_ode_control(debug_record_step_times = TRUE)\nsys &lt;- dust_system_create(wave, list(r1 = 11), ode_control = control)\ndust_system_run_to_time(sys, 25)\ntimes &lt;- dust_system_internals(sys)$step_times[[1]]\nplot(t, t &gt; 10, type = \"l\", xlab = \"Time\", ylab = \"Variable\")\npoints(times, rep(0, length(times)), pch = 19, col = \"red\")\n\n\n\n\n\n\n\n\nHere, the solver has started off slowly until working out that our solution is really very smooth (it has a derivative of zero!) and then started taking very large steps. One of these has landed just after our transition point has finished so it looks like it is simply not there.\nWe can use the ode_control to set a vector of critical times, ensuring that the solver will stop at times 10 and 11:\n\ncontrol &lt;- dust_ode_control(critical_times = c(10, 11))\nsys &lt;- dust_system_create(wave, list(r1 = 11), ode_control = control)\ndust_system_run_to_time(sys, 25)\ndust_system_state(sys)\n#&gt; [1] 0.9999276\n\nWith this approach we can ensure that even very small periods of discontinuity are found by the solver.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Inputs that vary over time</span>"
    ]
  },
  {
    "objectID": "interpolation.html#sec-interpolation-functions",
    "href": "interpolation.html#sec-interpolation-functions",
    "title": "5  Inputs that vary over time",
    "section": "5.3 Using interpolation functions",
    "text": "5.3 Using interpolation functions\nSometimes, you will want the time-varying functions of your model to be driven by data. So rather than having the model driven by seasonal change use some approximation of dynamics as we did with a sin wave above, you might want to use actual temperature or rainfall data. To do this, you can use odin’s “interpolation” functions, which take some series of time points and data and create a continuous function with respect to time. There are several different modes of interpolation available, which you can use to model different sorts of processes.\n\n5.3.1 A base model\nLet’s consider changes to a simple SIS (Susceptible-Infected-Susceptible) model. The basic model is a variation on our familiar SIR model that will allow the infection to become endemic, which will suit the demonstration here. We’ll work at first in continuous time, and then consider discrete time later.\n\nsis &lt;- odin({\n  deriv(S) &lt;- -beta * I * S / N + gamma * I\n  deriv(I) &lt;-  beta * I * S / N - gamma * I\n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  I0 &lt;- parameter(10)\n  N &lt;- parameter(1000)\n  beta &lt;- 0.2\n  gamma &lt;- 0.1\n})\n\nHere’s the system plotted over time:\n\nsys &lt;- dust_system_create(sis(), list())\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 200, length.out = 501)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\nplot(t, y$I, type = \"l\", xlab = \"Time\", ylab = \"Number of infected individuals\")\n\n\n\n\n\n\n\n\n\n\n5.3.2 Step-wise changes\nSuppose we want to model something that is on or off; perhaps beta changes in periods where schools are open or closed for holidays and the dates that this happen vary year-by-year, and we expect that beta is 60% lower when schools are closed due to fewer contacts among individuals. We might describe this in data as:\n\nschools_time &lt;- c(0, 50, 60, 120, 130, 170, 180)\nschools_open &lt;- c(1,  0,  1,   0,   1,   0,   1)\nschools_modifier &lt;- 0.6\n\nAnd, ignoring odin for a minute, we might demonstrate the effect by writing:\n\nbeta0 &lt;- 0.2\nbeta &lt;- approx(\n  schools_time,\n  ((1 - schools_open) * (1 - schools_modifier) + schools_open) * beta0,\n  xout = t,\n  method = \"constant\",\n  rule = 2)\nplot(beta, xlab = \"Time\", ylab = \"beta\", type = \"l\", ylim = c(0, 0.25))\n\n\n\n\n\n\n\n\nWe can take the same approach in odin, using its constant interpolation method:\n\nsis &lt;- odin({\n  deriv(S) &lt;- -beta * I * S / N + gamma * I\n  deriv(I) &lt;-  beta * I * S / N - gamma * I\n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  I0 &lt;- parameter(10)\n  N &lt;- parameter(1000)\n  beta0 &lt;- parameter(0.2)\n  schools &lt;- interpolate(schools_time, schools_open, \"constant\")\n  schools_time &lt;- parameter(constant = TRUE)\n  schools_open &lt;- parameter(constant = TRUE)\n  dim(schools_time, schools_open) &lt;- parameter(rank = 1)\n  schools_modifier &lt;- parameter(0.6)\n  beta &lt;- ((1 - schools) * (1 - schools_modifier) + schools) * beta0\n  gamma &lt;- 0.1\n})\n\nWhen we create the system, we must pass in values for the components of school; there are no defaults for vector parameters. The constant = TRUE argument when declaring the parameters specifies that these parameters cannot be changed after being set; this is necessary if we wanted to use these parameters to index into an array later, but moreover makes our intentions clear for the purposes of these parameters.\n\npars &lt;- list(schools_time = schools_time, schools_open = schools_open)\nsys &lt;- dust_system_create(sis(), pars)\n\nRun the system over the times as above, and plot the number of infected individuals over time, with the school closures in grey shading:\n\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 200, length.out = 501)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\nplot(t, y$I, type = \"l\", xlab = \"Time\", ylab = \"Number of infected individuals\")\nrect(schools_time[c(2, 4, 6)], par(\"usr\")[3],\n     schools_time[c(3, 5, 7)], par(\"usr\")[4], col = \"#00000033\", border = NA)\n\n\n\n\n\n\n\n\nInstead of piecewise constant functions, you can use piecewise linear functions or cubic spline interpolation. These allow for smoother changes in values than the piecewise constant functions above but with different properties.\nHere we have piecewise constant (dotted) and cubic spline (solid) interpolation functions through 11 evenly spaced data points:\n\n\n\n\n\n\n\n\n\nThe blue points might represent the strength of some signal over time, and we might prefer the smoothing effect of the spline to the rapid changes in the piecewise line function (e.g., around time 4). Notice that it does show some surprising oscillations (e.g., between time 9-10).\nThe red points might represent some variable moving through a phase transition, slowly decreasing then rapidly decaying to zero. The spline has “smoothed” this out by making it very wiggly, and pushing it outside of the range [0, 1].\nHere’s an example with a time varying rate of contact between susceptible individuals and infected individuals (or a varying rate of infection given contact), using spline interpolation:\n\nsis &lt;- odin({\n  deriv(S) &lt;- -beta * I * S / N + gamma * I\n  deriv(I) &lt;-  beta * I * S / N - gamma * I\n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  I0 &lt;- parameter(10)\n  N &lt;- parameter(1000)\n  beta &lt;- interpolate(beta_time, beta_value, \"spline\")\n  beta_time &lt;- parameter(constant = TRUE)\n  beta_value &lt;- parameter(constant = TRUE)\n  dim(beta_time, beta_value) &lt;- parameter(rank = 1)\n  gamma &lt;- 0.1\n})\n\nSuppose we have some beta values that vary over time:\n\nbeta_time &lt;- seq(0, 200, by = 20)\nbeta_value &lt;- runif(length(beta_time), 0.1, 0.2)\nplot(spline(beta_time, beta_value, n = 201), type = \"l\",\n     xlab = \"Time\", ylab = \"Beta\")\npoints(beta_time, beta_value, pch = 19)\n\n\n\n\n\n\n\n\nWe initialise this system with our values for beta_time and beta_value, and when we run the system we will see the number of infected individuals rise and fall with beta:\n\npars &lt;- list(beta_time = beta_time, beta_value = beta_value)\nsys &lt;- dust_system_create(sis, pars)\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 200, length.out = 501)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\nplot(t, y$I, type = \"l\", xlab = \"Time\", ylab = \"Number of infected individuals\")\n\n\n\n\n\n\n\n\n\n\n5.3.3 Interpolation of arrays\nThere are situations where you won’t just want to interpolate a scalar value at a time point, but an array. For instance, you have parameters indicating the daily number of vaccine doses that are being distributed and the time points at which these change.\nIn such an example the relevant odin code could be\ndaily_doses_value &lt;- parameter(constant = TRUE)\ndim(daily_doses_value) &lt;- parameter(rank = 2)\ndaily_doses_time &lt;- parameter(constant = TRUE)\ndim(daily_doses_time) &lt;- parameter(rank = 1)\n\ndaily_doses &lt;- interpolate(daily_doses_time, daily_doses_value, \"constant\")\ndim(daily_doses) &lt;- N_age\nHere daily_doses_value will be an array with first dimension of length N_age and the 2nd dimension of length equal to the length of daily_doses_time. Thus daily_doses_value[i, j] will be the value of daily_doses[i] at time daily_doses_time[j]. Interpolation will then be applied for each i (constant interpolation in the above case, but it could also be linear).\nNote that the syntax of the line\ndaily_doses &lt;- interpolate(daily_doses_time, daily_doses_value, \"constant\")\ndoes not differ whether are interpolating a scalar quantity or an array quantity.\nIn this example we have interpolated a vector quantity. You can interpolate higher-dimensional arrays. Just always make sure that the last dimension of your “value” array corresponds to your “time” vector.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Inputs that vary over time</span>"
    ]
  },
  {
    "objectID": "delays.html",
    "href": "delays.html",
    "title": "6  Looking back in time",
    "section": "",
    "text": "6.1 Calculating incidence, revisited\nSometimes you want to look back in time as your system runs. We’ve already seen a simple case of this in Section 2.2, where we compute incidence from cumulative traces using zero_every. However, sometimes this is not enough:\nWe can do this using delay differential equations (DDEs), in which rather than writing a system where \\(dy/dt\\) is expressed in terms of \\(t\\) and \\(y(t)\\), it also depends on \\(y(t - \\tau)\\) where \\(\\tau\\) is some fixed period back in time.\nIn general solving DDEs is hard, but if our main aim is to simply observe the behaviour over some interval they are fairly well behaved, empirically at least.\nHere is the SIR model from Section 2.2, but here we’ve made some changes to compute incidence in continuous time too:\nsir &lt;- odin({\n  deriv(S) &lt;- -beta * S * I / N\n  deriv(I) &lt;- beta * S * I / N - gamma * I\n  deriv(R) &lt;- gamma * I\n  rate_infections &lt;- beta * S * I / N\n  deriv(incidence) &lt;- rate_infections\n  deriv(infections) &lt;- rate_infections\n\n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  initial(R) &lt;- 0\n  initial(incidence, zero_every = 1) &lt;- 0\n  initial(infections) &lt;- 0\n\n  N &lt;- parameter(1000)\n  I0 &lt;- parameter(10)\n  beta &lt;- parameter(0.2)\n  gamma &lt;- parameter(0.1)\n\n  infections_prev &lt;- delay(infections, 1)\n  output(incidence_continuous) &lt;- infections - infections_prev\n})\nt &lt;- seq(0, 20, by = 0.01)\nsys &lt;- dust_system_create(sir, list(beta = 1, gamma = 0.5))\ndust_system_set_state_initial(sys)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\nPlotting the continuous measure (black) against our saw-toothed reset-every approach shows they line up at each time unit, but the black line changes smoothly while the red line shows increases followed by being reset.\nplot(t, y$incidence_continuous, type = \"l\")\nlines(t, y$incidence, type = \"S\", col = \"red\")\nNote how the continuous incidence measure at between time 0 and 1 is inaccurate; this is because it is subtracting from the assumed cumulative infection value of zero before the simulation starts.\nWithout using delays, we have no smooth and continuous measure of incidence that we can use throughout the simulation.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Looking back in time</span>"
    ]
  },
  {
    "objectID": "delays.html#calculating-incidence-revisited",
    "href": "delays.html#calculating-incidence-revisited",
    "title": "6  Looking back in time",
    "section": "",
    "text": "We store the rate of infections rate_infections and we add a cumulative variable infections; the calculations for incidence are unchanged from before\nWe compute the previous infections as the current cumulative infections delayed by one time unit\nWe can then compute (and output) our continuous incidence measure as the difference between the current and previous cumulative infections",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Looking back in time</span>"
    ]
  },
  {
    "objectID": "delays.html#potential-issues",
    "href": "delays.html#potential-issues",
    "title": "6  Looking back in time",
    "section": "6.2 Potential issues",
    "text": "6.2 Potential issues\nWhere your solution changes state abruptly, the handling of delays will be incorrect. Handling this correctly is non-trivial as it involves propagating all the harmonics of the points of change forward in time (that is, each change leaves an echo forward in time!). There are sophisticated solvers that can handle this, but we have not implemented one in dust2.\nDelayed variables cannot be used everywhere; in particular they are not yet supported in comparison functions (this is on the radar), nor in events (which are not yet described in this book).",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Looking back in time</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "7  Data",
    "section": "",
    "text": "7.1 The SIR model revisited\nBefore we start on inference, we need to start thinking about how our models fit to data, and how we can get data into the models. This gets very close to the interface that we need to work with monty, which is the focus of the next section of the book.\nIn a couple of chapters we’ll explore fitting a stochastic SIR model to data, so we’ll start with expressions from the model in Section 3.2\nsir &lt;- odin({\n  update(S) &lt;- S - n_SI\n  update(I) &lt;- I + n_SI - n_IR\n  update(R) &lt;- R + n_IR\n  update(incidence) &lt;- incidence + n_SI\n\n  p_SI &lt;- 1 - exp(-beta * I / N * dt)\n  p_IR &lt;- 1 - exp(-gamma * dt)\n  n_SI &lt;- Binomial(S, p_SI)\n  n_IR &lt;- Binomial(I, p_IR)\n\n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  initial(R) &lt;- 0\n  initial(incidence, zero_every = 1) &lt;- 0\n\n  N &lt;- parameter(1000)\n  I0 &lt;- parameter(10)\n  beta &lt;- parameter(0.2)\n  gamma &lt;- parameter(0.1)\n})\nAssuming our time unit is one day, if we run our model in time steps of a quarter of a day, then plotting incidence at daily time intervals we get:\npars &lt;- list(beta = 1, gamma = 0.6)\nsys &lt;- dust_system_create(sir, pars, dt = 0.25)\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 20)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\nplot(t, y$incidence, type = \"p\", xlab = \"Time\", ylab = \"Incidence\")",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#the-data-cometh",
    "href": "data.html#the-data-cometh",
    "title": "7  Data",
    "section": "7.2 The data cometh",
    "text": "7.2 The data cometh\nWe need a data set to fit to; we’ll use the data set data/incidence.csv, which you can download.\n\nd &lt;- read.csv(\"data/incidence.csv\")\nhead(d)\n#&gt;   time cases\n#&gt; 1    1    12\n#&gt; 2    2    23\n#&gt; 3    3    25\n#&gt; 4    4    36\n#&gt; 5    5    30\n#&gt; 6    6    57\ntail(d)\n#&gt;    time cases\n#&gt; 15   15    27\n#&gt; 16   16    25\n#&gt; 17   17    15\n#&gt; 18   18    20\n#&gt; 19   19    11\n#&gt; 20   20     7\n\nWe have a column for time time and one for observed cases cases spanning the time range 0 to 20.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#sec-simple-sir-data",
    "href": "data.html#sec-simple-sir-data",
    "title": "7  Data",
    "section": "7.3 Comparison to data",
    "text": "7.3 Comparison to data\nThe next step is to tell our model about this data:\n\nsir &lt;- odin({\n  update(S) &lt;- S - n_SI\n  update(I) &lt;- I + n_SI - n_IR\n  update(R) &lt;- R + n_IR\n  update(incidence) &lt;- incidence + n_SI\n\n  p_SI &lt;- 1 - exp(-beta * I / N * dt)\n  p_IR &lt;- 1 - exp(-gamma * dt)\n  n_SI &lt;- Binomial(S, p_SI)\n  n_IR &lt;- Binomial(I, p_IR)\n\n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  initial(R) &lt;- 0\n  initial(incidence, zero_every = 1) &lt;- 0\n\n  N &lt;- parameter(1000)\n  I0 &lt;- parameter(10)\n  beta &lt;- parameter(0.2)\n  gamma &lt;- parameter(0.1)\n\n  cases &lt;- data()\n  cases ~ Poisson(incidence)\n})\n\nThe last two lines here are doing the work for us:\nFirst, cases &lt;- data() says that cases is a special data variable. It will vary over time (there are different observations of cases at different times) and it will come from the data rather than from the model dynamics.\nSecond, cases ~ Poisson(incidence) describes the per-data-point likelihood calculation; the syntax may be familiar to you if you have read Richard McElreath’s Statistical Rethinking or used any number of Bayesian statistical frameworks.\n\n\n\n\n\n\nNote\n\n\n\nA data variable cannot have the same name as a state variable - in situations where one directly corresponds to the other you may have to think carefully about naming to distinguish between the two in a way that you can remember which refers to which.\n\n\nThe generator will advertise that this system can be compared to data:\n\nsir\n#&gt; \n#&gt; ── &lt;dust_system_generator: odin_system&gt; ────────────────────────────────────────\n#&gt; ℹ This system has 'compare_data' support\n#&gt; ℹ This system runs in discrete time with a default dt of 1\n#&gt; ℹ This system has 4 parameters\n#&gt; → 'N', 'I0', 'beta', and 'gamma'\n#&gt; ℹ Use dust2::dust_system_create() (`?dust2::dust_system_create()`) to create a system with this generator\n#&gt; ℹ Use coef() (`?stats::coef()`) to get more information on parameters\n\nOnce we have our new model, we can see how the data comparison works.\n\nsys &lt;- dust_system_create(sir, list(), n_particles = 10)\ndust_system_set_state_initial(sys)\ndust_system_run_to_time(sys, d$time[[1]])\ndust_system_compare_data(sys, d[1, ])\n#&gt;  [1] -13.669448  -7.351682 -20.987214  -9.803867 -13.669448  -5.673960\n#&gt;  [7]  -9.803867 -13.669448  -9.803867 -20.987214\n\nThis has run the model to the point where we have the first observed data (time 1), this time without returning any data to R, then we have used dust_system_compare_data with the first row of data. This returns a vector of 10 likelihoods – one per particle.\n\n\n\n\n\n\nNote\n\n\n\nThis is probably the first mention of a “particle”, and it is from this that the name dust is derived. As a nod to the particle filter, which will be the focus of the next section, we refer to each realisation of the dynamical system as a “particle”.\n\n\nTo demystify this a little we can perform this calculation manually. First we extract the state from the system, unpacking it to make it easier to work with:\n\ns &lt;- dust_unpack_state(sys, dust_system_state(sys))\ns\n#&gt; $S\n#&gt;  [1] 988 986 989 987 988 985 987 988 987 989\n#&gt; \n#&gt; $I\n#&gt;  [1] 10 13  8 12 12 15 13 12 12  9\n#&gt; \n#&gt; $R\n#&gt;  [1] 2 1 3 1 0 0 0 0 1 2\n#&gt; \n#&gt; $incidence\n#&gt;  [1] 2 4 1 3 2 5 3 2 3 1\n\nWe can then manually compute the likelihood, and bind this together with the calculation from dust to compare:\n\ncbind(dpois(d$cases[[1]], s$incidence, log = TRUE),\n      dust_system_compare_data(sys, d[1, ]))\n#&gt;             [,1]       [,2]\n#&gt;  [1,] -13.669448 -13.669448\n#&gt;  [2,]  -7.351682  -7.351682\n#&gt;  [3,] -20.987214 -20.987214\n#&gt;  [4,]  -9.803867  -9.803867\n#&gt;  [5,] -13.669448 -13.669448\n#&gt;  [6,]  -5.673960  -5.673960\n#&gt;  [7,]  -9.803867  -9.803867\n#&gt;  [8,] -13.669448 -13.669448\n#&gt;  [9,]  -9.803867  -9.803867\n#&gt; [10,] -20.987214 -20.987214\n\nAs you can see, these are the same; the expression\ncases ~ Poisson(incidence)\nhas done the same sort of thing as we can do ourselves by asking “what is the (log) probability of observing cases cases if the underlying rate of incidence is incidence”. Note that this can be -Inf (a probability of 0) in the case where the modelled incidence is zero.\n\ndpois(10, 0, log = TRUE)\n#&gt; [1] -Inf\n\nThis is fine, so long as not all particles are impossible.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#sec-data-filter",
    "href": "data.html#sec-data-filter",
    "title": "7  Data",
    "section": "7.4 The particle filter",
    "text": "7.4 The particle filter\nWe include a simple bootstrap particle filter in dust for estimating the marginal likelihood in this case; the probability of the entire data series conditional on our model, marginalised (averaged) over all stochastic realisations. Because our model is stochastic, this is an estimate of the likelihood but the estimate will get less noisy as the number of particles increases.\n\nfilter &lt;- dust_filter_create(sir, time_start = 0, data = d, n_particles = 200)\n\nHere, we’ve created a filter where the time series starts at 0, using our data set d and we’ve picked 200 particles to start with. We run the filter with dust_likelihood_run, and this returns a likelihood:\n\ndust_likelihood_run(filter, list())\n#&gt; [1] -230.2398\n\n\n\n\n\n\n\nNote\n\n\n\nA value of NA in the data time series for a given datastream at a given timepoint will indicate missing data and the filter will simply ignore that datastream at that timepoint.\n\n\nEach time we run the filter, we’ll get a different answer though.\n\ndust_likelihood_run(filter, list())\n#&gt; [1] -209.737\n\nFor example, running for 100 times:\n\nll &lt;- replicate(100, dust_likelihood_run(filter, list()))\nmean(ll)\n#&gt; [1] -221.6029\nvar(ll)\n#&gt; [1] 209.5122\n\nIf we increase the number of particles, this variance will decrease, at the cost of taking longer to run:\n\nfilter2 &lt;- dust_filter_create(sir, time_start = 0, data = d,\n                              n_particles = 2000)\nll2 &lt;- replicate(100, dust_likelihood_run(filter2, list()))\nmean(ll2)\n#&gt; [1] -187.2385\nvar(ll2)\n#&gt; [1] 60.33101\n\nThe log-likelihoods from different numbers of particles are not directly comparable, though.\nYou can extract trajectories from the filter after running it: this gives a tree showing the ancestry of the particles remaining in the sample. To enable this, you must run with save_trajectories = TRUE, as this incurs a runtime cost.\n\nll &lt;- dust_likelihood_run(filter, list(), save_trajectories = TRUE)\nh &lt;- dust_likelihood_last_trajectories(filter)\n\nThe trajectories will be an array with 3 dimensions representing (in turn) state, particle and time:\n\ndim(h)\n#&gt; [1]   4 200  20\n\n\n\n\n\n\n\nNote\n\n\n\nTrajectories will only be saved at the timepoints found in the data time series. If you want to output trajectories at timepoints where you do not have any data, you can do this by including the timepoints in the data time series with NA values in all of the datastreams. Doing so will have no impact on the filtering process. This can be useful if e.g. you want to output the trajectories between time_start and your first data timepoint; or you have weekly data but you want to output daily trajectories.\n\n\nWe can plot the trajectories of our incidence here:\n\nmatplot(d$time, t(dust_unpack_state(filter, h)$incidence), type = \"l\",\n        lty = 1, col = \"#00000044\", ylim = c(0, 75),\n        xlab = \"Time\", ylab = \"Incidence\")\npoints(cases ~ time, d, pch = 19, col = \"red\")\n\n\n\n\n\n\n\n\nThis model does not fit the data very well! The points don’t lie close to the modelled trajectories. We also see everything before time ~10 reduced to a single particle’s trajectories, which will have the effect of increasing the variance.\nIf we found better parameters things would look much better. We just so happen to know that if beta is 1 and gamma 0.6 then the model will fit better:\n\npars &lt;- list(beta = 1, gamma = 0.6)\nll &lt;- dust_likelihood_run(filter, pars, save_trajectories = TRUE)\nh &lt;- dust_likelihood_last_trajectories(filter)\nmatplot(d$time, t(dust_unpack_state(filter, h)$incidence), type = \"l\",\n        lty = 1, col = \"#00000044\", ylim = c(0, 75),\n        xlab = \"Time\", ylab = \"Incidence\")\npoints(cases ~ time, d, pch = 19, col = \"red\")\n\n\n\n\n\n\n\n\nAs the model fit improves and the log-likelihood increases, the variance in that estimator will also decrease as the model struggles less to describe the data:\n\nll &lt;- replicate(100, dust_likelihood_run(filter, pars))\nmean(ll)\n#&gt; [1] -80.61978\nvar(ll)\n#&gt; [1] 1.982596\n\nMoving from the poor-fitting parameters to the better fitting ones is the process of inference, which will be the focus of most of the rest of this book.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "order.html",
    "href": "order.html",
    "title": "8  Order of events for discrete-time stochastic models",
    "section": "",
    "text": "8.1 Updates\nHere we have a discrete-time stochastic model\nthis model includes many components we have introduced in preceding sections, such as variables that reset periodically, use of interpolation functions and comparison to data.\nIt is useful to understand the order in which events will be evaluated as the model updates from time = t0 to time = t0 + dt. There will first be a series of updates to the variables, followed by a comparison to data (assuming you are comparing the model to data).\nAt the beginning of the update we have time = t0 and then the updates proceed in the following order:",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Order of events for discrete-time stochastic models</span>"
    ]
  },
  {
    "objectID": "order.html#sec-order-update",
    "href": "order.html#sec-order-update",
    "title": "8  Order of events for discrete-time stochastic models",
    "section": "",
    "text": "8.1.1 Reset any variables that use zero_every\nAny variable that uses zero_every = x will be reset to 0 if t0 is a multiple of x. In our model we have\ninitial(incidence, zero_every = 1) &lt;- 0\nso incidence will reset to 0 whenever t0 is an integer.\n\n\n8.1.2 Read from variables\nAll variables will be read at their current values. In our example these are S, I, R and incidence.\n\n\n8.1.3 Look up interpolation\nAny uses of interpolate relating to updates are evaluated using time = t0. Thus in our example\nbeta &lt;- interpolate(beta_time, beta_value, \"linear\")\nis evaluated to give beta its value at time = t0.\n\n\n8.1.4 Evaluate assignments\nAssignment equations should have a logical order of evaluation (circularity should prevent compilation). For instance in our model it would naturally evaluate\np_SI &lt;- 1 - exp(-beta * I / N * dt)\np_IR &lt;- 1 - exp(-gamma * dt)\nand then\nn_SI &lt;- Binomial(S, p_SI)\nn_IR &lt;- Binomial(I, p_IR)\nEquations will be evaluated using the variables that were read in earlier (note that this is after any variables that use zero_every have been reset to 0). As with interpolation, any equations that use time (see Section 5.1) will use time = t0.\n\n\n8.1.5 Write out new values of state\nHere we write out new values of variables as given by update equations. In our example these are\nupdate(S) &lt;- S - n_SI\nupdate(I) &lt;- I + n_SI - n_IR\nupdate(R) &lt;- R + n_IR\nupdate(incidence) &lt;- incidence + n_SI\nAs with the other assignment equations, these are evaluated using values of the variables that were read in earlier. Thus in the equation\nupdate(S) &lt;- S - n_SI\nit is telling us the value we will assign to S for time = t0 + dt, but on the right hand side it will use the value of S at time = t0.\n\n\n\n\n\n\nWarning\n\n\n\nYou should be careful to avoid introducing lags between state variables in your update equations.\nFor example for this simple model\n\\[\\begin{gather*}\nX(t + dt) = X(t) + Normal(0, 1)\\\\\nY(t + dt) = Y(t) + Normal(0, 1)\\\\\nZ(t) = X(t) + Y(t)\n\\end{gather*}\\]\nit would be incorrect to code this as\n\nm &lt;- odin({\n  update(X) &lt;- X + dX\n  update(Y) &lt;- Y + dY\n  update(Z) &lt;- X + Y\n  \n  dX &lt;- Normal(0, 1)\n  dY &lt;- Normal(0, 1)\n  \n  initial(X) &lt;- 0\n  initial(Y) &lt;- 0\n  initial(Z) &lt;- 0\n})\n\nas we can see that running this results in Z being lagged by a time-step relative to X and Y:\n\nsys &lt;- dust_system_create(m, list(), seed = 1)\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 5)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\n\ny$X + y$Y\n#&gt; [1] 0.000000 1.666908 1.358213 4.669377 4.191150 6.221572\n\ny$Z\n#&gt; [1] 0.000000 0.000000 1.666908 1.358213 4.669377 4.191150\n\nThis is because\nupdate(Z) &lt;- X + Y\ncorresponds to \\(Z(t + dt) = X(t) + Y(t)\\) and not \\(Z(t) = X(t) + Y(t)\\). Thus we need to account for the updates to X and Y on the right-hand side.\nA correct way to write it could be\nupdate(Z) &lt;- X + dX + Y + dY\nhowever in more complex models such an approach may become unwieldy, and further changes to updates for X and Y must be replicated in the update to Z.\nA safer approach is to introduce intermediate variables representing the updated values of X and Y\n\nm &lt;- odin({\n  update(X) &lt;- X_new\n  update(Y) &lt;- Y_new\n  update(Z) &lt;- X_new + Y_new\n  \n  dX &lt;- Normal(0, 1)\n  X_new &lt;- X + dX\n  dY &lt;- Normal(0, 1)\n  Y_new &lt;- Y + dY\n  \n  initial(X) &lt;- 0\n  initial(Y) &lt;- 0\n  initial(Z) &lt;- 0\n})\n\nwhich means that subsequent changes to how X updates are automatically factored into how Z updates. We can see this version no longer results in a lag:\n\nsys &lt;- dust_system_create(m, list(), seed = 1)\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 5)\ny &lt;- dust_system_simulate(sys, t)\ny &lt;- dust_unpack_state(sys, y)\n\ny$X + y$Y\n#&gt; [1] 0.000000 1.666908 1.358213 4.669377 4.191150 6.221572\n\ny$Z\n#&gt; [1] 0.000000 1.666908 1.358213 4.669377 4.191150 6.221572\n\n\n\n\n\n8.1.6 Update time to t0 + dt\nThe series of updates ends with time being increased by dt.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Order of events for discrete-time stochastic models</span>"
    ]
  },
  {
    "objectID": "order.html#sec-order-comparison",
    "href": "order.html#sec-order-comparison",
    "title": "8  Order of events for discrete-time stochastic models",
    "section": "8.2 Comparison to data",
    "text": "8.2 Comparison to data\nThe comparison to data follows on from the above series of updates, and as such it is common that all equations relating to the comparison to data appear in a block at the end.\nEquations relating to comparison to data are evaluated after the update of time to t0 + dt and will only be evaluated if you have any data at time = t0 + dt.\n\n8.2.1 Read from variables\nAll variables will be read at their current values, which are the values corresponding to time = t0 + dt. Again, in our example the variables are S, I, R and incidence, although only incidence is used in the comparison to data\n\n\n8.2.2 Look up interpolation\nAny uses of interpolate that are used in the comparison to data will be evaluated using time = t0 + dt (not using time = t0 as was used earlier in the “update” step). Compilation of odin code will detect which interpolations are used in the comparison to data.\nIn our example we\nphi &lt;- interpolate(phi_time, phi_value, \"constant\")\nwhere phi might represent a time-varying ascertainment rate of cases (which could be affected by e.g. whether schools are open, or day of the week effects).\n\n\n8.2.3 Evaluate assignments\nAs with interpolation, compilation of odin code will detect which assignments are used only in the comparison to data. For instance in our example this would be\nexp_noise &lt;- Exponential(1e6)\nAny use of variables in these equations on the right-hand side will be evaluated using their values at time = t0 + dt.\n\n\n8.2.4 Compare to data\nFinally we evaluate the density given by any relationship equations. In our example this is\ncases ~ Poisson(phi * incidence + exp_noise)\nAs with assignments in the comparison to data step, any use of variables in relationship equations on the right-hand side will be evaluated using their values at time = t0 + dt. No actual assignment is done in relationship equations, but the density accumulates over all non-NA data entries.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Order of events for discrete-time stochastic models</span>"
    ]
  },
  {
    "objectID": "packaging.html",
    "href": "packaging.html",
    "title": "9  Packaging odin models",
    "section": "",
    "text": "9.1 A basic package skeleton\nSo far, we have compiled odin code as we have needed it, using the odin() function. This works well for many uses, but has its limitations:\nMany tools exist to create packages; here we will use usethis, but there’s nothing magic here - you could create these files by hand if you prefer (see Writing R Extensions for the official guide on R packages if this is the approach you prefer).\npath &lt;- tempfile()\nusethis::create_package(\n  path,\n  fields = list(Package = \"pkg\",\n                Title = \"My Odin Model\",\n                Description = \"An example odin model\"))\n#&gt; ✔ Creating '/tmp/RtmpluDTXN/file24aa35ed915a/'.\n#&gt; ✔ Setting active project to \"/tmp/RtmpluDTXN/file24aa35ed915a\".\n#&gt; ✔ Creating 'R/'.\n#&gt; ✔ Writing 'DESCRIPTION'.\n#&gt; Package: pkg\n#&gt; Title: My Odin Model\n#&gt; Version: 0.1.0\n#&gt; Authors@R (parsed):\n#&gt;     * An Author &lt;a.author@example.com&gt; [aut, cre]\n#&gt; Description: An example odin model\n#&gt; License: CC0\n#&gt; Encoding: UTF-8\n#&gt; Language: en-GB\n#&gt; Roxygen: list(markdown = TRUE)\n#&gt; RoxygenNote: 7.3.2\n#&gt; ✔ Writing 'NAMESPACE'.\n#&gt; ✔ Setting active project to \"&lt;no active project&gt;\".\nusethis::proj_set(path)\n#&gt; ✔ Setting active project to \"/tmp/RtmpluDTXN/file24aa35ed915a\".\nOur package now contains:\nfs::dir_tree(path)\n#&gt; /tmp/RtmpluDTXN/file24aa35ed915a\n#&gt; ├── DESCRIPTION\n#&gt; ├── NAMESPACE\n#&gt; └── R\nusethis has created some skeleton files for us. The DESCRIPTION contains:\nand the NAMESPACE file contains",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Packaging odin models</span>"
    ]
  },
  {
    "objectID": "packaging.html#a-basic-package-skeleton",
    "href": "packaging.html#a-basic-package-skeleton",
    "title": "9  Packaging odin models",
    "section": "",
    "text": "Package: pkg\nTitle: My Odin Model\nVersion: 0.1.0\nAuthors@R: \n    person(\"An\", \"Author\", , \"a.author@example.com\", role = c(\"aut\", \"cre\"))\nDescription: An example odin model\nLicense: CC0\nEncoding: UTF-8\nLanguage: en-GB\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.3.2\n\n# Generated by roxygen2: do not edit by hand",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Packaging odin models</span>"
    ]
  },
  {
    "objectID": "packaging.html#adding-odin-code",
    "href": "packaging.html#adding-odin-code",
    "title": "9  Packaging odin models",
    "section": "9.2 Adding odin code",
    "text": "9.2 Adding odin code\nThe odin code needs to go within this package in the inst/odin directory. Code saved as inst/odin/myname.R will create a generator called myname. Here, we create a file inst/odin/sir.R containing the SIR model from Chapter 1:\nderiv(S) &lt;- -beta * S * I / N\nderiv(I) &lt;- beta * S * I / N - gamma * I\nderiv(R) &lt;- gamma * I\n\ninitial(S) &lt;- N - I0\ninitial(I) &lt;- I0\ninitial(R) &lt;- 0\n\nN &lt;- parameter(1000)\nI0 &lt;- parameter(10)\nbeta &lt;- parameter(0.2)\ngamma &lt;- parameter(0.1)\nWe also need to make some changes to our package:\n\nWe need to include dust2 as an Imports dependency\nWe need to include dust2, monty and cpp11 as LinkingTo dependencies\nWe need to arrange our package so it loads the shared library that we build\n\nIf you run odin_package() before setting this up, it will error and indicate where the problem lies:\n\nodin_package(path)\n#&gt; ℹ Found 1 odin code file in 'inst/odin'\n#&gt; ✔ Wrote 'inst/dust/sir.cpp'\n#&gt; Error:\n#&gt; ! Expected package 'dust2' as 'Imports' in DESCRIPTION\n\n\nusethis::use_package(\"dust2\", \"Imports\")\n#&gt; ✔ Adding dust2 to 'Imports' field in DESCRIPTION.\n#&gt; ☐ Refer to functions with `dust2::fun()`.\nusethis::use_package(\"dust2\", \"LinkingTo\")\n#&gt; ✔ Adding dust2 to 'LinkingTo' field in DESCRIPTION.\n#&gt; Possible includes are:\n#&gt;   #include &lt;lostturnip.hpp&gt;\nusethis::use_package(\"monty\", \"LinkingTo\")\n#&gt; ✔ Adding monty to 'LinkingTo' field in DESCRIPTION.\n\nSetting up to use cpp11 is a bit more involved because of the changes that we need to make to ensure that everything links together correctly; for details see the packaging section of the cpp11 “Getting started” vignette\n\nusethis::use_package_doc()\n#&gt; ✔ Writing 'R/pkg-package.R'.\n#&gt; ☐ Run `devtools::document()` to update package-level documentation.\nusethis::use_cpp11()\n#&gt; ✔ Creating 'src/'.\n#&gt; ✔ Adding \"*.o\", \"*.so\", and \"*.dll\" to 'src/.gitignore'.\n#&gt; ✔ Adding \"@useDynLib pkg, .registration = TRUE\" to 'R/pkg-package.R'.\n#&gt; ☐ Run `devtools::document()` to update 'NAMESPACE'.\n#&gt; ✔ Adding cpp11 to 'LinkingTo' field in DESCRIPTION.\n#&gt; ✔ Writing 'src/code.cpp'.\ndevtools::document(path)\n#&gt; ℹ Updating pkg documentation\n#&gt; Writing 'NAMESPACE'\n#&gt; ℹ Loading pkg\n#&gt; ℹ 1 functions decorated with [[cpp11::register]]\n#&gt; \n#&gt; ✔ generated file 'cpp11.R'\n#&gt; \n#&gt; ✔ generated file 'cpp11.cpp'\n#&gt; \n#&gt; ℹ Re-compiling pkg (debug build)\n#&gt; ── R CMD INSTALL ───────────────────────────────────────────────────────────────\n#&gt; * installing *source* package ‘pkg’ ...\n#&gt; ** this is package ‘pkg’ version ‘0.1.0’\n#&gt; ** using staged installation\n#&gt; ** libs\n#&gt; using C++ compiler: ‘g++ (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0’\n#&gt; g++ -std=gnu++17 -I\"/opt/R/4.5.1/lib/R/include\" -DNDEBUG  -I'/home/runner/work/_temp/Library/cpp11/include' -I'/home/runner/work/_temp/Library/dust2/include' -I'/home/runner/work/_temp/Library/monty/include' -I/usr/local/include    -fpic  -g -O2  -UNDEBUG -Wall -pedantic -g -O0  -c code.cpp -o code.o\n#&gt; g++ -std=gnu++17 -I\"/opt/R/4.5.1/lib/R/include\" -DNDEBUG  -I'/home/runner/work/_temp/Library/cpp11/include' -I'/home/runner/work/_temp/Library/dust2/include' -I'/home/runner/work/_temp/Library/monty/include' -I/usr/local/include    -fpic  -g -O2  -UNDEBUG -Wall -pedantic -g -O0  -c cpp11.cpp -o cpp11.o\n#&gt; g++ -std=gnu++17 -shared -L/opt/R/4.5.1/lib/R/lib -L/usr/local/lib -o pkg.so code.o cpp11.o -L/opt/R/4.5.1/lib/R/lib -lR\n#&gt; installing to /tmp/RtmpluDTXN/devtools_install_24aa175451c1/00LOCK-file24aa35ed915a/00new/pkg/libs\n#&gt; ** checking absolute paths in shared objects and dynamic libraries\n#&gt; * DONE (pkg)\n#&gt; Writing 'pkg-package.Rd'\nfs::file_delete(file.path(path, \"src/code.cpp\"))\n\nWe can now generate our odin code:\n\nodin_package(path)\n#&gt; ℹ Found 1 odin code file in 'inst/odin'\n#&gt; ℹ 'inst/dust/sir.cpp' is up to date\n#&gt; ℹ Working in package 'pkg' at '/tmp/RtmpluDTXN/file24aa35ed915a'\n#&gt; ℹ Found 1 system\n#&gt; ✔ Wrote 'src/sir.cpp'\n#&gt; ✔ Wrote 'R/dust.R'\n#&gt; ✔ Wrote 'src/Makevars'\n#&gt; ℹ 13 functions decorated with [[cpp11::register]]\n#&gt; ✔ generated file 'cpp11.R'\n#&gt; ✔ generated file 'cpp11.cpp'\n\nThe package now contains more files:\n\nfs::dir_tree(path)\n#&gt; /tmp/RtmpluDTXN/file24aa35ed915a\n#&gt; ├── DESCRIPTION\n#&gt; ├── NAMESPACE\n#&gt; ├── R\n#&gt; │   ├── cpp11.R\n#&gt; │   ├── dust.R\n#&gt; │   └── pkg-package.R\n#&gt; ├── inst\n#&gt; │   ├── dust\n#&gt; │   │   └── sir.cpp\n#&gt; │   └── odin\n#&gt; │       └── sir.R\n#&gt; ├── man\n#&gt; │   └── pkg-package.Rd\n#&gt; └── src\n#&gt;     ├── Makevars\n#&gt;     ├── code.o\n#&gt;     ├── cpp11.cpp\n#&gt;     ├── cpp11.o\n#&gt;     ├── pkg.so\n#&gt;     └── sir.cpp\n\nAlmost every new file here should not be edited directly (and all contain a line at the start to that effect).\nOur DESCRIPTION now contains\nPackage: pkg\nTitle: My Odin Model\nVersion: 0.1.0\nAuthors@R: \n    person(\"An\", \"Author\", , \"a.author@example.com\", role = c(\"aut\", \"cre\"))\nDescription: An example odin model\nLicense: CC0\nEncoding: UTF-8\nLanguage: en-GB\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.3.2\nImports: \n    dust2\nLinkingTo: \n    cpp11,\n    dust2,\n    monty\nand NAMESPACE contains\n# Generated by roxygen2: do not edit by hand\n\nuseDynLib(pkg, .registration = TRUE)\nIn R/:\n\ncpp11.R is the glue code generated by cpp11\ndust.R is glue code generated by dust2\npkg-package.R was generated by usethis::use_package_doc() and holds the special roxygen2 comments that caused devtools::document() to write our NAMESPACE file (you can edit this file!)\n\n#' @keywords internal\n\"_PACKAGE\"\n\n## usethis namespace: start\n#' @useDynLib pkg, .registration = TRUE\n## usethis namespace: end\nNULL\nIn inst/dust, sir.cpp contains the dust interface for our model (see the “Writing dust2 systems” vignette if you are curious)\nIn man/, pkg-package.Rd contains help files generated by roxygen2\nIn src/\n\nMakevars contains code to allow OpenMP to work to parallelise the system\ncpp11.cpp is glue code generated by cpp11\nsir.cpp is the full system code generated by dust2\ncode.cpp was added by cpp11 and can be removed\nThe .o and .so (or .dll on Windows) files are generated by the compiler",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Packaging odin models</span>"
    ]
  },
  {
    "objectID": "packaging.html#development-of-the-package",
    "href": "packaging.html#development-of-the-package",
    "title": "9  Packaging odin models",
    "section": "9.3 Development of the package",
    "text": "9.3 Development of the package\nOnce your odin code is in a package, you will want to iterate over it. Previously you might have had scripts that you used source() on to load into the session. Now your workflow looks like:\n\nEdit the odin code in inst/odin\nRun odin_package()\nLoad the package with pkgload::load_all()\n\nIf you edit code in R/ you don’t need to run step 2, and running step 3 is enough.\n\npkgload::load_all(path)\n#&gt; ℹ Loading pkg\n#&gt; ℹ 13 functions decorated with [[cpp11::register]]\n#&gt; \n#&gt; ✔ generated file 'cpp11.R'\n#&gt; \n#&gt; ✔ generated file 'cpp11.cpp'\n#&gt; \n#&gt; ℹ Re-compiling pkg (debug build)\n#&gt; ── R CMD INSTALL ───────────────────────────────────────────────────────────────\n#&gt; * installing *source* package ‘pkg’ ...\n#&gt; ** this is package ‘pkg’ version ‘0.1.0’\n#&gt; ** using staged installation\n#&gt; ** libs\n#&gt; using C++ compiler: ‘g++ (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0’\n#&gt; g++ -std=gnu++17 -I\"/opt/R/4.5.1/lib/R/include\" -DNDEBUG  -I'/home/runner/work/_temp/Library/cpp11/include' -I'/home/runner/work/_temp/Library/dust2/include' -I'/home/runner/work/_temp/Library/monty/include' -I/usr/local/include   -fopenmp -fpic  -g -O2  -UNDEBUG -Wall -pedantic -g -O0  -c cpp11.cpp -o cpp11.o\n#&gt; g++ -std=gnu++17 -I\"/opt/R/4.5.1/lib/R/include\" -DNDEBUG  -I'/home/runner/work/_temp/Library/cpp11/include' -I'/home/runner/work/_temp/Library/dust2/include' -I'/home/runner/work/_temp/Library/monty/include' -I/usr/local/include   -fopenmp -fpic  -g -O2  -UNDEBUG -Wall -pedantic -g -O0  -c sir.cpp -o sir.o\n#&gt; g++ -std=gnu++17 -shared -L/opt/R/4.5.1/lib/R/lib -L/usr/local/lib -o pkg.so cpp11.o sir.o -fopenmp -L/opt/R/4.5.1/lib/R/lib -lR\n#&gt; installing to /tmp/RtmpluDTXN/devtools_install_24aa20ca912b/00LOCK-file24aa35ed915a/00new/pkg/libs\n#&gt; ** checking absolute paths in shared objects and dynamic libraries\n#&gt; * DONE (pkg)\n\nIf you are using RStudio then Ctrl-Shift-l will load the package for you.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Packaging odin models</span>"
    ]
  },
  {
    "objectID": "packaging.html#next-steps",
    "href": "packaging.html#next-steps",
    "title": "9  Packaging odin models",
    "section": "9.4 Next steps",
    "text": "9.4 Next steps\nOnce you have a model in a package, then you are within the realms of normal R package development, and nothing here is specific to odin. However, if you are not familiar with package development we hope these tips will be useful.\nA good place to look for information on package development is Hadley Wickham and Jenny Bryan’s “R packages” book, and to avoid repeating their material we’ll just link to it:\n\nCreate an RStudio project for your new package\nWrite some tests for your model and its support code. We’ll document some basic ideas for this later.\nCreate a git repository for your package and put it on GitHub. For more discussion see this chapter in “R packages”, and this guide on configuring R, RStudio and git to work well together.\nSet up continuous integration so that your tests are run automatically when you make changes to your package\nPut your package into an R universe to make it easy for others to install. Your organisation may already have one (for DIDE users, please see this repo), or you can start your own\n\nThis looks like a lot of work, but most of the setup here can be configured in a few lines. Writing tests is the only part that requires more than configuration, and that is something that you will tend to get better at over time.",
    "crumbs": [
      "Odin",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Packaging odin models</span>"
    ]
  },
  {
    "objectID": "monty.html",
    "href": "monty.html",
    "title": "10  Getting started with monty",
    "section": "",
    "text": "10.1 A simple example\nBefore showing how to fit odin models to data, we’ll focus for a bit on monty itself. If you are anxious to get on and fit the model from Section 7.4, you might skip ahead to Chapter 14, where we resume this.\nThe monty R package is designed for modular work with statistical distributions, leveraging Monte Carlo methods for sampling. It enables the construction of increasingly complex models through four approaches:\nThe most basic method to define a monty model is through a simple R function, as shown in this chapter. More advanced examples are covered in the Chapter 11 in particular in the context of Bayesian statistics. Chapter 12 introduces the monty DSL for more versatile model building using a small probabilistic DSL similar to BUGs. The last part of this book starting from Chapter 14 demonstrates how to incorporate odin models into monty workflows.\nlibrary(monty)\nWe can define a simple Gaussian mixture model of two sub-populations using the monty_model_function() from the package. The model represents the distribution of a quantity \\(l\\), sampled with a probability \\(p\\) from a normal distribution of mean \\(m_{1}\\) and with a probability \\(1-p\\) from another normal distribution of mean \\(m_{2}\\). Both subpopulations have variance equal to 1.\nTo build our monty model, we start by defining an R function returning the log-density of our statistical model. This function has four arguments \\(l\\) (the quantity of interest) and the three parameters \\(p\\), \\(m_{1}\\) and \\(m_{2}\\) defining the two Normally-distributed subpopulations.\nfn &lt;- function(l, p, m1, m2) {\n  log(p * dnorm(l, mean = m1) + (1 - p) * dnorm(l, mean = m2))\n}\nAssuming that the population is 75% from subpopulation 1 (normally distributed with mean 3) and 25% from subpopulation 2 (also normally distributed but with mean 7), we can build our monty model by indicating that the parameters of the subpopulations are fixed at these given values.\nmixture_model &lt;- monty_model_function(fn,\n                                       fixed = list(p = 0.75, m1 = 3, m2 = 7),\n                                       allow_multiple_parameters = TRUE)\nWe have just created a monty model.\nmixture_model\n#&gt; \n#&gt; ── &lt;monty_model&gt; ───────────────────────────────────────────────────────────────\n#&gt; ℹ Model has 1 parameter: 'l'\n#&gt; ℹ This model:\n#&gt; • accepts multiple parameters\n#&gt; ℹ See `?monty_model()` for more information\nWe can plot the density of our model for values of \\(l\\) between 0 and 10 and eye-check that we can see the two subpopulations in the correct proportions and with 3 and 7 as modes.\n#l &lt;- matrix(seq(from = 0, to = 10, by = 0.1), 1)\nl &lt;- seq(from = 0, to = 10, by = 0.1)\n#monty_model_density(l_distribution, l)\nplot(l,\n     exp(Vectorize(mixture_model$density)(l)),\n     type = \"l\",\n     ylab = \"density\")",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Getting started with monty</span>"
    ]
  },
  {
    "objectID": "monty.html#sampling-from-our-example-distribution",
    "href": "monty.html#sampling-from-our-example-distribution",
    "title": "10  Getting started with monty",
    "section": "10.2 Sampling from our example distribution",
    "text": "10.2 Sampling from our example distribution\nWe now want to sample from this model, using the monty_sample() function. For this we need to tell monty which sampler we want to use to explore our distribution. There are a variety of samplers available and you can learn about them in Chapter 13. One of the simplest is the random walk Metropolis-Hastings algorithm that should work almost out of the box (though not necessarily efficiently) in most cases.\nThe random walk sampler uses a variance-covariance (VCV) matrix to guide its exploration, determining the ‘jump’ from the current point to the next in a random walk by drawing from a multivariate normal distribution parametrised by this matrix. For our single-parameter model here, we use a 1x1 matrix of variance 2 (matrix(2)) as our VCV matrix.\nThe choice of the VCV matrix is critical for the sampler’s efficiency, especially in more complex cases where the tuning of this matrix can significantly affect performance. A well-chosen VCV matrix optimises moving across the parameter space, making the random walk sampler more effective in exploring the distribution of interest.\n\nsampler &lt;- monty_sampler_random_walk(matrix(2))\n\nWe are now ready to sample from our distribution using monty_sample() with 2000 samples, starting our MCMC chain at the value 3 and running 4 chains sequentially.\n\nsamples &lt;- monty_sample(mixture_model, sampler, 2000, initial = 3, n_chains = 4)\n#&gt; ⡀⠀ Sampling [▁▁▁▁] ■                                |   0% ETA: 26s\n#&gt; ✔ Sampled 8000 steps across 4 chains in 389ms\n#&gt; \n\nWe can visualise our 4 chains.\n\nmatplot(samples$density, type = \"l\", lty = 1,\n        xlab = \"sample\", ylab = \"log posterior density\", col = \"#00000055\")\n\n\n\n\n\n\n\n\nWe can also check that our samples are correctly representing our distribution:\n\nhist(samples$pars[\"l\", , ], breaks = 100)",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Getting started with monty</span>"
    ]
  },
  {
    "objectID": "monty.html#connection-of-monty-with-other-software",
    "href": "monty.html#connection-of-monty-with-other-software",
    "title": "10  Getting started with monty",
    "section": "10.3 Connection of monty with other software",
    "text": "10.3 Connection of monty with other software\nmonty includes a simple probabilistic domain-specific language (DSL) that is inspired by languages of the BUGS family such as stan and Statistical Rethinking. It is designed to make some tasks a bit easier, particularly when defining priors for your model. We expect that this DSL is not sufficiently advanced to represent most interesting models but it may get more clever and flexible in the future. In particular we do not expect the DSL to be useful in writing likelihood functions for comparison to data; we expect that if your model is simple enough for this you would be better off using stan or some similarly flexible system.\n*mention SSM, drjacoby, mcstate, BayesTools",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Getting started with monty</span>"
    ]
  },
  {
    "objectID": "monty.html#going-further",
    "href": "monty.html#going-further",
    "title": "10  Getting started with monty",
    "section": "10.4 Going further",
    "text": "10.4 Going further\nWe’ve discussed a little bit about the philosophy of monty and built a simple model using an R function with monty_function. The example introduces the basics of defining and sampling from a monty model.\nFor more advanced applications, refer to Chapter 12 for constructing models using monty’s domain-specific language, which enables greater flexibility for complex structures. Lastly, Chapter 14 illustrates how to incorporate odin models into monty workflows, expanding the package’s potential for Bayesian inference with more sophisticated, system-based models. Each section provides detailed examples to guide you in leveraging monty’s full capabilities.",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Getting started with monty</span>"
    ]
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "11  About (monty) Models",
    "section": "",
    "text": "11.1 Models vs. Models: dynamical and statistical perspectives\nIn this book, we explore two fundamentally different yet interconnected approaches to modelling: dynamical systems and statistical models. To illustrate these differences, let’s begin with a familiar (but maybe dated!) metaphor: the game SimCity.",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>About (monty) Models</span>"
    ]
  },
  {
    "objectID": "model.html#models-vs.-models-dynamical-and-statistical-perspectives",
    "href": "model.html#models-vs.-models-dynamical-and-statistical-perspectives",
    "title": "11  About (monty) Models",
    "section": "",
    "text": "11.1.1 SimCity and dynamical systems\nImagine a city model, as in SimCity, where thousands of virtual inhabitants follow routines, interact, and respond to changes like new buildings or natural disasters. These elements evolve according to predefined rules and parameters, similar to how dynamical systems simulate real-world processes over time.\nIn a dynamical model, we track changes in a system’s “state” over time. The state is a summary of key information at a specific time point; for example, in an epidemiological model, the state might include the numbers of susceptible, infected, and recovered individuals. More detailed models may add variables like age, location, health risks, and symptoms, allowing us to simulate interventions, such as vaccination campaigns, and explore their potential impacts. There exist many formalisms to describe dynamical systems, incorporating e.g. specific input and output functions in control theory but the central element of these systems is this notion of the “state”, a mathematical object summarising the system at a time-point.\nThe odin package, which supports differential and difference equations, is an effective tool for building dynamical models, enabling users to simulate time-evolving systems. Dynamical models are well-suited for exploring how specific scenarios or interventions impact a system over time, making them particularly useful for modelling real-world phenomena in a structured way.\nTODO: simple odin deterministic model with discussion about results being a time indexed suite of “states”\n\n\n11.1.2 Statistical models and uncertainty\nStatistical models, on the other hand, focus on capturing uncertainty in outcomes. Instead of simulating the system’s evolution over time, they represent possible states of the world probabilistically. Statistical models summarise data patterns or help make predictions based on uncertainties, such as estimating the range of future cases of a disease or identifying risk factors in a population.\nThe monty package facilitates statistical modelling, providing tools for working with probability distributions and Monte Carlo methods. Where odin enables us to explore the dynamics of changing systems, monty is ideal for making probabilistic inferences and assessing variability across potential outcomes without necessarily modelling time-evolving dynamics.\nTODO: simple gaussian model - discussion about parameter being actually the sampling space and explain that it connects with Bayesian inference, show that the important component of the model is the parameters and domain support + density function, maybe shows that the model can be built in different way (R function, monty_model(), DSL).",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>About (monty) Models</span>"
    ]
  },
  {
    "objectID": "model.html#bridging-dynamical-systems-and-statistical-models",
    "href": "model.html#bridging-dynamical-systems-and-statistical-models",
    "title": "11  About (monty) Models",
    "section": "11.2 Bridging dynamical systems and statistical models",
    "text": "11.2 Bridging dynamical systems and statistical models\nWhile dynamical systems and statistical models serve distinct purposes, they are not strictly separate. In fact, they can be connected through two powerful approaches that bring probabilistic reasoning into dynamical systems: stochastic processes and Bayesian inference.\n\n11.2.1 Stochastic processes: adding uncertainty to dynamical models\nA natural way to bridge dynamical and statistical models is by introducing stochastic processes. Traditional dynamical models use fixed parameters and deterministic rules to evolve a system’s state over time. However, many real-world systems have inherent randomness or uncertainty that deterministic models cannot capture.\nIn a stochastic process, the system’s state is no longer a single deterministic value but a collection of potential outcomes, each weighted by a probability. This probabilistic view enables us to model fluctuations and uncertainties within the dynamical framework, capturing both the system’s evolution and the uncertainty in each state. Stochastic processes are thus a natural extension of dynamical models, adding an extra layer of realism by treating system evolution as inherently uncertain.\nThe odin package provides an intuitive framework for writing a class of stochastic systems, making it easier to define models that incorporate randomness in their evolution over time. The dust package complements odin by enabling efficient large-scale simulations, allowing users to capture and analyse the uncertainty inherent to these systems through repeated runs. Together, odin and dust offer a powerful toolkit for developing and exploring stochastic models that reflect the complexity and variability of real-world dynamics.\nTODO simple dust example or just link with relevant dust section in the book\n\n\n11.2.2 Bayesian inference: statistical modelling of model parameters\nBayesian inference is another approach to linking dynamical and statistical models by treating model parameters as random variables rather than fixed values. This introduces a probability distribution over possible parameter values, making parameter estimation a statistical problem.\nUsing Bayes’ theorem, Bayesian inference combines:\n\nThe likelihood: the probability of observing the data given specific parameter values, and\nThe prior distribution: our initial assumptions about the parameter values before observing the data.\n\nThe result is the posterior distribution of a parameter \\(\\theta\\) given data \\(y\\):\n\\[\np(\\theta | y) = \\frac{p(y|\\theta) p(\\theta)}{p(y)}\n\\]\nwhere:\n\n\\(p(y|\\theta)\\) is the likelihood,\n\\(p(\\theta)\\) is the prior distribution, and\n\\(p(y)\\) is a normalising constant to ensure the posterior integrates to 1 over all \\(\\theta\\) values.\n\nBayesian inference allows us to update our understanding of parameters based on observed data, yielding a posterior distribution that incorporates both model assumptions and the influence of the data. This approach provides a probabilistic framework that can adapt dynamically as new data becomes available, making it ideal for statistical models that require flexibility.\nMany statistical modelling tools—such as WinBUGS, JAGS, stan, and BayesTools—are fundamentally Bayesian. However, the monty package is Bayesian-agnostic, allowing users to choose between Bayesian and non-Bayesian approaches to probabilistic modelling, depending on the analytical requirements.\nBy combining stochastic processes with Bayesian inference, we add a dual dimension of uncertainty: randomness in the state of dynamical systems through stochastic processes, and probabilistic modelling of parameters through Bayesian methods. Together, these frameworks enable us to build robust models for complex systems that evolve over time, capturing both inherent randomness and uncertainty in our understanding.",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>About (monty) Models</span>"
    ]
  },
  {
    "objectID": "model.html#parameters-and-model-complexity",
    "href": "model.html#parameters-and-model-complexity",
    "title": "11  About (monty) Models",
    "section": "11.3 Parameters and model complexity",
    "text": "11.3 Parameters and model complexity\nIn both dynamical and statistical frameworks, the number of parameters can be adjusted as needed to capture the desired level of complexity. In the monty package, random variables - termed ‘parameters’ with a slight simplification of language - are typically used to summarise processes, and so they often form a more compact set than those found in dynamical models. This distinction is especially relevant in Bayesian models constructed from complex odin models.\nIn dynamical systems, parameters define the structure and evolution of a scenario in detail. For instance, an epidemiological model may include parameters for transmission rates, contact patterns, or intervention schedules. These inputs enable “what-if” scenarios, allowing decision-makers to predict and manage changes in real time. The odin package, designed to support such dynamical models, provides the flexibility to specify numerous parameters for exploring system behaviours over time.\nStatistical models, by contrast, use parameters to define probability distributions over possible outcomes, capturing uncertainties, predicting risks, or summarising data patterns. In Bayesian models based on a complex odin framework, the statistical parameters are usually a subset of those used in the dynamical model itself. Parameters such as those defining a vaccination campaign (e.g. daily number of doses given to target groups), for example, might be central to shaping the odin model but may not necessarily be included in Bayesian inference (that might focus on just vaccine efficacy at most). This selective approach allows us to quantify uncertainties and make probabilistic inferences about key aspects of the model without needing to explore detail of the underlying dynamics that are “known” for what was actually observed.\nThus, while dynamical models rely on a broad parameter set for flexibility, statistical parameters summarise uncertainty more compactly, making the combined approach especially effective for realistic, data-driven inferences.",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>About (monty) Models</span>"
    ]
  },
  {
    "objectID": "model.html#probability-densities-normalised-vs.-unnormalised",
    "href": "model.html#probability-densities-normalised-vs.-unnormalised",
    "title": "11  About (monty) Models",
    "section": "11.4 Probability densities: normalised vs. unnormalised",
    "text": "11.4 Probability densities: normalised vs. unnormalised\nA key concept in Bayesian inference and Monte Carlo methods is the distinction between normalised and unnormalised probability densities.\nIn Bayesian inference, rather than using the “full” Bayesian as above, we are often working with defining posterior density as being proportional to a product of densities:\n\\[\np(\\theta | y) \\propto p(y|\\theta) p(\\theta)\n\\]\nwhere:\n\n\\(p(y|\\theta)\\) is the likelihood, and\n\\(p(\\theta)\\) is the prior distribution, as above.\n\nNote that it does not involve the normalising constant \\(p(y)\\) any more. The reason is that since calculating \\(p(y)\\) can be very difficult, we often work with the unnormalised posterior density \\(p(y|\\theta)p(\\theta)\\). This unnormalised form is sufficient for many Monte Carlo methods, where only relative densities matter.\nA normalised density integrates to 1 over its entire parameter space. This is necessary for direct probability interpretations and for certain Bayesian methods, like model comparison using Bayes factors.\nMonte Carlo algorithms, such as Metropolis-Hastings and Importance Sampling, often operate using unnormalised densities, focusing on relative probabilities rather than absolute values. This makes them efficient for high-dimensional problems where calculating a normalising constant is untractable.\nNormalisation in probability densities has parallels in physics. In statistical mechanics, the partition function \\(Z\\) normalises probabilities over all possible states, much like normalising densities in Bayesian inference. This connection highlights why algorithms like Metropolis-Hastings use unnormalised densities: they mirror physical systems where absolute energies are less relevant than energy differences.",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>About (monty) Models</span>"
    ]
  },
  {
    "objectID": "monty-dsl.html",
    "href": "monty-dsl.html",
    "title": "12  The monty DSL",
    "section": "",
    "text": "12.1 A simple example\nThe monty DSL provides a more intuitive way to define statistical models with monty. It is currently relatively basic and focuses on providing support for defining priors in Bayesian models. It fully support differentiability allowing to use gradient based samplers on these models.\nIn chapter 4 of Statistical Rethinking, we build a regression model of height with parameters \\(\\alpha\\), \\(\\beta\\) and \\(\\sigma\\). We can define the model for the prior probability of this model in monty by running\nprior &lt;- monty_dsl({\n  alpha ~ Normal(178, 20)\n  beta ~ Normal(0, 10)\n  sigma ~ Uniform(0, 50)\n})\nThis will define a new monty_model() object that represents the prior, but with all the bits that we might need depending on how we want to use it:\nWe have model parameters\nprior$parameters\n#&gt; [1] \"alpha\" \"beta\"  \"sigma\"\nThese are defined in the order that they appear in your definition (so alpha is first and sigma is last)\nWe can compute the domain for your model:\nprior$domain\n#&gt;       [,1] [,2]\n#&gt; alpha -Inf  Inf\n#&gt; beta  -Inf  Inf\n#&gt; sigma    0   50\nWe can draw samples from the model if we provide a monty_rng object\nrng &lt;- monty_rng_create()\ntheta &lt;- monty_model_direct_sample(prior, rng)\ntheta\n#&gt; [1] 155.30396 -12.79361  27.66180\nWe can compute the (log) density at a point in parameter space\nprior$density(theta)\n#&gt; [1] -12.51049\nThe computed properties for the model are:\nprior$properties\n#&gt; \n#&gt; ── &lt;monty_model_properties&gt; ────────────────────────────────────────────────────\n#&gt; • has_gradient: `TRUE`\n#&gt; • has_direct_sample: `TRUE`\n#&gt; • is_stochastic: `FALSE`\n#&gt; • has_parameter_groups: `FALSE`\n#&gt; • has_observer: `FALSE`\n#&gt; • allow_multiple_parameters: `TRUE`",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The monty DSL</span>"
    ]
  },
  {
    "objectID": "monty-dsl.html#distribution-functions",
    "href": "monty-dsl.html#distribution-functions",
    "title": "12  The monty DSL",
    "section": "12.2 Distribution functions",
    "text": "12.2 Distribution functions\nIn the above example we use distribution functions for the normal and uniform distributions. The distribution functions available for the monty DSL are the same as those for the odin DSL, the full list of which can be found here.",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The monty DSL</span>"
    ]
  },
  {
    "objectID": "monty-dsl.html#dependent-distributions",
    "href": "monty-dsl.html#dependent-distributions",
    "title": "12  The monty DSL",
    "section": "12.3 Dependent distributions",
    "text": "12.3 Dependent distributions\nIt is possible within the DSL to have the distribution of parameters to depend upon the value of other parameters:\n\nm &lt;- monty_dsl({\n    a ~ Normal(0, 1)\n    b ~ Normal(a, 1)\n})\n\nThis is particularly useful for the implementation of hyperpriors when using the DSL to define priors.\nOrder of equations is important when using dependent distributions in the monty DSL! You cannot have the distribution of a parameter depend upon a parameter that is defined later. Thus rewriting the above example as\nm &lt;- monty_dsl({\n    b ~ Normal(a, 1)\n    a ~ Normal(0, 1)\n})\nwould produce an error.",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The monty DSL</span>"
    ]
  },
  {
    "objectID": "monty-dsl.html#calculations-in-the-dsl",
    "href": "monty-dsl.html#calculations-in-the-dsl",
    "title": "12  The monty DSL",
    "section": "12.4 Calculations in the DSL",
    "text": "12.4 Calculations in the DSL\nSometimes it will be useful to perform calculations in the code; you can do this with assignments. Most trivially, giving names to numbers may help make code more understandable:\n\nm &lt;- monty_dsl({\n  mu &lt;- 10\n  sd &lt;- 2\n  a ~ Normal(mu, sd)\n})\n\nYou can also use this to do things like:\n\nm &lt;- monty_dsl({\n  a ~ Normal(0, 1)\n  b ~ Normal(0, 1)\n  mu &lt;- (a + b) / 2\n  c ~ Normal(mu, 1)\n})\n\nWhere c is drawn from a normal distribution with a mean that is the average of a and b.",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The monty DSL</span>"
    ]
  },
  {
    "objectID": "monty-dsl.html#pass-in-fixed-data",
    "href": "monty-dsl.html#pass-in-fixed-data",
    "title": "12  The monty DSL",
    "section": "12.5 Pass in fixed data",
    "text": "12.5 Pass in fixed data\nYou can also pass in a list of data with values that should be available in the DSL code. For example, our first example:\n\nprior &lt;- monty_dsl({\n  alpha ~ Normal(178, 20)\n  beta ~ Normal(0, 10)\n  sigma ~ Uniform(0, 50)\n})\n\nMight be written as\n\nfixed &lt;- list(alpha_mean = 170, alpha_sd = 20,\n              beta_mean = 0, beta_sd = 10,\n              sigma_max = 50)\nprior &lt;- monty_dsl({\n  alpha ~ Normal(alpha_mean, alpha_sd)\n  beta ~ Normal(beta_mean, beta_sd)\n  sigma ~ Uniform(0, sigma_max)\n}, fixed = fixed)\n\nValues you pass in this way are fixed (hence the name!) and cannot be modified after the model object is created.",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The monty DSL</span>"
    ]
  },
  {
    "objectID": "samplers.html",
    "href": "samplers.html",
    "title": "13  Samplers and inference",
    "section": "",
    "text": "13.1 Sampling without monty\nMany quantities of interest in uncertain systems can be expressed as integrals that weight outcomes according to their probability. A common approach to computing these integrals is Monte Carlo estimation, where we draw samples from our distribution of interest and take their mean as an approximation. This method has been central to probabilistic inference and has driven the development of sophisticated sampling algorithms since the advent of modern computing in the 1950s.\nThe monty package supports several sampling algorithms designed to handle a variety of target distributions and leverage any available information (such as gradients). At the moment, monty provides the following samplers:\nThese samplers can all be accessed via constructors (e.g. monty_sampler_random_walk(), monty_sampler_hmc(), etc.) and used with the general-purpose function monty_sample(). By choosing the sampler that best suits your distribution - whether it is unimodal or multimodal, gradient-accessible or not - you can often achieve more efficient exploration of your parameter space.\nIn this section we are going to see an example where we can sample from a monty model without using monty. The idea is then to compare this ideal situation with less favourable cases when we have to use Monte Carlo methods to sample.\nImagine that we have a simple 2D (bivariate) Gaussian monty_model model with some positive correlation:\n# Set up a simple 2D Gaussian model, with correlation\nVCV &lt;- matrix(c(1, 0.8, 0.8, 1), 2, 2)\nm &lt;- monty_example(\"gaussian\", VCV)\nm\n#&gt; \n#&gt; ── &lt;monty_model&gt; ───────────────────────────────────────────────────────────────\n#&gt; ℹ Model has 2 parameters: 'a' and 'b'\n#&gt; ℹ This model:\n#&gt; • can compute gradients\n#&gt; • can be directly sampled from\n#&gt; ℹ See `?monty_model()` for more information\nThis monty_model is differentiable and can be directly sampled from (a very low level way of “sampling” that means different things depending on the situation e.g. could mean sampling from the prior distribution, we advise to use it very carefully).\nIn that particularly simple case, we can even visualise its density over a grid:\na &lt;- seq(-4, 4, length.out = 1000)\nb &lt;- seq(-3, 3, length.out = 1000)\n\nz &lt;- matrix(1,\n            nrow = length(a),\n            ncol = length(b))\nfor(i in seq_along(a))\n  for(j in seq_along(b))\n    z[i,j] &lt;- exp(monty_model_density(m, c(a[i], b[j])))\nimage(a, b, z, xlab = \"a\", ylab = \"b\",\n      main = \"2D Gaussian model with correlation\")\nAs we are dealing with a bivariate normal distribution, we can use a trick to sample easily from this distribution. We use samples from a simple standard normal distribution and multiply them by the Cholesky decomposition of the Variance-Covariance parameter matrix of our bivariate normal distribution:\nn_samples &lt;- 1000\nstandard_samples &lt;- matrix(rnorm(2 * n_samples), ncol = 2)\nsamples &lt;- standard_samples %*% chol(VCV)\nThese samples align well with the density:\nimage(a, b, z, xlab = \"a\", ylab = \"b\",\n      main = \"2D Gaussian model with samples\")\npoints(samples, pch = 19, col = \"#00000055\")\nThey are i.i.d. and present no sign of autocorrelation, which can be visualised using the acf() function - successive samples (i.e. lagged by one) in this case do not present any sign of correlation.\nacf(samples[, 1],\n    main = \"Autocorrelation of i.i.d. samples\")",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Samplers and inference</span>"
    ]
  },
  {
    "objectID": "samplers.html#sampling-with-monty",
    "href": "samplers.html#sampling-with-monty",
    "title": "13  Samplers and inference",
    "section": "13.2 Sampling with monty",
    "text": "13.2 Sampling with monty\nHowever most of the time, in practical situations such as Bayesian modelling, we are not able to sample using simple functions, and we have to use an MCMC sampler. monty samplers exploit the properties of the underlying monty model (e.g. availability of gradient) to draw samples. While they differ, a key commonality is that they are based on a chain of Monte Carlo draws and are thus characterised by their number of steps in the chain, n_steps. Also, they are built using a constructor of the form monty_sampler_name() and then samples are generated using the monty_sample() function.\n\n13.2.1 Randow-Walk Metropolis-Hastings\nRandom-Walk Metropolis-Hastings (RWMH) is one of the most straightforward Markov chain Monte Carlo (MCMC) algorithms. At each iteration, RWMH proposes a new parameter vector by taking a random step - usually drawn from a symmetric distribution (e.g. multivariate normal with mean zero) - from the current parameter values. This new proposal is then accepted or rejected based on the Metropolis acceptance rule, which compares the density of the proposed point with that of the current point.\nThe random-walk nature of the proposal means that tuning the step size and directionality (defined by a variance-covariance matrix in multiple dimensions) is crucial. If steps are too large, many proposals will be rejected; if they are too small, the chain will move slowly through parameter space, leading to high autocorrelation in the samples. RWMH can be a good starting point for problems where gradient information is unavailable or when simpler methods suffice.\nThe monty_sampler_random_walk() function allows us to define an RWMH sampler by passing the Variance-Covariance matrix of the proposal distribution as an argument.\n\nvcv &lt;- diag(2) * 0.1\nsampler_rw &lt;- monty_sampler_random_walk(vcv = vcv)\n\nOnce the sampler is built, the generic monty_sample() function can be used to generate samples:\n\nres_rw &lt;- monty_sample(m, sampler_rw, n_steps = 1000)\n#&gt; ⡀⠀ Sampling  ■                                |   0% ETA:  3s\n#&gt; ✔ Sampled 1000 steps across 1 chain in 48ms\n#&gt; \n\nThis produces a chain of length n_steps that can be visualised:\n\nplot(res_rw$pars[1, , 1],\n     type = \"l\",\n     ylab = \"Value of sample\",\n     main = \"MCMC chain from RWMH sampler\")\n\n\n\n\n\n\n\n\nSamples can also be visualised over the density:\n\nimage(a, b, z, xlab = \"a\", ylab = \"b\",\n      main = \"2D Gaussian model with RWMH samples\")\npoints(t(res_rw$pars[, , 1]), pch = 19, col = \"#00000055\")\n\n\n\n\n\n\n\n\nAnd we can look at the autocorrelation of the chain\n\nacf(res_rw$pars[1, , 1], 200,\n    main = \"Autocorrelation of the RWMH samples\")\n\n\n\n\n\n\n\n\nWe can see from the autocorrelation function that we have to wait almost 100 steps for the algorithm to produce a “new” (i.e. not correlated) sample, meaning a lot of calculation is “wasted” just trying to move away from previous samples. Improving the number of uncorrelated samples is at the heart of many strategies to improve the efficiency of Monte Carlo sampling algorithms. In particular, the adaptive Metropolis-Hastings sampler offers tools to automatically optimise the proposal distribution.\n\n13.2.1.1 Boundaries\nThere is a boundaries argument to monty_sampler_random_walk (and some other samplers too), which controls what happens when your domain is bounded in one or more dimensions and the Gaussian proposal results in proposed parameter set out of bounds. There are three options:\n\n\"reflect\" - where an out-of-bounds proposal is reflected back into bounds to ensure a valid proposed parameter set, where the density is then calculated in order to potentially accept or reject.\n\"reject\" - where an out-of-bounds proposal results in an automatic rejection (without density calculation) at that step in the MCMC chain, and the current parameter set is retained.\n\"ignore\" - where the density is calculated for the out-of-bounds parameter set. This option is to be used carefully as it may result in accepting samples out-of-bounds, or perhaps might result in an error.\n\nLet’s look at a bounded model, where we have parameters a and b that are bounded below at 0.\n\nm &lt;- monty_dsl({\n  a ~ TruncatedNormal(0, 1, min = 0, max = Inf)  \n  b ~ TruncatedNormal(0, 1, min = 0, max = Inf)\n}, gradient = FALSE)\n\nSuppose the Gaussian proposal resulted in \\(a = -1, b = 2\\), which is out-of-bounds. With the \"reject\" option we would just reject and move onto the next step. With the \"reflect\"option, we would reflect about \\(a = 0\\) to give \\(a = 1, b = 2\\) as our proposed parameter set and calculate the density there. With the \"ignore\" option we would keep \\(a = -1, b = 2\\) as the proposed parameter set and calculate the density for it (safely in this example as the log-density is defined as -Inf when out of bounds of the truncated-normal distribution).\nLet’s run the sampler with boundaries = \"reject\"\n\nvcv &lt;- diag(2)\n\nsampler_reject &lt;- monty_sampler_random_walk(vcv = vcv, boundaries = \"reject\")\nres_reject &lt;- monty_sample(m, sampler_reject, \n                           n_steps = 1000, initial = c(1, 1))\n#&gt; ⡀⠀ Sampling  ■                                |   0% ETA:  1s\n#&gt; ✔ Sampled 1000 steps across 1 chain in 67ms\n#&gt; \n\nand with boundaries = \"reflect\"\n\nsampler_reflect &lt;- monty_sampler_random_walk(vcv = vcv, boundaries = \"reflect\")\nres_reflect &lt;- monty_sample(m, sampler_reflect, \n                            n_steps = 1000, initial = c(1, 1))\n\nwe see that the acceptance rate by reflecting at boundaries is higher due to always proposing a valid parameter set\n\nsum(diff(c(res_reject$initial[1], res_reject$pars[1, , 1])) != 0) / 1000\n#&gt; [1] 0.274\nsum(diff(c(res_reflect$initial[1], res_reflect$pars[1, , 1])) != 0) / 1000\n#&gt; [1] 0.548\n\nand it has also resulted in higher effective sample size (ESS)\n\nposterior::summarise_draws(posterior::as_draws_df(res_reject))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable  mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 a        0.716  0.555 0.569 0.568 0.0684  1.82  1.04     80.3     52.3\n#&gt; 2 b        0.770  0.670 0.590 0.572 0.0310  1.99  1.02     79.3     64.4\nposterior::summarise_draws(posterior::as_draws_df(res_reflect))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable  mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 a        0.719  0.601 0.540 0.509 0.0595  1.82  1.00     262.     225.\n#&gt; 2 b        0.768  0.626 0.619 0.576 0.0502  1.96  1.01     201.     179.\n\nWe have boundaries = \"reflect\" as the default as we expect this is what users will want in most cases, though there may be situations in which boundaries = \"reject\" is more useful and quicker per MCMC step (due to skipping a number of density calculations), although you may then need more steps to achieve the same effective sample size as with boundaries = \"reflect\". In situations where you are unlikely to propose out-of-bounds, there will be little difference between the options.\n\n\n\n13.2.2 Adaptive Metropolis-Hastings Sampler\nOverview\nThis sampler extends the basic (non-adaptive) random-walk Metropolis-Hastings algorithm by dynamically updating its proposal distribution as the chain progresses. In a standard random-walk MCMC, one must guess a single variance-covariance matrix (VCV) up front. If the target distribution is high-dimensional or has strong correlations, it can be challenging to find a VCV that allows the chain to explore efficiently.\nWith this adaptive approach, the VCV and the overall scaling factor evolve according to the observed samples. The sampler “learns” the covariance structure of the target distribution on-the-fly, leading to (potentially) much lower autocorrelation, better mixing, and more efficient exploration. Formally, this adaptivity modifies the Markov property, so care must be taken to ensure the adaptation “diminishes” over time.\nMain ideas\n\nAdaptive Shaping\n\nAfter each iteration, the algorithm updates an empirical VCV using the newly accepted parameter values.\n\nEarly samples are gradually forgotten (depending on forget_rate and forget_end) so that the empirical VCV primarily reflects the more recent part of the chain. This is helpful if the chain starts far from the high posterior density region - early samples will be informative about the shape of movement towards this region but once there will not be informative about the shape of the region itself.\nIn the proposal kernel, the empirical VCV is weighted according to its sample size against an initial estimate of the VCV, initial_vcv, with weight initial_vcv_weight.\n\nAdaptive Scaling\n\nThe sampler also updates a global scaling factor (which is squared and multiplied by \\(2.38^2 / d\\) in the proposal, where \\(d\\) is the number of parameters) to target a desired acceptance rate (acceptance_target). The optimal scaling factor should be 1 in a Gaussian target space when using the true underlying VCV.\nIf acceptance is too high, the sampler increases the scaling factor. If acceptance is too low, it decreases it. Doing this in log-space is often more stable (log_scaling_update = TRUE).\n\nAdaptation Stopping\n\nEventually, the sampler stops adapting (adapt_end), freezing the proposal distribution for the remainder of the run. This helps restore formal MCMC convergence properties, as purely adaptive samplers can break standard theory if they keep adapting indefinitely.\n\n\nThis implementation is inspired by an “accelerated shaping” adaptive algorithm from Spencer (2021).\n\n\n\n\n\n\n\nExpand for technical details of the adaptive algorithm\n\n\n\n\n\nAt iteration \\(i\\), we propose our new parameter set \\(Y_{i+1}\\) given current parameter set \\(X_i\\) (\\(d\\) is the number of fitted parameters):\n\\[\\begin{align*}\nY_{i+1}\\sim N\\left(X_i, \\frac{2.38^2}{d}\\lambda_i^2V_i\\right)\n\\end{align*}\\]\nThe algorithm can be broken into two parts:\n\nthe shaping part, which determines \\(V_i\\)\nthe scaling part, which determines \\(\\lambda_i\\)\n\n1. Shaping\nThe shaping is controlled by the following input parameters to monty_sampler_adaptive():\n\ninitial_vcv: the initial estimate of the variance-covariance matrix (VCV)\ninitial_vcv_weight: the prior weight on the initial VCV\nforget_rate: the rate at which we forget early parameter sets\nforget_end: the final iteration at which we can forget early parameter sets\nadapt_end: the final iteration at which we adaptively update the proposal VCV (also applies to scaling)\n\nAdditionally, the shaping algorithm involves calculation of an empirical VCV, which after iteration \\(i\\) is given by \\[\\begin{align*}\nvcv_i & = cov\\left(X_{\\lfloor forget\\_rate * \\min\\{i,\\, forget\\_end,\\, adapt\\_end\\}\\rfloor+1}, \\ldots, X_{\\min\\{i,\\, adapt\\_end\\}}\\right).\n\\end{align*}\\] Thus while iteration \\(i \\leq adapt\\_end\\) the empirical VCV is updated by including the new parameter set \\(X_i\\), but additionally while \\(i \\leq forget\\_end\\) we remove (“forget”) the earliest parameter set remaining from the empirical VCV sample if \\(\\lfloor forget\\_rate * i \\rfloor &gt; \\lfloor forget\\_rate * (i - 1) \\rfloor\\) . After \\(forget\\_end\\) iterations we no longer forget early parameter sets from the sample VCV, and after \\(adapt\\_end\\) iterations the empirical VCV is no longer updated.\nWith \\(weight_i\\) being the size of the empirical VCV sample, we then weight the empirical VCV and initial VCV: \\[\\begin{align*}\nV_i = \\frac{weight_i*sample\\_vcv_i + \\left(initial\\_vcv\\_weight+d+1\\right)*initial\\_vcv}{weight_i+initial\\_vcv\\_weight+d+2}\n\\end{align*}\\] (Note: weightings in numerator do not add up to denominator.)\n2. Scaling\nThe shaping is controlled by the following input parameters to monty_sampler_adaptive():\n\ninitial_scaling: the initial value for scaling (\\(\\lambda_0\\))\nmin_scaling: the minimum value for scaling\nscaling_increment: the increment we use to increase or decrease the scaling\nacceptance_target: the acceptance rate we target\ninitial_scaling_weight: value used in the starting denominator of the scaling update\npre_diminish: the number of iterations before we apply diminishing adaptation to the scaling updates\nlog_scaling_change: logical whether we update the scaling on a log scale or not\nadapt_end: the final iteration at which we adaptively update the proposal VCV (also applies to shaping)\n\ninitial_scaling_weight can be unspecified (NULL), in which case we use \\[initial\\_scaling\\_weight = \\frac{5}{acceptance\\_target * (1 - acceptance\\_target)}\\]\nscaling_increment can be unspecified (NULL), in which case we use \\(scaling\\_increment = \\frac{1}{100}\\) if \\(\\log\\_scaling\\_change\\) is \\(FALSE\\), otherwise \\[\\begin{align*}\nscaling\\_increment & = \\left(1 - \\frac{1}{d}\\right) \\left(\\frac{\\sqrt{2\\pi}}{2A}\\exp\\left(\\frac{A ^ 2}{2}\\right)\\right)\\\\\n& \\quad \\quad + \\frac{1}{d * acceptance\\_target * (1 - acceptance\\_target)},\n\\end{align*}\\] where \\(A = -\\psi^{-1}(acceptance\\_target/2)\\) and \\(\\psi^{-1}\\) is the inverse cdf of a standard normal distribution.\nWe update scaling after iteration \\(i\\leq adapt\\_end\\) based on the acceptance probability at that iteration \\(\\alpha_i\\) with \\[\\begin{align*}\nscaling\\_change_i & = \\frac{scaling\\_increment}{\\sqrt{scaling\\_weight_i + \\max\\{0,\\, i - pre\\_diminish\\}}}(\\alpha_i - acceptance\\_target)\n\\end{align*}\\]\nthen\n\nif \\(log\\_scaling\\_change = TRUE\\): \\[\\begin{align*}\n\\log(\\lambda_i) & = \\max\\left\\{\\log(min\\_scaling), \\log(\\lambda_{i-1}) + scaling\\_change_i\\right\\}\n\\end{align*}\\]\nif \\(log\\_scaling\\_change = FALSE\\): \\[\\begin{align*}\n\\lambda_i = \\max\\left\\{min\\_scaling, \\lambda_{i-1} + scaling\\_change_i\\right\\}.\n\\end{align*}\\]\n\nSo when the acceptance probability is larger than acceptance_target the scaling is increased, whereas when the acceptance probability is larger than acceptance_target the scaling is decreased. After \\(adapt\\_end\\) iterations, we no longer update the scaling.\n\n\n\n\n13.2.2.1 Example: Adaptive vs. Non-adaptive Metropolis-Hastings\nBelow is a simple demonstration showing how to use the adaptive sampler on a multivariate Gaussian example, comparing it against the basic random-walk approach. The target Gaussian has some correlation in its variance-covariance matrix, so the adaptive sampler’s ability to learn this correlation on the fly can be advantageous.\nWe return to our a simple 2D (bivariate) Gaussian monty_model model:\n\n# Set up a simple 2D Gaussian model, with correlation\nVCV &lt;- matrix(c(1, 0.8, 0.8, 1), 2, 2)\nm &lt;- monty_example(\"gaussian\", VCV)\nm\n#&gt; \n#&gt; ── &lt;monty_model&gt; ───────────────────────────────────────────────────────────────\n#&gt; ℹ Model has 2 parameters: 'a' and 'b'\n#&gt; ℹ This model:\n#&gt; • can compute gradients\n#&gt; • can be directly sampled from\n#&gt; ℹ See `?monty_model()` for more information\n\nWe’ll start both samplers from the same initial value, away from the target space.\n\n# 1. Run RWMH starting away from target space\nsampler_rw &lt;- monty_sampler_random_walk(vcv)\nres_rw &lt;- monty_sample(m, sampler_rw, n_steps = 1000, initial = c(5, -5))\n\n# 2. Adaptive sampler:\nsampler_adaptive &lt;- monty_sampler_adaptive(\n  initial_vcv       = vcv,             # start from the same guess\n  initial_vcv_weight = 10,             # weight for the initial guess\n  initial_scaling    = 1,\n  acceptance_target  = 0.234,          # desired acceptance rate\n  forget_rate        = 0.2,            # regularly forget earliest samples\n  adapt_end          = 300,            # stop adapting after 300 iterations\n  boundaries         = \"reflect\"       # default reflection at domain edges\n)\n\n# Run adaptive samplers for 1,000 iterations\nres_adaptive &lt;- monty_sample(m, sampler_adaptive, n_steps = 1000, \n                             initial = c(5, -5))\n\nWe can then compare the chains\n\n# Compare the chains for parameter a\nplot(res_adaptive$pars[1, , ], type = \"l\", col = 4,   xlab = \"Iteration\",\n     ylab = \"a\", main = \"Comparison of RWMH vs. Adaptive M-H\")\nlines(res_rw$pars[1, , ], type = \"l\", col = 2)\n\nlegend(\"topright\", legend = c(\"Random-Walk\", \"Adaptive\"),\n       col = c(2, 4), lty = 1, bty = \"n\")\n\n\n\n\n\n\n\n\nand while the acceptance rate for the adaptive sampler is lower in this case\n\n## Acceptance rate of RW sampler\nsum(diff(c(res_rw$initial[1], res_rw$pars[1, , 1])) != 0) / 1000\n#&gt; [1] 0.369\n\n## Acceptance rate of adaptive sampler\nsum(diff(c(res_adaptive$initial[1], res_adaptive$pars[1, , 1])) != 0) / 1000\n#&gt; [1] 0.23\n\nthe adaptive sampler produces less autocorrelation\n\n\nacf(res_rw$pars[1, , 1], 200,\n    main = \"Autocorrelation of the RWMH samples\")\n\n\n\n\n\n\n\nacf(res_adaptive$pars[1, , 1], 200,\n    main = \"Autocorrelation of the Adaptive M-H samples\")\n\n\n\n\n\n\n\n\nand higher effective sample size (ESS)\n\ndf_rw &lt;- posterior::as_draws_df(res_rw)\nposterior::summarise_draws(df_rw)\n#&gt; # A tibble: 2 × 10\n#&gt;   variable   mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 a        -0.135 -0.215 0.905 0.864 -1.59  1.31  1.01     90.7    250. \n#&gt; 2 b        -0.214 -0.188 1.03  0.914 -1.78  1.24  1.01     69.8     75.4\n\ndf_adaptive &lt;- posterior::as_draws_df(res_adaptive)\nposterior::summarise_draws(df_adaptive)\n#&gt; # A tibble: 2 × 10\n#&gt;   variable     mean  median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 a         0.00304 -0.0141 0.949 0.962 -1.56  1.62  1.02     53.2     139.\n#&gt; 2 b        -0.126   -0.0800 1.00  1.13  -1.78  1.42  1.02     74.2     116.\n\nThis is because the initial estimate of the VCV had too small variance, so while the MHRW sampler moves more frequently, its moves a small so the target space is explored slowly. The adaptive sampler learns to move around the space more optimally.\nIn the above code:\n\nRandom-Walk Metropolis uses a fixed variance-covariance matrix (vcv_initial) throughout the chain.\nAdaptive Metropolis-Hastings starts with the same matrix but actively refines it. You should see that the adaptive sampler often converges to a better proposal distribution, leading to improved mixing and typically higher log densities (indicating that the chain is exploring the posterior more effectively).\n\nYou can also inspect the final estimated variance-covariance matrix from the adaptive sampler:\n\n# Show the final estimate of the VCV from the adaptive sampler\n# (s_adaptive$details is updated after each chain)\nest_vcv &lt;- res_adaptive$details$vcv\nprint(est_vcv)\n#&gt; , , 1\n#&gt; \n#&gt;           [,1]      [,2]\n#&gt; [1,] 1.3232696 0.8668864\n#&gt; [2,] 0.8668864 0.8093146\n\nOver many iterations, this matrix will reflect the empirical correlation structure of the target distribution—showing how the chain has “learned” the shape of the posterior. We can also plot the scaling factor to see how it evolved over the chain\n\nplot(res_adaptive$details$scaling_history, type = \"l\", xlab = \"Iteration\",\n     ylab = \"Scaling factor\")\n\n\n\n\n\n\n\n\n\nSummary\n- This Adaptive Metropolis-Hastings sampler is especially helpful in moderate to high dimensions or when the posterior exhibits nontrivial correlations.\n- By updating the proposal’s scale and shape in real time, it can achieve more stable acceptance rates and faster convergence compared to a fixed random-walk approach.\n- The user has fine-grained control via parameters like acceptance_target, forget_rate, and adapt_end, allowing adaptation to be tailored to the problem at hand.\nFeel free to experiment with different settings—particularly the forgetting and adaptation window parameters—to see how they affect convergence and mixing for your particular model.\n\n\n\n13.2.3 Hamiltonian Monte Carlo\nHamiltonian Monte Carlo (HMC) leverages gradient information of the log-density to make proposals in a more directed manner than random-walk approaches. By treating the parameters as positions in a physical system and introducing “momentum” variables, HMC uses gradient information to simulate Hamiltonian dynamics to propose new states. This often allows the sampler to traverse the parameter space quickly, reducing random-walk behaviour and yielding lower autocorrelation.\nUnder the hood, HMC introduces auxiliary “momentum” variables that share the same dimensionality as the parameters. At each iteration, the momentum is drawn from a suitable distribution (typically multivariate normal) that decides the initial (random) direction of the move. The algorithm then performs a series of leapfrog steps that evolve both the parameter and momentum variables forward in “fictitious time.” These leapfrog steps use the gradient of the log-posterior to move through parameter space in a way that avoids the random, diffusive behaviour of simpler samplers. Crucially, at the end of these steps, a Metropolis-style acceptance step ensures that the correct target distribution is preserved. For a more complete introduction, you can see (Neal 2011).\nTuning HMC involves setting parameters such as the step size (often denoted \\(\\epsilon\\)) and the number of leapfrog (or integration) steps. A small step size improves the accuracy of the leapfrog integrator but increases computational cost, whereas too large a step size risks poor exploration and lower acceptance rates. Likewise, the number of leapfrog steps determines how far the chain moves in parameter space before proposing a new sample. Balancing these factors can initially be more involved than tuning simpler methods like random-walk Metropolis. However, modern approaches - such as the No-U-Turn Sampler (NUTS) (Hoffman and Gelman 2014) - dynamically adjust these tuning parameters, making HMC more user-friendly and reducing the need for extensive manual calibration. Although NUTS is not yet available in monty, it is a high priority on our development roadmap.\nBy leveraging gradient information, HMC is often able to navigate complex, high-dimensional, or strongly correlated posteriors far more efficiently than random-walk-based approaches. Typically, it exhibits substantially lower autocorrelation in the resulting chains, meaning fewer samples are needed to achieve a given level of accuracy in posterior estimates. As a result, HMC has become a default choice in many modern Bayesian libraries (e.g. Stan, PyMC). Nevertheless, HMC’s reliance on smooth gradient information limits its applicability to models where the target density is differentiable - discontinuities can pose significant challenges. Moreover, while HMC can drastically reduce random-walk behaviour, the additional computations required for gradient evaluations and Hamiltonian integration mean that it is not always faster in absolute wall-clock terms, particularly for models with costly gradient functions.\n\n13.2.3.1 An Illustrative Example: The Bendy Banana\nTo see HMC in action, we can compare it against a random-walk Metropolis sampler on a two-dimensional “banana”-shaped function. Our model takes two parameters alpha and beta, and is based on two successive simple draws, with one conditional on the other, so \\(\\beta \\sim Normal(1,0)\\) and \\(\\alpha \\sim Normal(\\beta^2, \\sigma)\\), with \\(\\sigma\\) the standard deviation of the conditional draw.\nWe include this example within the package; here we create a model with \\(\\sigma = 0.5\\):\n\nm &lt;- monty_example(\"banana\", sigma = 0.5)\nm\n#&gt; \n#&gt; ── &lt;monty_model&gt; ───────────────────────────────────────────────────────────────\n#&gt; ℹ Model has 2 parameters: 'alpha' and 'beta'\n#&gt; ℹ This model:\n#&gt; • can compute gradients\n#&gt; • can be directly sampled from\n#&gt; • accepts multiple parameters\n#&gt; ℹ See `?monty_model()` for more information\n\nWe can plot a visualisation of its density by computing the density over a grid. Normally this is not possible, but here it’s small enough to illustrate:\n\na &lt;- seq(-2, 6, length.out = 1000)\nb &lt;- seq(-2.5, 2.5, length.out = 1000)\nz &lt;- outer(a, b, function(alpha, beta) {\n  exp(monty_model_density(m, rbind(alpha, beta)))\n})\nimage(a, b, z, xlab = \"alpha\", ylab = \"beta\")\n\n\n\n\n\n\n\n\nIn this particular case we can also easily generate samples directly from the model, so we know what a good sampler should produce:\n\nrng &lt;- monty_rng_create()\ns &lt;- vapply(seq(200), function(x) monty_model_direct_sample(m, rng), numeric(2))\nimage(a, b, z, xlab = \"alpha\", ylab = \"beta\")\npoints(s[1, ], s[2, ], pch = 19, col = \"#00000055\")\n\n\n\n\n\n\n\n\nIt is also possible to compute the 95% confidence interval of the distribution using the relationship between the standard bivariate normal distribution and the banana-shaped distribution as defined above. We can check that roughly 10 samples (out of 200) are out of this 95% CI contour:\n\ntheta &lt;- seq(0, 2 * pi, length.out = 10000)\nz95 &lt;- local({\n  sigma &lt;- 0.5\n  r &lt;- sqrt(qchisq(.95, df = 2))\n  x &lt;- r * cos(theta)\n  y &lt;- r * sin(theta)\n  cbind(x^2 + y * sigma, x)\n})\nimage(a, b, z, xlab = \"alpha\", ylab = \"beta\")\nlines(z95[, 1], z95[, 2])\npoints(s[1, ], s[2, ], pch = 19, col = \"#00000055\")\n\n\n\n\n\n\n\n\n\n13.2.3.1.1 Random-Walk Metropolis on the Banana\nIt is not generally possible to directly sample from a density (otherwise MCMC and similar methods would not exist!). In these cases, we need to use a sampler based on the density and - if available - the gradient of the density.\nWe can start with a basic random-walk sampler to see how it performs on the banana distribution:\n\nsampler_rw &lt;- monty_sampler_random_walk(vcv = diag(2) * 0.01)\nres_rw &lt;- monty_sample(m, sampler_rw, 1000)\n#&gt; ⡀⠀ Sampling  ■                                |   0% ETA:  1s\n#&gt; ✔ Sampled 1000 steps across 1 chain in 40ms\n#&gt; \nplot(t(drop(res_rw$pars)), type = \"l\", col = \"#0000ff66\",\n     xlim = range(a), ylim = range(b))\nlines(z95[, 1], z95[, 2])\n\n\n\n\n\n\n\n\nAs we can see, this is not great, exhibiting strong random-walk behaviour as it slowly explores the surface (this is over 1,000 steps).\nAnother way to view this is by plotting parameters over steps:\n\nmatplot(t(drop(res_rw$pars)), lty = 1, type = \"l\", col = c(2, 4),\n        xlab = \"Step\", ylab = \"Value\")\n\n\n\n\n\n\n\n\nWe could try improving the samples here by finding a better variance-covariance matrix (VCV), but the banana shape means a single VCV will not be ideal across the whole space.\n\n\n13.2.3.1.2 Hamiltonian Monte Carlo on the Banana\nNow let’s try the Hamiltonian Monte Carlo (HMC) sampler, which uses gradient information to move more efficiently in parameter space:\n\nsampler_hmc &lt;- monty_sampler_hmc(epsilon = 0.1, n_integration_steps = 10)\nres_hmc &lt;- monty_sample(m, sampler_hmc, 1000)\nplot(t(drop(res_hmc$pars)), type = \"l\", col = \"#0000ff33\",\n     xlim = range(a), ylim = range(b))\nlines(z95[, 1], z95[, 2])\n\n\n\n\n\n\n\n\nOr viewed over steps:\n\nmatplot(t(drop(res_hmc$pars)), lty = 1, type = \"l\", col = c(2, 4),\n        xlab = \"Step\", ylab = \"Value\")\n\n\n\n\n\n\n\n\nClearly, HMC outperforms the random walk, rapidly exploring the full banana-shaped region with far less random wander.\n\n\n\n\n13.2.4 Parallel Tempering Sampler\nParallel tempering (also known as replica exchange MCMC) is a technique designed to improve the mixing of Markov chain Monte Carlo methods, particularly in situations where the posterior distribution is multimodal or somehow challenging to explore.\nLet’s for example define a simple Bayesian model where the likelihood is a mixture model:\n\nex_mixture &lt;- function(x) log(dnorm(x, mean = 5) / 2 + dnorm(x, mean = -5) / 2)\nlikelihood &lt;- monty_model_function(ex_mixture, allow_multiple_parameters = TRUE)\n\nand the prior is a normal distribution with a wider variance:\n\nprior &lt;- monty_dsl({\n  x ~ Normal(0, 10)\n})\n\nand the posterior is simply the product of the two (or the sum if working with log-densities)\n\nposterior &lt;- likelihood + prior\n\n\nx &lt;- seq(-10, 10, length.out = 1001)\ny &lt;- exp(posterior$density(rbind(x)))\nplot(x, y / sum(y) / diff(x)[[1]], col = \"red\", type = 'l', ylab = \"density\")\n\n\n\n\n\n\n\n\nWe’ll try to use the random walk Metropolis-Hastings sampler for this model\n\nvcv &lt;- matrix(1.5)\nsampler_rw &lt;- monty_sampler_random_walk(vcv = vcv)\n\nOnce the sampler is built, the generic monty_sample() function can be used to generate samples:\n\nres_rw &lt;- monty_sample(posterior, sampler_rw, n_steps = 1000)\n#&gt; ⡀⠀ Sampling  ■                                |   0% ETA:  3s\n#&gt; ✔ Sampled 1000 steps across 1 chain in 81ms\n#&gt; \n\n\nplot(res_rw$pars[1, , ],\n     ylim = c(-8, 8),\n     ylab = \"Value\",\n     main = \"RW samples (1 chain)\")\nabline(h = -5, lty = 3, col = \"red\")\nabline(h = 5, lty = 3, col = \"red\")\n\n\n\n\n\n\n\n\nAs we can see, the RW sampler does not manage to move outside of the mode that it starts from. MCMC theory tells us that it will eventually reach the other side of the distribution, whether with a (low probability) large jump or by accepting several consecutive small disadvantageous steps in the right direction. In practice, it can mean that the second mode might never be explored in the finite amount of time allowed for sampling.\nOne might think that running multiple chains from different initial values could solve the problem. Suppose then that we run three chains, starting at values -5, 0 and 5:\n\nres_rw3 &lt;- monty_sample(posterior, sampler_rw, n_steps = 1000, n_chains = 3,\n                        initial = rbind(c(-5, 0, 5)))\n\n\nmatplot(res_rw3$pars[1, , ], type = \"p\", pch = 21,\n        col = c(\"blue\", \"green\", \"purple\"),\n        ylim = c(-8, 8), ylab = \"Value\", main = \"RW samples (3 chains)\")\nabline(h = -5, lty = 3, col = \"red\")\nabline(h = 5, lty = 3, col = \"red\")\n\n\n\n\n\n\n\n\nWe can see with our three chains, we are exploring both modes, with \\(\\frac{1}{3}\\) of our samples from one mode and \\(\\frac{2}{3}\\) the other, which we know is not representative of the true distribution! So even if running multiple chains manages to help identify and explore more than one local mode, they cannot tell you anything about the relative densities of those modes if each chain ends up only exploring a single mode. Furthermore, there is no guarantee that simply running multiple chains from different starting points will even identify all modes, particularly in higher dimensions. We need a better way to make use of multiple chains, and that’s where parallel tempering comes in.\nThe core idea behind parallel tempering is to run multiple chains at different “temperatures” - where the posterior is effectively flattened or softened at higher temperatures - allowing the “hot” chains to move more freely across parameter space. Periodically, the states of the chains are swapped according to an acceptance rule that preserves the correct stationary distribution. The hope is that the higher-temperature chains will quickly explore multiple modes, and then swap states with the lower-temperature chains, thereby transferring information about other modes and improving overall exploration.\nThis can also be beneficial if your model can efficiently evaluate multiple points in parallel (via parallelisation or vectorisation). Even though parallel tempering runs multiple chains, the computational cost can be partly offset by improved mixing or by leveraging multiple CPU cores.\nIn monty, parallel tempering is implemented in the function monty_sampler_parallel_tempering() based on the non-reversible swap approach (Syed et al. 2022). We will use the RW sampler to sample with each chain within the parallel tempering sampler, but other samplers can also be used.\n\nvcv &lt;- matrix(1.5)\nsampler_rw &lt;- monty_sampler_random_walk(vcv = vcv)\n\ns &lt;- monty_sampler_parallel_tempering(sampler_rw, n_rungs = 10)\n\nHere, n_rungs specifies the number of additional chains (beyond the base chain) to run at different temperatures (so total chains = n_rungs + 1). The argument vcv is the variance-covariance matrix that will be passed to the underlying random-walk sampler. An optional base argument can be used to specify a “reference” model if your original model cannot be automatically decomposed into prior and posterior components, or if you want an alternative easy-to-sample-from distribution for the hottest rung.\n\nres_pt &lt;- monty_sample(posterior, s, 1000, n_chains = 1)\n\n\nplot(res_pt$pars[1,,],\n     ylim = c(-8, 8),\n     ylab = \"Value\",\n     main = \"PT samples\")\nabline(h = -5, lty = 3, col = \"red\")\nabline(h = 5, lty = 3, col = \"red\")\n\n\n\n\n\n\n\n\n\nhist(c(res_pt$pars), freq = FALSE,\n     xlab = \"Values of samples\",\n     main = \"Parallel tempering samples\")\nx &lt;- seq(min(res_pt$pars), max(res_pt$pars), length.out = 1001)\ny &lt;- exp(posterior$density(rbind(x)))\nlines(x, y / sum(y) / diff(x)[[1]], col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA parallel tempering sampler performs more total computations than a single-chain sampler because it runs multiple chains simultaneously (n_rungs + 1 chains) with only the “coldest” chain targeting the distribution of interest. However, there are scenarios where this additional cost pays off:\n\nParallelisation: If your model can be efficiently evaluated across multiple cores, the wall-clock time may not be much larger than for a single chain - though CPU usage will naturally be higher.\nVectorisation: In R, if the density calculations can be vectorised, then evaluating multiple chains in one go (in a vectorised manner) may not cost significantly more than evaluating a single chain.\nMultimodality: In models with multiple distinct modes, standard samplers often get “stuck” in a single mode. Parallel tempering can swap states between chains at different temperatures, making it more likely to fully explore all modes, thereby improving posterior exploration and reducing the risk of biased inference.\n\n\n\n\n\n\n\nHoffman, Matthew D, and Andrew Gelman. 2014. “The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.” Journal of Machine Learning Research 15: 1351–81. http://mcmc-jags.sourceforge.net.\n\n\nNeal, Radford M. 2011. “MCMC Using Hamiltonian Dynamics.” In Handbook of Markov Chain Monte Carlo, 113–62. https://doi.org/10.1201/b10905-6.\n\n\nSpencer, Simon E. F. 2021. “Accelerating Adaptation in the Adaptive Metropolis–Hastings Random Walk Algorithm.” Australian & New Zealand Journal of Statistics 63 (3): 468–84. https://doi.org/https://doi.org/10.1111/anzs.12344.\n\n\nSyed, Saifuddin, Alexandre Bouchard-Côté, George Deligiannidis, and Arnaud Doucet. 2022. “Non-Reversible Parallel Tempering: A Scalable Highly Parallel MCMC Scheme.” Journal of the Royal Statistical Society Series B: Statistical Methodology 84 (2): 321–50. https://doi.org/10.1111/rssb.12464.",
    "crumbs": [
      "Monty",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Samplers and inference</span>"
    ]
  },
  {
    "objectID": "inference.html",
    "href": "inference.html",
    "title": "14  Inference",
    "section": "",
    "text": "14.1 Recap\nGetting started with inference on odin models. In this chapter, we will fit the simple SIR model from Section 7.3; this combines all three packages together and tries to demonstrate some of the flexibility we are aiming for.\nOur basic odin code describes an SIR system. We compute daily incidence using zero_every in the initial conditions and compare this to case data using a Poison likelihood:\nsir &lt;- odin({\n  update(S) &lt;- S - n_SI\n  update(I) &lt;- I + n_SI - n_IR\n  update(R) &lt;- R + n_IR\n  update(incidence) &lt;- incidence + n_SI\n\n  p_SI &lt;- 1 - exp(-beta * I / N * dt)\n  p_IR &lt;- 1 - exp(-gamma * dt)\n  n_SI &lt;- Binomial(S, p_SI)\n  n_IR &lt;- Binomial(I, p_IR)\n\n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  initial(R) &lt;- 0\n  initial(incidence, zero_every = 1) &lt;- 0\n\n  N &lt;- parameter(1000)\n  I0 &lt;- parameter(10)\n  beta &lt;- parameter(0.2)\n  gamma &lt;- parameter(0.1)\n\n  cases &lt;- data()\n  cases ~ Poisson(incidence)\n})\nsir\n#&gt; \n#&gt; ── &lt;dust_system_generator: odin_system&gt; ────────────────────────────────────────\n#&gt; ℹ This system has 'compare_data' support\n#&gt; ℹ This system runs in discrete time with a default dt of 1\n#&gt; ℹ This system has 4 parameters\n#&gt; → 'N', 'I0', 'beta', and 'gamma'\n#&gt; ℹ Use dust2::dust_system_create() (`?dust2::dust_system_create()`) to create a system with this generator\n#&gt; ℹ Use coef() (`?stats::coef()`) to get more information on parameters\nWe are looking to fit this to a small (synthetic) data set data/incidence.csv.\nd &lt;- read.csv(\"data/incidence.csv\")\nhead(d)\n#&gt;   time cases\n#&gt; 1    1    12\n#&gt; 2    2    23\n#&gt; 3    3    25\n#&gt; 4    4    36\n#&gt; 5    5    30\n#&gt; 6    6    57\nWe have constructed a particle filter with this system and data, with which we can compute likelihoods:\nfilter &lt;- dust_filter_create(sir, time_start = 0, data = d, n_particles = 200)\ndust_likelihood_run(filter, list(beta = 0.3, gamma = 0.15, I0 = 50))\n#&gt; [1] -81.42941",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Inference</span>"
    ]
  },
  {
    "objectID": "inference.html#sec-MCMC",
    "href": "inference.html#sec-MCMC",
    "title": "14  Inference",
    "section": "14.2 Running an MCMC",
    "text": "14.2 Running an MCMC\nOur aim is to fit the parameters beta, gamma and I0 using MCMC (because this is an MCMC using a particle filter we might call this pMCMC).\nThe first challenge is that our filter takes a named list of inputs, but any MCMC we run will work in terms of a vector of parameter space. In this case it seems trivial, we should be able to take a vector of numbers c(0.3, 0.15, 50), stick some names on them and convert to a list with as.list(). However, as seen in the more complex models (e.g., in Chapter 4) this won’t be generally possible.\nOur solution is to use monty_packer objects to smooth this transition:\n\npacker &lt;- monty_packer(c(\"beta\", \"gamma\", \"I0\"))\npacker\n#&gt; \n#&gt; ── &lt;monty_packer&gt; ──────────────────────────────────────────────────────────────\n#&gt; ℹ Packing 3 parameters: 'beta', 'gamma', and 'I0'\n#&gt; ℹ Use '$pack()' to convert from a list to a vector\n#&gt; ℹ Use '$unpack()' to convert from a vector to a list\n#&gt; ℹ See `?monty_packer()` for more information\n\nYou can use a packer object to fix other inputs to your system. For example, we might write:\n\npacker &lt;- monty_packer(c(\"beta\", \"gamma\", \"I0\"), fixed = list(N = 1000))\n\nwhich fixes N to 1000. This is an input to our system, but not an input to the statistical process.\nWe can combine our filter and packer together to make a monty_model object:\n\nlikelihood &lt;- dust_likelihood_monty(filter, packer)\nlikelihood\n#&gt; \n#&gt; ── &lt;monty_model&gt; ───────────────────────────────────────────────────────────────\n#&gt; ℹ Model has 3 parameters: 'beta', 'gamma', and 'I0'\n#&gt; ℹ This model:\n#&gt; • is stochastic\n#&gt; ℹ See `?monty_model()` for more information\n\nAt this point, we can “forget” that our likelihood is an SIR model, and instead just note that it is a stochastic estimate of a likelihood.\nThe other ingredient we need is a prior. This we can construct with monty_dsl as before:\n\nprior &lt;- monty_dsl({\n  beta ~ Exponential(mean = 0.3)\n  gamma ~ Exponential(mean = 0.1)\n  I0 ~ Uniform(1, 50)\n})\n\nWe use broad exponential priors on beta and gamma but with a higher mean for beta (reflecting our prior belief that an epidemic did happen) and a uniform prior for the initial number of infected individuals.\nOur posterior is the product of the likelihood and prior, or the sum of their logs:\n\nposterior &lt;- likelihood + prior\n\nNext, we define a sampler; we’ll start with a random walk with a fairly arbitrary diagonal proposal matrix:\n\nvcv &lt;- diag(3) * 0.0004\nsampler &lt;- monty_sampler_random_walk(vcv)\n\nWe start this off, using explicit initial conditions\n\nsamples &lt;- monty_sample(posterior, sampler, 1000, initial = c(0.3, 0.1, 5),\n                        n_chains = 3)\n#&gt; ⡀⠀ Sampling [▁▁▁] ■                                |   0% ETA: 18s\n#&gt; ⠄⠀ Sampling [██▆] ■■■■■■■■■■■■■■■■■■■■■■■■■■■■     |  92% ETA:  0s\n#&gt; ✔ Sampled 3000 steps across 3 chains in 2.9s\n#&gt; \n\n\n\n\n\n\n\nNote\n\n\n\nWe have used explicit initial conditions here, which might not be what you want in all situations. Better might be to sample from the prior, but we have not yet implemented support to try a few points from the sample before getting a point with finite density, which is really needed here.\n\n\nHere the log posterior density of our three chains over time, showing a rapid improvement in the posterior probability density followed by what might be reasonable (but not great) mixing:\n\nmatplot(samples$density, type = \"l\", lty = 1,\n        xlab = \"Sample\", ylab = \"Log posterior probability density\")\n\n\n\n\n\n\n\n\n\n14.2.1 Working with samples\nThe samples that we get back contain sampled densities and parameters; they are described more in vignette(\"samples\", package = \"monty\")\n\nsamples\n#&gt; \n#&gt; ── &lt;monty_samples: 3 parameters x 1000 samples x 3 chains&gt; ─────────────────────\n#&gt; ℹ Parameters: 'beta', 'gamma', and 'I0'\n#&gt; ℹ Conversion to other types is possible:\n#&gt; → ! posterior::as_draws_array() [package installed, but not loaded]\n#&gt; → ! posterior::as_draws_df() [package installed, but not loaded]\n#&gt; → ! coda::as.mcmc.list() [package installed, but not loaded]\n#&gt; ℹ See `?monty_sample()` and `vignette(\"samples\")` for more information\n\nYou can convert them into other formats, for example the posterior package:\n\nsamples_df &lt;- posterior::as_draws_df(samples)\nsamples_df\n#&gt; # A draws_df: 1000 iterations, 3 chains, and 3 variables\n#&gt;    beta gamma I0\n#&gt; 1  0.32 0.083  5\n#&gt; 2  0.32 0.083  5\n#&gt; 3  0.32 0.083  5\n#&gt; 4  0.32 0.083  5\n#&gt; 5  0.32 0.083  5\n#&gt; 6  0.32 0.083  5\n#&gt; 7  0.31 0.117  5\n#&gt; 8  0.31 0.117  5\n#&gt; 9  0.31 0.148  5\n#&gt; 10 0.31 0.148  5\n#&gt; # ... with 2990 more draws\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\nWe don’t implement any diagnostics in monty itself, and suggest that you use the diagnostics available in these other packages, for example:\n\nposterior::summarise_draws(samples_df)\n#&gt; # A tibble: 3 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 beta     0.623  0.586 0.218 0.268 0.360 0.950  2.15     3.90     24.2\n#&gt; 2 gamma    0.449  0.400 0.246 0.271 0.148 0.840  2.27     3.78     16.9\n#&gt; 3 I0       5.10   5.04  0.166 0.111 4.95  5.44   1.94     4.26     16.1\n\n\n\n\n\n\n\nWarning\n\n\n\nThis section needs expanding to help us see how much work this set of samples needs before moving into the next section, though some of that will better go in the previous monty section most likely?",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Inference</span>"
    ]
  },
  {
    "objectID": "inference.html#extracting-trajectories-while-we-sample",
    "href": "inference.html#extracting-trajectories-while-we-sample",
    "title": "14  Inference",
    "section": "14.3 Extracting trajectories while we sample",
    "text": "14.3 Extracting trajectories while we sample\nA complication of running these dynamical models is that we are interested in more than just the sampled parameters; we’re interested in how the system evolved over time given these parameters. However, because the model is stochastic we can’t simply simulate over time given the parameters because that may not be representative of the inferred time-series when the particle filter ran (see Chapter 7). We need some way of sampling trajectories while the sampler runs, and storing these alongside the samples, which will give us a paired set of parameters and their histories.\nThe simplest way of doing this is to specify save_trajectories = TRUE when constructing the monty model from the filter:\n\nlikelihood &lt;- dust_likelihood_monty(filter, packer, save_trajectories = TRUE)\n\nThis adds a monty observer to the model:\n\nlikelihood\n#&gt; \n#&gt; ── &lt;monty_model&gt; ───────────────────────────────────────────────────────────────\n#&gt; ℹ Model has 3 parameters: 'beta', 'gamma', and 'I0'\n#&gt; ℹ This model:\n#&gt; • is stochastic\n#&gt; • has an observer\n#&gt; ℹ See `?monty_model()` for more information\n\nWe then proceed as before:\n\nposterior &lt;- likelihood + prior\nsamples &lt;- monty_sample(posterior, sampler, 1000, initial = c(0.3, 0.1, 5),\n                        n_chains = 3)\n#&gt; ⡀⠀ Sampling [██▂] ■■■■■■■■■■■■■■■■■■■■■■■          |  75% ETA:  1s\n#&gt; ✔ Sampled 3000 steps across 3 chains in 3s\n#&gt; \nsamples\n#&gt; \n#&gt; ── &lt;monty_samples: 3 parameters x 1000 samples x 3 chains&gt; ─────────────────────\n#&gt; ℹ Parameters: 'beta', 'gamma', and 'I0'\n#&gt; ℹ Conversion to other types is possible:\n#&gt; → ✔ posterior::as_draws_array() [package loaded]\n#&gt; → ✔ posterior::as_draws_df() [package loaded]\n#&gt; → ! coda::as.mcmc.list() [package installed, but not loaded]\n#&gt; ℹ These samples have associated observations\n#&gt; ℹ See `?monty_sample()` and `vignette(\"samples\")` for more information\n\nAs before we have a 3-dimensional array of parameters (3 parameters x 1000 steps x 3 chains)\n\ndim(samples$pars)\n#&gt; [1]    3 1000    3\n\nBut we also have a new set of “observations” in the $observations element. The trajectories element of this contains our trajectories:\n\ndim(samples$observations$trajectories)\n#&gt; [1]    4   20 1000    3\n\nThe trajectories are a 4-dimensional array (4 states x 20 time points x 1000 samples x 3 chains). Trajectories will get very large very quickly; this small example generates around 2MB of data so we only need do increase by a factor of 1000 to start running into the limits of RAM on small machines, and this is surprisingly easy to do in practice.\n\nobject.size(samples$observations$trajectories)\n#&gt; 1920224 bytes\n\nThe trajectories that we return here are in the same order as the parameters (the 1000 x 3 dimensions at the end of each object), so you have a pairing of parameters with trajectories.",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Inference</span>"
    ]
  },
  {
    "objectID": "inference.html#next-steps",
    "href": "inference.html#next-steps",
    "title": "14  Inference",
    "section": "14.4 Next steps",
    "text": "14.4 Next steps\nThe next steps here:\n\ncontinue that chain without the burn-in (needs a monty tweak)\nadd an observer so we can see what is going on\nrun multiple chains and get started with diagnostics\n\nIn other chapters eventually\n\ndeterministic fits\nrun multiple groups\nworking with larger models\nthinning while running\nonward simulation\nrestarts (once enabled)\nmultistage fits (once enabled)",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Inference</span>"
    ]
  },
  {
    "objectID": "counterfactuals.html",
    "href": "counterfactuals.html",
    "title": "15  Projections and counterfactuals",
    "section": "",
    "text": "15.1 Introduction\nlibrary(odin2)\nlibrary(dust2)\nlibrary(monty)\nWe have seen how to fit odin models with monty to produce estimates of fitted parameters and the trajectories of the underlying model. It is common to use such outputs for either of the following:\nGenerally, both of these require that you configure your likelihood object created with dust_likelihood_monty to save additional information about the filtering process, via the save_state or save_snapshots inputs. As with saving fitted trajectories via the save_trajectories input, the outputs can only be extracted after running your sampler if you specified to save them when setting up the likelihood object. It is not possible to extract such information retrospectively so it is important that you set things up correctly.\nIn the following we’ll illustrate how to correctly setup the likelihood object and then how to use the sampled output from fitting to run both projections and counterfactuals. We begin with some basic setup for an example of an SIS model incorporating school opening and closing, before moving onto the specific implementation for projections and then counterfactuals.\nsis &lt;- odin({\n  update(S) &lt;- S - n_SI + n_IS\n  update(I) &lt;- I + n_SI - n_IS\n  update(incidence) &lt;- incidence + n_SI\n  \n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  initial(incidence, zero_every = 1) &lt;- 0\n  \n  schools &lt;- interpolate(schools_time, schools_open, \"constant\")\n  schools_time &lt;- parameter()\n  schools_open &lt;- parameter()\n  dim(schools_time, schools_open) &lt;- parameter(rank = 1)\n  \n  beta &lt;- ((1 - schools) * (1 - schools_modifier) + schools) * beta0\n  \n  p_SI &lt;- 1 - exp(-beta * I / N * dt)\n  p_IS &lt;- 1 - exp(-gamma * dt)\n  n_SI &lt;- Binomial(S, p_SI)\n  n_IS &lt;- Binomial(I, p_IS)\n  \n  N &lt;- parameter(1000)\n  I0 &lt;- parameter(10)\n  beta0 &lt;- parameter()\n  gamma &lt;- parameter()\n  schools_modifier &lt;- parameter()\n  \n  cases &lt;- data()\n  cases ~ Poisson(incidence)\n})\nWe will fit this model to some case data.\ndata &lt;- read.csv(\"data/schools.csv\")\nplot(data, pch = 19, col = \"red\")\nWe’ll assume we know the times of schools opening and closing\nschools_time &lt;- c(0, 50, 60, 120, 130, 170, 180)\nschools_open &lt;- c(1,  0,  1,   0,   1,   0,   1)\nand we will fit the parameters beta0, gamma and schools_modifier\npacker &lt;- monty_packer(c(\"beta0\", \"gamma\", \"schools_modifier\"),\n                       fixed = list(schools_time = schools_time,\n                                    schools_open = schools_open))\n\nprior &lt;- monty_dsl({\n  beta0 ~ Exponential(mean = 0.3)\n  gamma ~ Exponential(mean = 0.1)\n  schools_modifier ~ Uniform(0, 1)\n})\nWe will create our filter object, starting at time = 0 with dt = 0.25, and setup our sampler\ntime_start &lt;- 0\ndt &lt;- 0.25\nfilter &lt;- dust_filter_create(sis, time_start = time_start, dt = dt,\n                             data = data, n_particles = 200)\n\n\n\nvcv &lt;- diag(c(2e-4, 2e-4, 4e-4))\nsampler &lt;- monty_sampler_random_walk(vcv)",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Projections and counterfactuals</span>"
    ]
  },
  {
    "objectID": "counterfactuals.html#introduction",
    "href": "counterfactuals.html#introduction",
    "title": "15  Projections and counterfactuals",
    "section": "",
    "text": "Projections - running the model forward from the end of fitted time series to estimate what would happen under given choices of parameters.\nCounterfactuals - estimating what would have happened had parameters been different from those estimated from or assumed in the fits. This could be run from the initial time used in fitting, or from a point in the data time series.",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Projections and counterfactuals</span>"
    ]
  },
  {
    "objectID": "counterfactuals.html#projections",
    "href": "counterfactuals.html#projections",
    "title": "15  Projections and counterfactuals",
    "section": "15.2 Projections",
    "text": "15.2 Projections\nWe want to run projections from the state of the model at the end of the time series. This is not saved by default so in order to do this we need to specify save_state = TRUE when setting up our dust likelihood object. After obtaining our samples we will thin them, resulting in a sample size of 200 in this case.\n\nlikelihood &lt;- dust_likelihood_monty(filter, packer, save_trajectories = TRUE,\n                                    save_state = TRUE)\n\nposterior &lt;- likelihood + prior\n\nsamples &lt;- monty_sample(posterior, sampler, 500, initial = c(0.3, 0.1, 0.5),\n                        n_chains = 4)\nsamples &lt;- monty_samples_thin(samples, burnin = 100, thinning_factor = 8)\ntraj_fit &lt;- dust_unpack_state(filter, samples$observations$trajectories)\n\nThe saved state can be found in samples$observations. First we will flatten out the chains dimension of this and the fitted parameters, and unpack each vector of fitted parameters to produce a list (of length equal to the sample size) of list of parameters required by our odin model.\n\nstate &lt;- array(samples$observations$state, c(3, 200))\npars &lt;- array(samples$pars, c(3, 200))\npars &lt;- lapply(seq_len(200), function(i) packer$unpack(pars[, i]))\n\nWe create a dust system using our compiled odin model and these parameters, to start at time = 150 (the final timepoint in the data time series). We set n_particles = 1 to run once per parameter set.\n\nsys &lt;- dust_system_create(sis, pars, time = 150, n_particles = 1,\n                          n_groups = length(pars), dt = dt)\n\nWe then set the state of the system with the end state from fitting and simulate\n\ndust_system_set_state(sys, state)\n\nt &lt;- seq(150, 200)\nres &lt;- dust_system_simulate(sys, t)\ntraj_projection &lt;- dust_unpack_state(sys, res)\n\nWe can then plot our projections\n\nincidence_fit &lt;- array(traj_fit$incidence, c(150, 200))\nmatplot(data$time, incidence_fit, type = \"l\", col = \"#00000044\", lty = 1,\n        xlab = \"Time\", ylab = \"Incidence\", xlim = c(0, 200))\nmatlines(t, t(traj_projection$incidence), col = \"blue\")\npoints(data, pch = 19, col = \"red\")",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Projections and counterfactuals</span>"
    ]
  },
  {
    "objectID": "counterfactuals.html#counterfactuals",
    "href": "counterfactuals.html#counterfactuals",
    "title": "15  Projections and counterfactuals",
    "section": "15.3 Counterfactuals",
    "text": "15.3 Counterfactuals\nCounterfactuals are used to examine what would have happened if certain parameters (fitted or fixed) had been different. Broadly there are two types of counterfactuals\n\nCounterfactuals run from the beginning of the model - when a change of parameters would result in the counterfactual diverging from the fitted trajectories from the very beginning\nCounterfactuals run from a timepoint in the data timeseries - when a change of parameters would result in the counterfactual diverging from the fitted trajectories only from that given timepoint onwards, and everything before that should be the same as the fitted trajectories.\n\n\n15.3.1 Running counterfactuals from the beginning\nSuppose we want to examine what would happen if the infection rate was reduced by 20%. This would affect the model from the beginning - we can just run a simulation from the start time. There is nothing that we are required to save while fitting in order to do this (although we will save trajectories from fitting to compare those to the counterfactual trajectories).\n\nlikelihood &lt;- dust_likelihood_monty(filter, packer, save_trajectories = TRUE)\n\nposterior &lt;- likelihood + prior\n\nsamples &lt;- monty_sample(posterior, sampler, 500, initial = c(0.3, 0.1, 0.5),\n                        n_chains = 4)\nsamples &lt;- monty_samples_thin(samples, burnin = 100, thinning_factor = 8)\ntraj_fit &lt;- dust_unpack_state(filter, samples$observations$trajectories)\n\nWe will unpack the fitted parameters into a list (of length equal to the sample size) of lists of parameters\n\npars &lt;- array(samples$pars, c(3, 200))\npars &lt;- lapply(seq_len(200), function(i) packer$unpack(pars[, i]))\n\nWe will then use a function to multiply beta0 by 0.8 in each parameter list.\n\nf &lt;- function(p) {\n  p$beta0 &lt;- 0.8 * p$beta0\n  p\n}\npars &lt;- lapply(pars, f)\n\nWe create a dust system setting the time to the start time used in the fitting. We set the state to the initial state as defined in the odin code, and simulate.\n\nsys &lt;- dust_system_create(sis, pars, n_particles = 1, n_groups = length(pars),\n                          time = time_start, dt = dt)\n\ndust_system_set_state_initial(sys)\nt &lt;- seq(0, 150)\nres &lt;- dust_system_simulate(sys, t)\ntraj_counterfactual &lt;- dust_unpack_state(sys, res)\n\nWe can then plot the results to compare the fitted trajectories to the counterfactual ones.\n\nincidence_fit &lt;- array(traj_fit$incidence, c(150, 200))\nmatplot(data$time, incidence_fit, type = \"l\", col = \"#00000044\", lty = 1,\n        xlab = \"Time\", ylab = \"Incidence\")\nmatlines(t, t(traj_counterfactual$incidence), col = \"blue\")\npoints(data, pch = 19, col = \"red\")\n\n\n\n\n\n\n\n\nNote that the trajectories from fitting are produced by filtering to the data, whereas the counterfactual trajectories are produced from unfiltered simulation. This is why we see much more variance in the counterfactual trajectories.\n\n\n15.3.2 Running counterfactuals from a timepoint in the data time series\nSuppose now we want to examine what would have happened if schools had not opened at time = 60 (as they had in our fitting) and had instead stayed closed until time = 130. This counterfactual would diverge from the fitted trajectories at time = 60. To implement this counterfactual we need to save a “snapshot” of the state at time = 60.\n\nlikelihood &lt;- dust_likelihood_monty(filter, packer, save_trajectories = TRUE,\n                                    save_snapshots = 60)\n\nposterior &lt;- likelihood + prior\n\nsamples &lt;- monty_sample(posterior, sampler, 500, initial = c(0.3, 0.1, 0.5),\n                        n_chains = 4)\nsamples &lt;- monty_samples_thin(samples, burnin = 100, thinning_factor = 8)\ntraj_fit &lt;- dust_unpack_state(filter, samples$observations$trajectories)\n\nWe will unpack the fitted parameters into a list (of length equal to the sample size) of lists of parameters\n\npars &lt;- array(samples$pars, c(3, 200))\npars &lt;- lapply(seq_len(200), function(i) packer$unpack(pars[, i]))\n\nand use a function to change schools_time and schools_open within each list of parameters\n\nf &lt;- function(p) {\n  p$schools_time &lt;- c(0, 50, 130, 170, 180)\n  p$schools_open &lt;- c(1, 0, 1, 0, 1)\n  p\n}\npars &lt;- lapply(pars, f)\n\nWe create a dust system setting the time to the start time of our counterfactual, set the state of the system using our snapshot (reshaping to remove the chains dimension first) and simulate.\n\nsys &lt;- dust_system_create(sis, pars, n_particles = 1, n_groups = length(pars),\n                          time = 60, dt = dt)\n\nsnapshot &lt;- array(samples$observations$snapshots, c(3, 200))\ndust_system_set_state(sys, snapshot)\n\nt &lt;- seq(60, 150)\nres &lt;- dust_system_simulate(sys, t)\ntraj_counterfactual &lt;- dust_unpack_state(sys, res)\n\nWe can then plot the results to compare the fitted trajectories to the counterfactual ones.\n\nincidence_fit &lt;- array(traj_fit$incidence, c(150, 200))\nmatplot(data$time, incidence_fit, type = \"l\", col = \"#00000044\", lty = 1,\n        xlab = \"Time\", ylab = \"Incidence\")\nmatlines(t, t(traj_counterfactual$incidence), col = \"blue\")\npoints(data, pch = 19, col = \"red\")",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Projections and counterfactuals</span>"
    ]
  },
  {
    "objectID": "differentiability.html",
    "href": "differentiability.html",
    "title": "16  Differentiability",
    "section": "",
    "text": "Random walk suppression and other uses",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Differentiability</span>"
    ]
  },
  {
    "objectID": "2009-flu-uk.html",
    "href": "2009-flu-uk.html",
    "title": "17  2009 pandemic in the UK",
    "section": "",
    "text": "17.1 Introduction\nThe 2009 A/H1N1 influenza pandemic (Ghani et al. 2009) posed a significant public health challenge in England and Wales, requiring rapid and evidence-based decision-making to mitigate its impact (Baguelin et al. 2010). This chapter explores the use of odin and monty to model the dynamics of the 2009 A/H1N1 influenza pandemic in England and Wales, incorporating changes in social contacts during holiday periods. We demonstrate how to construct, fit, and analyse a compartmental model to infer key epidemiological parameters.",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>2009 pandemic in the UK</span>"
    ]
  },
  {
    "objectID": "2009-flu-uk.html#introduction",
    "href": "2009-flu-uk.html#introduction",
    "title": "17  2009 pandemic in the UK",
    "section": "",
    "text": "17.1.1 Objective of this chapter\nThe chapter is structured to guide the reader through an entire modelling pipeline, from data preparation and visualisation to model construction, parameter inference, and validation. Along the way, we highlight the integration of real-world data, discuss challenges in linking models to observed cases, and showcase the use of Bayesian methods for robust parameter estimation.\n\n\n17.1.2 Overview of the pipeline\nThis chapter illustrates how to:\n\nConstruct an SEIR transmission model with time-varying contact rate using odin\nImplement a (probabilistic) observation model in odin\nDerive a likelihood based on observations using dust and convert it to monty\nBuilt a prior distribution for the model parameters using the monty DSL\nRun Bayesian inference using adaptive Markov chain Monte Carlo (MCMC) with monty\nAnalyse and interpret the MCMC results.\n\n\n\n17.1.3 Key parameters of interest\nWe are interested in particular in two epidemiological parameters:\n\nThe basic reproduction number \\(R_0\\) of the novel influenza strain;\n\nThe ascertainment probability, i.e., the proportion of total infections reported as cases.",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>2009 pandemic in the UK</span>"
    ]
  },
  {
    "objectID": "2009-flu-uk.html#data-preparation-and-visualisation",
    "href": "2009-flu-uk.html#data-preparation-and-visualisation",
    "title": "17  2009 pandemic in the UK",
    "section": "17.2 Data preparation and visualisation",
    "text": "17.2 Data preparation and visualisation\nData is the number of weekly cases of A/H1N1 pandemic cases from June 2009, and initially broken up into seven age-groups. For simplicity, we aggregate the data into a single time series for this analysis.\n\n17.2.1 Loading data\nThe data file is taken from the supplement material in (Endo, Leeuwen, and Baguelin 2019) and can be found here.\nWe will fit our model to all cases aggregated so we need to load our data, add the age-group using rowSums, and then build a dataframe (a table where each rows is an observations of certains variables in the columns) with ‘days’ and ‘cases’.\n\n# Read the data\noriginal_data &lt;- rowSums(read.csv(file = \"data/flu_2009.csv\"))\n\n# Create the data frame and add days as time\ndata &lt;- data.frame(\n  time = seq(7, by = 7, length.out = length(original_data)),\n  cases = original_data\n)\n\n\n\n17.2.2 Plotting the data\nYou can plot the data and see the two waves of infections and the presence of holiday periods (note that only the first part of the plotting code is shown here for clarity - look at source for full plotting code).\n\nplot(data$time, data$cases, pch = 19, col = \"red\", \n     xlab = \"Days since start of epidemics\",\n     ylab = \"Official cases count\",\n     main = \"Cases over Time with Holiday Periods\",\n     ylim = c(0, max(data$cases) * 1.3), # Add padding to the y-axis\n     xlim = c(min(data$time), max(data$time)))",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>2009 pandemic in the UK</span>"
    ]
  },
  {
    "objectID": "2009-flu-uk.html#model-design",
    "href": "2009-flu-uk.html#model-design",
    "title": "17  2009 pandemic in the UK",
    "section": "17.3 Model design",
    "text": "17.3 Model design\n\n17.3.1 Transmission model\nSimilarly to the SIR model, we saw already, the SEIR model divides the population into four compartments:\n\nSusceptible: Individuals at risk of infection.\n\nExposed: Infected individuals who are not yet infectious.\n\nInfectious: Actively transmitting the disease.\n\nRecovered: Immune individuals.\n\nAdditionally, the model incorporates time-varying transmission rates to account for changes in contact patterns during holidays.\nThe SEIR model is governed by the following system of ordinary differential equations:\n\\[\n\\left\\{\n\\begin{aligned}\n    \\frac{dS}{dt} &= - \\beta(t) \\frac{S I}{N} \\\\\n    \\frac{dE}{dt} &= \\beta(t) \\frac{S I}{N} - \\sigma E \\\\\n    \\frac{dI}{dt} &= \\sigma E - \\gamma I \\\\\n    \\frac{dR}{dt} &= \\gamma I\n\\end{aligned}\n\\right.\n\\]\nwhere:\n\n\\(\\beta(t)\\) is the time-dependent transmission rate, representing the rate at which susceptible individuals become exposed through contact with infectious individuals.\n\\(\\sigma\\) is the rate at which exposed individuals transition to the infectious stage (the inverse of the latency period).\n\\(\\gamma\\) is the recovery rate, indicating the rate at which infectious individuals recover or are removed from the infectious population.\n\\(N\\) is the total population size, assumed to remain constant.\n\\(S(t)\\), \\(E(t)\\), \\(I(t)\\), and \\(R(t)\\) represent the number of susceptible, exposed, infectious, and recovered individuals, respectively, at time \\(t\\).\n\nWe assume that the contact rate is constant outside of the holiday period, dropping by 30% during the summer and 15% during the half-term. To parameterise the model, we use the basic reproduction number \\(R_{0}\\), which represents the average number of secondary infections caused by one infected individual in a fully susceptible population. Using the relationship \\(R_{0} = \\beta / \\gamma\\) and interpreting \\(h(t)\\) as a piecewise constant function equal to 0.7 during the summer, 0.85 during the half-term, and 1 otherwise, we define:\n\\[\\beta(t) = R_{0} \\cdot \\gamma \\cdot  h(t).\\]\nTo seed the model we assume that a small proportion of the population is infected - equally shared between the E and I compartments. The initial conditions are thus:\n\\[\n\\begin{aligned}\n    S(0) &= (1 - 2 \\alpha) N \\\\\n    E(0) &= \\alpha N \\\\\n    I(0) &= \\alpha N \\\\\n    R(0) &= 0 \\\\\n\\end{aligned}\n\\]\n\n\n17.3.2 Observation model\nThe fundamental component of our transmission model is the ‘I’ compartment tracking continuously the number of infectious people in our population (an infection prevalence). However, what we observe through our surveillance system is a fraction of the weekly total incidence, more precisely an estimate of the number of new cases in a period of 7 days (a week).\nIn our odin model we can track the weekly cumulative incidence \\(Z(t)\\) by:\n\nadding a differential equation integrating the instantaneous incidence:\n\n\\[\\frac{dZ}{dt} = \\sigma E\\]\n\nresetting \\(Z(t) = 0\\) at the beginning of each week to only account for the new cases from the current week.\n\nThen we get for each \\(t\\) that is a multiple of 7 (i.e. when we change week):\n\\[Z(t) = \\int_{t-7}^{t} \\sigma E(s) \\ ds\\]\ni.e. the cumulative incidence over a week.\nFinally, we need to account for the imperfection of the surveillance system, assuming that only a fraction \\(\\rho\\) of the infections are captured by the surveillance system and accounting for potential overdispersion we define the following observation model using a negative binomial distribution with mean \\(\\mu = \\rho Z(t)\\) and size \\(\\eta\\):\n\\[\n\\text{cases(t)} \\sim \\text{NegativeBinomial}(\\text{size} = \\eta, \\mu = \\rho Z(t)),\n\\]\nwhere \\(\\rho\\) is the ascertainment probability, and \\(\\eta\\) is the dispersion parameter.\n\n\n\n\n\n\nNote\n\n\n\nEven if the surveillance system was perfect we would expect a difference between the number of symptomatic cases and the number of infections as a proportion of flu cases are asymptomatic or ‘pauci-symptomatic’ (showing very few symptoms).\n\n\n\n\n17.3.3 Summary of model parameters\nA summary of the parameters of our model:\n\n\\(R_{0}\\), the basic reproduction number,\n\\(\\alpha\\), the proportion of the population infected at the start of the epidemic,\n\\(\\sigma\\), the inverse of the mean incubation period set to 1 day,\n\\(\\gamma\\), the recovery rate, the inverse of the mean recovery time assumed to be 1.25 days,\n\\(h(t)\\), the reduction of contact due to holidays, assumed piecewise constant,\n\\(\\rho\\), the ascertainment probability i.e. the proportion of infections we expect to ascert as cases,\n\\(\\eta\\), the size parameter of our Negative Binomial observation model,\n\\(N\\) the total size of the population in England and Wales in 2009.\n\nAmong these parameters, \\(R_{0}\\), \\(\\alpha\\), \\(\\rho\\), and \\(\\eta\\) are treated as “unknown” and inferred using our Bayesian pipeline.\n\n\n17.3.4 Odin code of the model\n\nlibrary(odin2)\nlibrary(dust2)\nlibrary(monty)\n\nBelow is the odin code for our model - the structure matches closely the mathematical formulation we derived in the previous section. Note the cases &lt;- data() lines telling that cases are observations though the model will compile and work even if not linked with any dataset. However providing data is essential to compute a likelihood with dust or derive a monty likelihood statistical model of our system.\nThe compilation step takes time. The model needs to be first transpiled (e.g. translated from one programming language to another) in order to create some C++ code and then that code is compiled and loaded in the R environnment. After this, a “fast” model can be called from the R environment and used to simulate scenarios or perform inference.\n\nseir &lt;- odin2::odin({\n  # initial conditions\n  initial(S) &lt;- (1 - 2 * alpha) * N\n  initial(E) &lt;- alpha * N\n  initial(I) &lt;- alpha * N\n  initial(R) &lt;- 0\n  initial(incidence, zero_every = 7) &lt;- 0\n  \n  # equations\n  deriv(S) &lt;- - hol * beta * S * I / N\n  deriv(E) &lt;- hol * beta * S * I / N - sigma * E\n  deriv(I) &lt;- sigma * E - gamma * I\n  deriv(R) &lt;- gamma * I\n  deriv(incidence) &lt;- sigma * E\n  \n  # parameter values\n  R_0 &lt;- parameter(1.5)\n  L &lt;- 1\n  D &lt;- 1.25\n  alpha &lt;- parameter(1e-4) # initial proportion\n  N &lt;- parameter(55000000) # total population\n  \n  # convert parameters\n  hol &lt;- interpolate(h_times, h_values, \"constant\")\n  h_times &lt;- parameter()\n  h_values &lt;- parameter()\n  dim(h_times) &lt;- parameter(rank = 1)\n  dim(h_values) &lt;- length(h_times)\n  gamma &lt;- 1 / L\n  sigma &lt;- 1 / D\n  beta &lt;- R_0 * gamma\n  \n  # observation model\n  rho &lt;- parameter(0.1)\n  eta &lt;- parameter(10)\n  cases &lt;- data()\n  cases ~ NegativeBinomial(size = eta, mu = rho * incidence)\n})\n\n\n\n17.3.5 Running the model\nOnce the model is compiled, it is possible to generate one (or more!) instance of your model by using the dust_system_create() and your model generator.\n\nmod &lt;- dust_system_create(seir,\n                          pars = list(h_times = hol_t, h_values = hol_v))\n\nThen parameters can be passed to the model using a list with the dust_system_update_pars() function.\n\npars &lt;- list(\n  alpha = 2e-5,\n  R_0 = 1.3,\n  rho = 0.1,\n  eta = 10,\n  N = 55000000,\n  h_times = hol_t,\n  h_values= hol_v\n)\ndust_system_update_pars(sys = mod, pars = pars)\n\nThen the model can be run by specifying the time points between which to integrate the ODEs. Note that the first point (here 0) set the inital time of the integration. Once the time vector t is defined we can run the model by using the dust_system_simulate() function.\n\nt &lt;- c(0,data$time)\ndust_system_set_state_initial(mod)\ny &lt;- dust_system_simulate(mod, t)\n\nLet’s plot the incidence compartment over time.\n\nplot(t, dust_unpack_state(mod, y)$incidence, type = \"l\", col = \"#000088ff\")\n\n\n\n\n\n\n\n\nIt looks a bit like the actual epidemic; a good sign, but let’s compare our model with the data.\n\nplot(data$time, data$cases,\n     xlab = \"Days since start of epidemics\",\n     ylab = \"Official estimates of cases\",\n     pch = 19,\n     col = \"red\",\n     ylim = c(0, max(data$cases) * 1.5))\nlines(t, dust_unpack_state(mod, y)$incidence * pars$rho, col = \"#000088ff\")\n\n\n\n\n\n\n\n\nWe seem to be overestimating the expected number of cases by a factor two or so, but the MCMC pipeline should allow us to infer the distribution of the parameters consistent with the observations.",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>2009 pandemic in the UK</span>"
    ]
  },
  {
    "objectID": "2009-flu-uk.html#the-mcmc-pipeline",
    "href": "2009-flu-uk.html#the-mcmc-pipeline",
    "title": "17  2009 pandemic in the UK",
    "section": "17.4 The MCMC pipeline",
    "text": "17.4 The MCMC pipeline\nWe now have a dataset and a working model, all loaded in our R environment. We need to link the output of this model with the data in order to derive a likelihood function. As we are working within a Bayesian framework we also need to define the prior distribution for our parameters.\n\n17.4.1 Setting up the likelihood\nThe likelihood is a function that takes a parameter as argument and return the probability density that our model (transmission model + observation) generates exactly the observed data. This number is usually very small as it is the product of each individual observation density given the model. Remember that functionns log-densities (rather than densities) and that products then become sums and divisions become differences. So for example if we need to compute a ratio a densities, we would substract the relevant log-densities and then exponentiate the result.\n\nfilter &lt;- dust_unfilter_create(seir, data = data, time_start = 0)\ndust_likelihood_run(filter, pars)\n#&gt; [1] -503.2286\n\n\n\n\n\n\n\nNote\n\n\n\nTo create the likelihood dust expect a “time” column in the data, that tells the timepoints where the model output needs to be compared with the observations.\n\n\nThis is the likelihood associated with the dust model written using the odin DSL. We now need to move this into the monty statistical world to be able to integrate this into our pipeline. For this, we use the packer concept (see Section 14.2) that allows us to define a one-to-one translation between the two worlds.\n\npacker &lt;- monty_packer(c(\"alpha\", \"R_0\", \"rho\", \"eta\"),\n                       fixed = list(h_times = pars$h_times,\n                                    h_values = pars$h_values,\n                                    N = pars$N))\n\nNow building the monty model for the likelihood of the model is very easy:\n\nlikelihood &lt;- dust_likelihood_monty(filter, packer, save_trajectories = TRUE)\n\n\n\n17.4.2 Setting up the prior distribution\nWe similarly set up a log-prior function. Note that we use the function to exclude impossible values such as a proportion below 0 or above 1. This is to avoid to getting a log-density of -Inf given that these values would have a density value of 0 (=impossible).\nWe can construct the prior with monty_dsl, note that the names are matching the parameters from the likelihood as it should be.\n\nprior &lt;- monty_dsl({\n  alpha ~ Beta(a = 4e-4, b = 2)\n  R_0 ~ Gamma(2, 0.7)\n  rho ~ Uniform(0, 1)\n  eta ~ Exponential(mean = 1000)\n})\n\nLet’s inspect our prior monty model\n\nprior\n#&gt; \n#&gt; ── &lt;monty_model&gt; ───────────────────────────────────────────────────────────────\n#&gt; ℹ Model has 4 parameters: 'alpha', 'R_0', 'rho', and 'eta'\n#&gt; ℹ This model:\n#&gt; • can compute gradients\n#&gt; • can be directly sampled from\n#&gt; • accepts multiple parameters\n#&gt; ℹ See `?monty_model()` for more information\n\nAs it has been built using the monty DSL, it comes with gradient calculation, direct sampling (so no need to use one of the Monte Carlo algorithm) and accepts multiple parameters.\nLet’s try to generate samples and check that they match our prior distribution:\n\nn_streams &lt;- 10000\nr &lt;- monty_rng_create(n_streams = n_streams)\nprior_samples &lt;- matrix(monty_model_direct_sample(prior, r), nrow = n_streams)\ncolnames(prior_samples) &lt;- prior$parameters\n\n\nbayesplot::mcmc_pairs(prior_samples)\n#&gt; Warning: Only one chain in 'x'. This plot is more useful with multiple chains.\n\n\n\n\n\n\n\n\n\n\n17.4.3 Setting up the posterior\nOur posterior is the product of the likelihood and prior, or its log is the sum of their logs:\n\nposterior &lt;- likelihood + prior\n\n\n\n17.4.4 Chosing the sampler\nNext, we define a sampler; as, we have little information about the scale and structure of our posterior, we’ll use an adaptive sampler with a simple and fairly arbitrary variance-covariance matrix with a low weight to generate the initial random walk:\n\nvcv &lt;- diag(c(5e-10, 5e-5, 1e-5, 1))\nsampler &lt;- monty_sampler_adaptive(vcv, initial_vcv_weight = 10)\n\nWe start this off, using explicit initial conditions based on the value we tested earlier:\n\nsamples &lt;- monty_sample(posterior,\n                        sampler,\n                        10000,\n                        initial = packer$pack(pars),\n                        n_chains = 4)\n#&gt; ⡀⠀ Sampling [▁▁▁▁] ■                                |   0% ETA:  5m\n#&gt; ⠄⠀ Sampling [▁▁▁▁] ■                                |   1% ETA:  1m\n#&gt; ⢂⠀ Sampling [▂▁▁▁] ■■■                              |   6% ETA:  1m\n#&gt; ⡂⠀ Sampling [▄▁▁▁] ■■■■                             |  11% ETA:  1m\n#&gt; ⠅⠀ Sampling [▅▁▁▁] ■■■■■■                           |  16% ETA:  1m\n#&gt; ⢃⠀ Sampling [▆▁▁▁] ■■■■■■■                          |  21% ETA: 47s\n#&gt; ⡃⠀ Sampling [█▁▁▁] ■■■■■■■■■                        |  26% ETA: 45s\n#&gt; ⠍⠀ Sampling [█▂▁▁] ■■■■■■■■■■                       |  31% ETA: 42s\n#&gt; ⢋⠀ Sampling [█▄▁▁] ■■■■■■■■■■■■                     |  36% ETA: 39s\n#&gt; ⡋⠀ Sampling [█▅▁▁] ■■■■■■■■■■■■■                    |  41% ETA: 35s\n#&gt; ⠍⠁ Sampling [█▆▁▁] ■■■■■■■■■■■■■■■                  |  46% ETA: 33s\n#&gt; ⢋⠁ Sampling [██▁▁] ■■■■■■■■■■■■■■■■                 |  50% ETA: 30s\n#&gt; ⡋⠁ Sampling [██▂▁] ■■■■■■■■■■■■■■■■■■               |  56% ETA: 27s\n#&gt; ⠍⠉ Sampling [██▃▁] ■■■■■■■■■■■■■■■■■■■              |  60% ETA: 24s\n#&gt; ⠋⠉ Sampling [██▅▁] ■■■■■■■■■■■■■■■■■■■■■            |  65% ETA: 21s\n#&gt; ⠋⠉ Sampling [██▆▁] ■■■■■■■■■■■■■■■■■■■■■■           |  70% ETA: 18s\n#&gt; ⠉⠙ Sampling [███▁] ■■■■■■■■■■■■■■■■■■■■■■■■         |  75% ETA: 15s\n#&gt; ⠉⠙ Sampling [███▂] ■■■■■■■■■■■■■■■■■■■■■■■■■        |  80% ETA: 12s\n#&gt; ⠉⠩ Sampling [███▃] ■■■■■■■■■■■■■■■■■■■■■■■■■■■      |  85% ETA:  9s\n#&gt; ⠈⢙ Sampling [███▅] ■■■■■■■■■■■■■■■■■■■■■■■■■■■■     |  90% ETA:  6s\n#&gt; ⠈⡙ Sampling [███▆] ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■   |  95% ETA:  3s\n#&gt; ⢈⠩ Sampling [███▇] ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  | 100% ETA:  0s\n#&gt; ✔ Sampled 40000 steps across 4 chains in 1m 0.8s\n#&gt; \n\n\n\n\n\n\n\nNote\n\n\n\nWe have used explicit initial conditions here, which might not be what you want in all situations. It might be better to sample from the prior, but we have not yet implemented support to try a few points from the sample before getting a point with finite density, which is really needed here.\n\n\nHere the log-posterior density of our three chains over time, showing a rapid improvement in the posterior probability density followed by what might be reasonable (but not great) mixing:\n\nmatplot(samples$density, type = \"l\", lty = 1,\n        xlab = \"Sample\", ylab = \"Log posterior probability density\")\n\n\n\n\n\n\n\nlength(unique(samples$density)) / length(samples$density)\n#&gt; [1] 0.6552\n\nWe will thin the samples, removing the first 2000 iterations from each chain and then thinning by a factor of 32 to produce a sample size of 1000.\n\nsamples &lt;- monty_samples_thin(samples, thinning_factor = 32, burnin = 2000)\n\nWe can use the posterior package to summarise the fitted parameters and provide convergence diagnostics and bayesplot for pairs plots:\n\nsamples_df &lt;- posterior::as_draws_df(samples)\nposterior::summarise_draws(samples_df)\n#&gt; # A tibble: 4 × 10\n#&gt;   variable        mean     median      sd     mad      q5     q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha     0.00000905    9.04e-6 1.06e-6 1.04e-6 7.33e-6 1.08e-5 1.03     310. \n#&gt; 2 R_0       1.37          1.37e+0 1.11e-2 1.10e-2 1.36e+0 1.39e+0 1.03     304. \n#&gt; 3 rho       0.0392        3.92e-2 1.75e-3 1.73e-3 3.65e-2 4.22e-2 0.999    410. \n#&gt; 4 eta      16.1           1.58e+1 3.53e+0 3.41e+0 1.06e+1 2.26e+1 1.04      90.0\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\nbayesplot::mcmc_pairs(samples_df)\n\n\n\n\n\n\n\n\nFinally we can get an idea of the fit of the samples by producing a plot comparing the fitted trajectories to the data.\n\ny &lt;- dust_unpack_state(filter, samples$observations$trajectories)\n\n## Resize the array to remove the chains dimension\nincidence &lt;- array(y$incidence, c(nrow(data), 1000))\n\n## Multiply incidence by fitted value of rho to give modelled cases\nrho &lt;- c(samples$pars[\"rho\", , ])\ncases_modelled &lt;- t(incidence) * rho\n\nmatplot(data$time, t(cases_modelled), type = \"l\", lty = 1, col = \"#00008822\",\n        xlab = \"Time\", ylab = \"Cases\")\npoints(data$time, data$cases, pch = 19, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nBaguelin, Marc, Albert Jan Van A. J. V. Hoek, Mark Jit, Stefan Flasche, Peter J. P. J. Peter J. White, W. J. John Edmunds, Albert Jan A. J. van Hoek, et al. 2010. “Vaccination Against Pandemic Influenza A/H1N1v in England: A Real-Time Economic Evaluation.” Vaccine 28 (12): 2370–84. https://doi.org/10.1016/j.vaccine.2010.01.002.\n\n\nEndo, Akira, Edwin van Leeuwen, and Marc Baguelin. 2019. “Introduction to Particle Markov-Chain Monte Carlo for Disease Dynamics Modellers.” Epidemics 29 (December): 100363.\n\n\nGhani, Azra, Marc Baguelin, Jamie Griffin, Stefan Flasche, Albert Jan van Hoek, Simon Cauchemez, Christl Donnelly, et al. 2009. “The Early Transmission Dynamics of H1N1pdm Influenza in the United Kingdom.” PLoS Currents 1 (January): RRN1130. https://doi.org/10.1371/currents.RRN1130.",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>2009 pandemic in the UK</span>"
    ]
  },
  {
    "objectID": "parallel.html",
    "href": "parallel.html",
    "title": "18  Parallelisation",
    "section": "",
    "text": "18.1 Using workers to parallelise between chains\nBoth dust2 and monty have built-in support that makes running in parallel relatively simple when you have multiple cores available. There are two main ways to parallelise:\nThe parallelisation is implemented in such a way that ensures that results will be identical to running in serial.\nThere is a third way to parallelise via manual scheduling of chains, which is of use if you want to distribute chains over, for example, the nodes of an HPC system.\nWe illustrate how to implement the three ways to parallelise below.\nlibrary(monty)\nLet’s revisit the simple Gaussian mixture model example from Section 10.1, and sample 4 chains of length 1000.\nfn &lt;- function(l, p, m1, m2) {\n  log(p * dnorm(l, mean = m1) + (1 - p) * dnorm(l, mean = m2))\n}\n\nmixture_model &lt;- monty_model_function(fn,\n                                      fixed = list(p = 0.75, m1 = 3, m2 = 7),\n                                      allow_multiple_parameters = TRUE)\n\nsampler &lt;- monty_sampler_random_walk(matrix(2))\n\nset.seed(1)\nsamples &lt;- monty_sample(mixture_model, sampler, 1000, initial = 3, n_chains = 4)\n#&gt; ⡀⠀ Sampling [▁▁▁▁] ■                                |   0% ETA: 28s\n#&gt; ✔ Sampled 4000 steps across 4 chains in 213ms\n#&gt;\nOne of the inputs to monty_sample we have not specified is runner. The runner determines how the chains are run, and these can be setup with functions in monty. If runner is not specified then as a default the samples will be run with the simplest runner which is constructed with monty_runner_serial. With this runner, chains are run in series (one after another).\nHowever if we have multiple cores available, we may want to run chains in parallel using workers. In this case we can construct a runner with monty_runner_callr. This runner uses the callr package to distribute your chains over a number of worker processes on the same machine.\nSuppose we have 2 cores, then we will setup the runner setting n_workers = 2.\nrunner &lt;- monty_runner_callr(n_workers = 2)\nThis indicates that we can run 2 chains in parallel. Running 4 chains in our example will mean that each worker process will run 2 chains in sequence. Ideally if you have sufficiently many cores available, you will set n_workers equal to the number of chains. Otherwise typically you want n_workers to be an even divisor of the number of chains - for 4 chains using 3 workers is not likely to be much faster than using 2 workers, as one of the workers would still need to run 2 chains in sequence.\nWe can run chains in parallel by using our runner\nset.seed(1)\nsamples2 &lt;- monty_sample(mixture_model, sampler, 1000, initial = 3, n_chains = 4,\n                         runner = runner)\nWe have set the seed before running in serial and before running in parallel so we can compare the output, and we can see that they produce identical results.\nidentical(samples, samples2)\n#&gt; [1] TRUE\nNotice that it has actually taken longer to run in parallel! This is because there is a cost to forking across the cores that outweighs the benefit of running in parallel in this case. If we run longer chains, in serial\nset.seed(1)\nsamples &lt;- monty_sample(mixture_model, sampler, 100000, initial = 3, n_chains = 4)\n#&gt; ⡀⠀ Sampling [▂▁▁▁] ■■■                              |   7% ETA: 18s\n#&gt; ⠄⠀ Sampling [▇▁▁▁] ■■■■■■■■                         |  23% ETA: 15s\n#&gt; ⢂⠀ Sampling [█▄▁▁] ■■■■■■■■■■■■■                    |  39% ETA: 12s\n#&gt; ⡂⠀ Sampling [██▂▁] ■■■■■■■■■■■■■■■■■■               |  55% ETA:  8s\n#&gt; ⠅⠀ Sampling [██▆▁] ■■■■■■■■■■■■■■■■■■■■■■           |  71% ETA:  5s\n#&gt; ⢃⠀ Sampling [███▄] ■■■■■■■■■■■■■■■■■■■■■■■■■■■      |  88% ETA:  2s\n#&gt; ✔ Sampled 4e+05 steps across 4 chains in 18.5s\n#&gt;\nand then in parallel\nrunner &lt;- monty_runner_callr(2)\nset.seed(1)\nsamples2 &lt;- monty_sample(mixture_model, sampler, 100000, initial = 3, n_chains = 4,\n                         runner = runner)\n#&gt; ⡀⠀ Sampling [▁▁▁▁] ■                                |   1% ETA:  1m\n#&gt; ⠄⠀ Sampling [▃▄▁▁] ■■■■■■■                          |  21% ETA: 14s\n#&gt; ⢂⠀ Sampling [▆▆▁▁] ■■■■■■■■■■■■■                    |  41% ETA: 10s\n#&gt; ⡂⠀ Sampling [██▂▂] ■■■■■■■■■■■■■■■■■■■              |  59% ETA:  7s\n#&gt; ⠅⠀ Sampling [██▅▄] ■■■■■■■■■■■■■■■■■■■■■■■■■        |  79% ETA:  3s\n#&gt; ⢃⠀ Sampling [███▇] ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  |  99% ETA:  0s\n#&gt; ✔ Sampled 4e+05 steps across 4 chains in 15.8s\n#&gt;\nwe now see that we are running quicker in parallel! In general, the longer each chain takes to run and the fewer chains you need to run per worker, the greater the benefit of running in parallel.",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Parallelisation</span>"
    ]
  },
  {
    "objectID": "parallel.html#using-threads-to-parallelise-among-particles-in-the-filter",
    "href": "parallel.html#using-threads-to-parallelise-among-particles-in-the-filter",
    "title": "18  Parallelisation",
    "section": "18.2 Using threads to parallelise among particles in the filter",
    "text": "18.2 Using threads to parallelise among particles in the filter\n\nlibrary(odin2)\nlibrary(dust2)\n\nLet’s consider the following discrete-time, stochastic SIR model\n\nsir &lt;- odin({\n  update(S) &lt;- S - n_SI\n  update(I) &lt;- I + n_SI - n_IR\n  update(R) &lt;- R + n_IR\n  update(incidence) &lt;- incidence + n_SI\n  \n  p_SI &lt;- 1 - exp(-beta * I / N * dt)\n  p_IR &lt;- 1 - exp(-gamma * dt)\n  n_SI &lt;- Binomial(S, p_SI)\n  n_IR &lt;- Binomial(I, p_IR)\n  \n  initial(S) &lt;- N - I0\n  initial(I) &lt;- I0\n  initial(R) &lt;- 0\n  initial(incidence, zero_every = 1) &lt;- 0\n  \n  N &lt;- parameter(1000)\n  I0 &lt;- parameter(10)\n  beta &lt;- parameter(0.2)\n  gamma &lt;- parameter(0.1)\n  \n  cases &lt;- data()\n  cases ~ Poisson(incidence)\n})\n\nWhich we will fit to the (synthetic) data set data/incidence.csv.\n\nd &lt;- read.csv(\"data/incidence.csv\")\nhead(d)\n#&gt;   time cases\n#&gt; 1    1    12\n#&gt; 2    2    23\n#&gt; 3    3    25\n#&gt; 4    4    36\n#&gt; 5    5    30\n#&gt; 6    6    57\n\nWe will setup our packer, prior and sampler\n\npacker &lt;- monty::monty_packer(scalar = c(\"beta\", \"gamma\"),\n                              fixed = list(I0 = 10, N = 1000))\n\nprior &lt;- monty::monty_dsl({\n  beta ~ Exponential(mean = 0.3)\n  gamma ~ Exponential(mean = 0.1)\n})\n\nvcv &lt;- diag(2) * 0.01\nsampler &lt;- monty::monty_sampler_random_walk(vcv)\n\nand then we will setup our likelihood using a filter with 100 particles and then run 4 chains without any parallelisation\n\nfilter &lt;- dust_filter_create(sir, time_start = 0,\n                             data = d, dt = 0.25,\n                             n_particles = 200)\n\nlikelihood &lt;- dust_likelihood_monty(filter, packer,\n                                    save_trajectories = TRUE)\n\nposterior &lt;- likelihood + prior\n\nsamples &lt;- monty_sample(posterior, sampler, n_steps = 1000,\n                        initial = c(0.3, 0.1),\n                        n_chains = 4)\n#&gt; ⡀⠀ Sampling [▂▁▁▁] ■■■                              |   6% ETA: 33s\n#&gt; ⠄⠀ Sampling [▅▁▁▁] ■■■■■                            |  15% ETA: 30s\n#&gt; ⢂⠀ Sampling [▇▁▁▁] ■■■■■■■■                         |  23% ETA: 27s\n#&gt; ⡂⠀ Sampling [█▂▁▁] ■■■■■■■■■■                       |  32% ETA: 24s\n#&gt; ⠅⠀ Sampling [█▅▁▁] ■■■■■■■■■■■■■                    |  40% ETA: 21s\n#&gt; ⢃⠀ Sampling [█▇▁▁] ■■■■■■■■■■■■■■■■                 |  49% ETA: 18s\n#&gt; ⡃⠀ Sampling [██▂▁] ■■■■■■■■■■■■■■■■■■               |  57% ETA: 15s\n#&gt; ⠍⠀ Sampling [██▅▁] ■■■■■■■■■■■■■■■■■■■■■            |  66% ETA: 12s\n#&gt; ⢋⠀ Sampling [██▇▁] ■■■■■■■■■■■■■■■■■■■■■■■          |  74% ETA:  9s\n#&gt; ⡋⠀ Sampling [███▃] ■■■■■■■■■■■■■■■■■■■■■■■■■■       |  83% ETA:  6s\n#&gt; ⠍⠁ Sampling [███▅] ■■■■■■■■■■■■■■■■■■■■■■■■■■■■     |  91% ETA:  3s\n#&gt; ⢋⠁ Sampling [███▇] ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  | 100% ETA:  0s\n#&gt; ✔ Sampled 4000 steps across 4 chains in 35.4s\n#&gt; \n\nAn input to dust_filter_create that we have not specified is n_threads, which has a default value of 1. Threads can be used in the filter to run particles forward in parallel. Suppose we have two available cores and we want to use these for threads in the filter, then we would set n_threads = 2\n\nfilter &lt;- dust_filter_create(sir, time_start = 0,\n                             data = d, dt = 0.25,\n                             n_particles = 200, \n                             n_threads = 2)\n\nlikelihood &lt;- dust_likelihood_monty(filter, packer,\n                                    save_trajectories = TRUE)\n\nposterior &lt;- likelihood + prior\n\nsamples &lt;- monty_sample(posterior, sampler, n_steps = 1000,\n                        initial = c(0.3, 0.1),\n                        n_chains = 4)\n#&gt; ⡀⠀ Sampling [▄▁▁▁] ■■■■■                            |  14% ETA: 17s\n#&gt; ⠄⠀ Sampling [█▂▁▁] ■■■■■■■■■■                       |  29% ETA: 14s\n#&gt; ⢂⠀ Sampling [█▆▁▁] ■■■■■■■■■■■■■■                   |  44% ETA: 11s\n#&gt; ⡂⠀ Sampling [██▃▁] ■■■■■■■■■■■■■■■■■■■              |  59% ETA:  8s\n#&gt; ⠅⠀ Sampling [██▇▁] ■■■■■■■■■■■■■■■■■■■■■■■          |  74% ETA:  5s\n#&gt; ⢃⠀ Sampling [███▅] ■■■■■■■■■■■■■■■■■■■■■■■■■■■■     |  90% ETA:  2s\n#&gt; ✔ Sampled 4000 steps across 4 chains in 19.8s\n#&gt; \n\nand we can see this is quicker than without parallelisation. As with workers and chains, generally the number of threads should be an even divisor of the number of particles.\nYou can use workers in combination with threads. To illustrate how to prioritise workers vs threads, let’s instead use our 2 cores for workers.\n\nfilter &lt;- dust_filter_create(sir, time_start = 0,\n                             data = d, dt = 0.25,\n                             n_particles = 200, \n                             n_threads = 1)\n\nlikelihood &lt;- dust_likelihood_monty(filter, packer,\n                                    save_trajectories = TRUE)\n\nposterior &lt;- likelihood + prior\n\nrunner &lt;- monty_runner_callr(n_workers = 2)\n\nsamples &lt;- monty_sample(posterior, sampler, n_steps = 1000,\n                        initial = c(0.3, 0.1),\n                        n_chains = 4,\n                        runner = runner)\n#&gt; ⡀⠀ Sampling [▁▁▁▁] ■                                |   1% ETA:  1m\n#&gt; ⠄⠀ Sampling [▃▃▁▁] ■■■■■■                           |  18% ETA: 18s\n#&gt; ⢂⠀ Sampling [▅▅▁▁] ■■■■■■■■■■■                      |  34% ETA: 14s\n#&gt; ⡂⠀ Sampling [██▁▁] ■■■■■■■■■■■■■■■■                 |  50% ETA: 10s\n#&gt; ⠅⠀ Sampling [██▂▃] ■■■■■■■■■■■■■■■■■■■■             |  64% ETA:  7s\n#&gt; ⢃⠀ Sampling [██▅▅] ■■■■■■■■■■■■■■■■■■■■■■■■■        |  81% ETA:  4s\n#&gt; ⡃⠀ Sampling [██▇█] ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  |  99% ETA:  0s\n#&gt; ✔ Sampled 4000 steps across 4 chains in 19.4s\n#&gt; \n\nWe see that this was quicker - this is because there is no communication between workers while the chains run, but there is regular communication between threads during while the filter runs. Thus it is better to prioritise workers over threads. Suppose you have 32 cores available and are running 4 chains. Ideally you would set n_workers = 4 in monty_runner_callr to ensure all 4 chains run at the same time, and then set n_threads = 8 (n_threads represents the number of threads per worker) to use all 32 cores, and choose n_particles to be a multiple of 8.",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Parallelisation</span>"
    ]
  },
  {
    "objectID": "parallel.html#using-manual-scheduling-to-parallelise-between-chains",
    "href": "parallel.html#using-manual-scheduling-to-parallelise-between-chains",
    "title": "18  Parallelisation",
    "section": "18.3 Using manual scheduling to parallelise between chains",
    "text": "18.3 Using manual scheduling to parallelise between chains\nSuppose you have access to an HPC system with multiple nodes of e.g. 32 cores. Efficient combination of workers and threads on a single 32-core node is already beneficial. Manual scheduling with monty enables running chains on different nodes, essentially increasing the number of cores available. For example, instead of running 4 chains with 4 workers on a 32-core node resulting in 8 threads per chain/worker, you could run 4 chains on 4 32-core nodes using 32 cores per chain (using 128 cores in total).\nInstead of using monty_sample, first we would need to prepare the chains\nmonty_sample_manual_prepare(posterior, sampler, n_steps = 1000,\n                            path = \"mypath\",\n                            initial = c(0.3, 0.1),\n                            n_chains = 4)\nwhere here \"mypath\" is the location for writing outputs to. Cluster jobs are submitted for each chain, running the chain with\nmonty_sample_manual_run(1, path = \"mypath\")\nfor chain 1,\nmonty_sample_manual_run(2, path = \"mypath\")\nfor chain 2, and so on.\nOnce all chains have been run, results from the chains can be collected together\nsamples &lt;- monty_sample_manual_collect(\"mypath\")",
    "crumbs": [
      "Odin & Monty",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Parallelisation</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Baguelin, Marc, Albert Jan Van A. J. V. Hoek, Mark Jit, Stefan Flasche,\nPeter J. P. J. Peter J. White, W. J. John Edmunds, Albert Jan A. J. van\nHoek, et al. 2010. “Vaccination Against Pandemic Influenza\nA/H1N1v in England:\nA Real-Time Economic Evaluation.” Vaccine\n28 (12): 2370–84. https://doi.org/10.1016/j.vaccine.2010.01.002.\n\n\nEndo, Akira, Edwin van Leeuwen, and Marc Baguelin. 2019.\n“Introduction to Particle Markov-Chain\nMonte Carlo for Disease Dynamics\nModellers.” Epidemics 29 (December): 100363.\n\n\nGhani, Azra, Marc Baguelin, Jamie Griffin, Stefan Flasche, Albert Jan\nvan Hoek, Simon Cauchemez, Christl Donnelly, et al. 2009. “The\nEarly Transmission Dynamics of\nH1N1pdm Influenza in the United\nKingdom.” PLoS Currents 1 (January):\nRRN1130. https://doi.org/10.1371/currents.RRN1130.\n\n\nHoffman, Matthew D, and Andrew Gelman. 2014. “The\nNo-U-Turn Sampler:\nAdaptively Setting Path\nLengths in Hamiltonian Monte\nCarlo.” Journal of Machine Learning\nResearch 15: 1351–81. http://mcmc-jags.sourceforge.net.\n\n\nNeal, Radford M. 2011. “MCMC Using Hamiltonian\nDynamics.” In Handbook of Markov\nChain Monte Carlo, 113–62.\nhttps://doi.org/10.1201/b10905-6.\n\n\nSpencer, Simon E. F. 2021. “Accelerating Adaptation in the\nAdaptive Metropolis–Hastings Random Walk Algorithm.”\nAustralian & New Zealand Journal of Statistics 63 (3):\n468–84. https://doi.org/https://doi.org/10.1111/anzs.12344.\n\n\nSyed, Saifuddin, Alexandre Bouchard-Côté, George Deligiannidis, and\nArnaud Doucet. 2022. “Non-Reversible\nParallel Tempering: A\nScalable Highly Parallel\nMCMC Scheme.” Journal of the Royal\nStatistical Society Series B: Statistical Methodology 84 (2):\n321–50. https://doi.org/10.1111/rssb.12464.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Appendix A — Installation",
    "section": "",
    "text": "A.1 Packages\nPackage installation is hard, let’s go shopping.\nThe short version:\nWe require a number of R packages, most of which are currently (as of late 2024) under very active development. The canonical source for these packages is currently our r-universe and not CRAN, but we hope to get the stack onto CRAN as soon as they stabilise. The version of odin on CRAN is now wildly out of date with the content in this guide.\nThe required packages are:\nThese packages sit on a huge foundation of work, much of which has been written by staff at Posit (formerly RStudio)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "installation.html#packages",
    "href": "installation.html#packages",
    "title": "Appendix A — Installation",
    "section": "",
    "text": "install.packages(\n  c(\"monty\", \"dust2\", \"odin2\"),\n  repos = c(\"https://mrc-ide.r-universe.dev\", \"https://cloud.r-project.org\"))\n\n\n\nodin2: the DSL itself\ndust2: support for running odin models (odin “transpiles” R code into dust2)\nmonty: statistical distributions and inference support\n\n\n\ncpp11 for painless bindings between C++ and R\npkgbuild for building packages\npkgload for loading temporary packages\ncli for messages and console interfaces\nrlang for control over metaprogramming and errors",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "installation.html#system-requirements",
    "href": "installation.html#system-requirements",
    "title": "Appendix A — Installation",
    "section": "A.2 System requirements",
    "text": "A.2 System requirements\nYou need a functioning C++ toolchain. How you get one depends on your platform, and is unfortunately a bit of a moving target. The source of truth for these matters is Writing R extensions and R installation and administration.\nFor windows users it is usually sufficient to install Rtools for your version of R. For Linux users there’s a good chance you already have a functioning toolchain. Mac users tend to have the biggest issues, particularly with OpenMP support.\nYou can run this diagnostic function in pkgbuild (which we use to do compilation) to help diagnose your system\n\npkgbuild::check_build_tools(debug = TRUE)\n#&gt; Trying to compile a simple C file\n#&gt; Running /opt/R/4.5.1/lib/R/bin/R CMD SHLIB foo.c\n#&gt; using C compiler: ‘gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0’\n#&gt; gcc -std=gnu2x -I\"/opt/R/4.5.1/lib/R/include\" -DNDEBUG   -I/usr/local/include    -fpic  -g -O2  -c foo.c -o foo.o\n#&gt; gcc -std=gnu2x -shared -L/opt/R/4.5.1/lib/R/lib -L/usr/local/lib -o foo.so foo.o -L/opt/R/4.5.1/lib/R/lib -lR\n#&gt; \n#&gt; Your system is ready to build packages!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "colophon.html",
    "href": "colophon.html",
    "title": "Appendix B — Colophon",
    "section": "",
    "text": "Key versions:\n\nodin2: 0.3.36\ndust2: 0.3.25\nmonty: 0.4.0\n\nRendered on 2025-08-15 15:53:22.18534 using quarto 1.7.33\nFull system information:\n\nsessioninfo::session_info()\n#&gt; ─ Session info ───────────────────────────────────────────────────────────────\n#&gt;  setting  value\n#&gt;  version  R version 4.5.1 (2025-06-13)\n#&gt;  os       Ubuntu 24.04.2 LTS\n#&gt;  system   x86_64, linux-gnu\n#&gt;  ui       X11\n#&gt;  language (EN)\n#&gt;  collate  C.UTF-8\n#&gt;  ctype    C.UTF-8\n#&gt;  tz       UTC\n#&gt;  date     2025-08-15\n#&gt;  pandoc   3.1.3 @ /usr/bin/ (via rmarkdown)\n#&gt;  quarto   1.7.33 @ /usr/local/bin/quarto\n#&gt; \n#&gt; ─ Packages ───────────────────────────────────────────────────────────────────\n#&gt;  package     * version date (UTC) lib source\n#&gt;  brio          1.1.5   2024-04-24 [1] RSPM\n#&gt;  cli           3.6.5   2025-04-23 [1] RSPM\n#&gt;  cpp11         0.5.2   2025-03-03 [1] RSPM\n#&gt;  decor         1.0.2   2023-07-01 [1] RSPM\n#&gt;  digest        0.6.37  2024-08-19 [1] RSPM\n#&gt;  dust2         0.3.25  2025-08-11 [1] Github (mrc-ide/dust2@d0a72cc)\n#&gt;  evaluate      1.0.4   2025-06-18 [1] RSPM\n#&gt;  fastmap       1.2.0   2024-05-15 [1] RSPM\n#&gt;  fs            1.6.6   2025-04-12 [1] RSPM\n#&gt;  glue          1.8.0   2024-09-30 [1] RSPM\n#&gt;  htmltools     0.5.8.1 2024-04-04 [1] RSPM\n#&gt;  htmlwidgets   1.6.4   2023-12-06 [1] RSPM\n#&gt;  jsonlite      2.0.0   2025-03-27 [1] RSPM\n#&gt;  knitr         1.50    2025-03-16 [1] RSPM\n#&gt;  later         1.4.2   2025-04-08 [1] RSPM\n#&gt;  lifecycle     1.0.4   2023-11-07 [1] RSPM\n#&gt;  magrittr      2.0.3   2022-03-30 [1] RSPM\n#&gt;  monty         0.4.0   2025-08-15 [1] Github (mrc-ide/monty@b4a9f47)\n#&gt;  odin2         0.3.36  2025-08-11 [1] Github (mrc-ide/odin2@9fa05a8)\n#&gt;  pillar        1.11.0  2025-07-04 [1] RSPM\n#&gt;  pkgbuild      1.4.8   2025-05-26 [1] RSPM\n#&gt;  pkgconfig     2.0.3   2019-09-22 [1] RSPM\n#&gt;  pkgload       1.4.0   2024-06-28 [1] RSPM\n#&gt;  processx      3.8.6   2025-02-21 [1] RSPM\n#&gt;  ps            1.9.1   2025-04-12 [1] RSPM\n#&gt;  purrr         1.1.0   2025-07-10 [1] RSPM\n#&gt;  quarto        1.5.0   2025-07-28 [1] RSPM\n#&gt;  R6            2.6.1   2025-02-15 [1] RSPM\n#&gt;  Rcpp          1.1.0   2025-07-02 [1] RSPM\n#&gt;  rlang         1.1.6   2025-04-11 [1] RSPM\n#&gt;  rmarkdown     2.29    2024-11-04 [1] RSPM\n#&gt;  rstudioapi    0.17.1  2024-10-22 [1] RSPM\n#&gt;  sessioninfo   1.2.3   2025-02-05 [1] RSPM\n#&gt;  tibble        3.3.0   2025-06-08 [1] RSPM\n#&gt;  usethis       3.1.0   2024-11-26 [1] RSPM\n#&gt;  vctrs         0.6.5   2023-12-01 [1] RSPM\n#&gt;  xfun          0.52    2025-04-02 [1] RSPM\n#&gt;  yaml          2.3.10  2024-07-26 [1] RSPM\n#&gt; \n#&gt;  [1] /home/runner/work/_temp/Library\n#&gt;  [2] /opt/R/4.5.1/lib/R/site-library\n#&gt;  [3] /opt/R/4.5.1/lib/R/library\n#&gt; \n#&gt; ──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Colophon</span>"
    ]
  }
]